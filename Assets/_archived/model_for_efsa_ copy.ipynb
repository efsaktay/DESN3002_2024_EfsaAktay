{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23194c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "th = torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from random import randint\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b0352",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a815cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dfs = pickle.load(open('scaled_companies_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0491f777-b444-483d-b53c-71ad9f6d5197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tesla':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.011927                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.014130                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.015604                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.018631                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.022618                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.385859                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.395966                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.382698                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.390057                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.380858                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'salesforce':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.221674                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.217416                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.255219                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.268460                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.275366                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.921331                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.924655                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.910375                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.907934                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.882854                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'goldman_sachs':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.343914                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.334430                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.342634                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.347965                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.355822                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.953926                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.954514                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.920071                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.908716                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.881058                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'microsoft':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.085729                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.078925                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.080320                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.075387                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.083926                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.983739                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.989488                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.979214                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.995101                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.974588                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'delta_airlines':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.930205                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.907330                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.897993                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.896825                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.925770                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.649393                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.656629                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.631419                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.663866                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.645892                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'apple':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.133751                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.128611                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.132783                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.130301                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.138751                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.791152                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.799743                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.786435                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.837555                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.848188                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'visa':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.358145                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.348315                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.345664                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.342430                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.363319                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.918451                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.911725                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.897239                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.904999                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.906810                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'ford':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.255430                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.245515                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.243154                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.247403                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.247403                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.443815                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.449953                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.427290                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.426346                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.406043                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'dell':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.100521                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.093138                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.095327                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.089834                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.090692                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.952832                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.923870                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.920821                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.926495                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.873314                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'alphabet':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.147394                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.144039                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.161044                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.159779                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.164432                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.957265                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.973665                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.969354                0.971629      0.968939         0.936562\n",
       " 2024-04-11  1.000000                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.984255                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c47022fe-ce6f-41f6-b629-0be82f098483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Companies: 10 | # of Price Points: 1077\n",
      "Companies: \n",
      "['tesla', 'salesforce', 'goldman_sachs', 'microsoft', 'delta_airlines', 'apple', 'visa', 'ford', 'dell', 'alphabet']\n",
      "number to be assigned as train: 862 | test: 215\n"
     ]
    }
   ],
   "source": [
    "pc_train = 0.2\n",
    "\n",
    "names = list(dfs.keys())\n",
    "T = len(dfs[names[0]])\n",
    "n_train = int(pc_train * T)\n",
    "\n",
    "dfs_train, dfs_test = {}, {}\n",
    "for _name, _df in dfs.items():\n",
    "    dfs_train[_name] = _df.iloc[:len(_df) - n_train]\n",
    "    dfs_test[_name] = _df.iloc[len(_df) - n_train:]\n",
    "\n",
    "n_train_per_company = len(dfs_train[_name])\n",
    "n_test_per_company = len(dfs_test[_name])\n",
    "\n",
    "print('# of Companies: {} | # of Price Points: {}'.format(len(names), T))\n",
    "print('Companies: ')\n",
    "print(names)\n",
    "print('# to be assigned as train: {} | test: {}'.format(len(dfs_train[_name]), len(dfs_test[_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a77a41f7-7bad-4d9b-891f-ccbd7515a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-01-02',\n",
       " '2020-01-03',\n",
       " '2020-01-06',\n",
       " '2020-01-07',\n",
       " '2020-01-08',\n",
       " '2020-01-09',\n",
       " '2020-01-10',\n",
       " '2020-01-13',\n",
       " '2020-01-14',\n",
       " '2020-01-15',\n",
       " '2020-01-16',\n",
       " '2020-01-17',\n",
       " '2020-01-21',\n",
       " '2020-01-22',\n",
       " '2020-01-23',\n",
       " '2020-01-24',\n",
       " '2020-01-27',\n",
       " '2020-01-28',\n",
       " '2020-01-29',\n",
       " '2020-01-30',\n",
       " '2020-01-31',\n",
       " '2020-02-03',\n",
       " '2020-02-04',\n",
       " '2020-02-05',\n",
       " '2020-02-06',\n",
       " '2020-02-07',\n",
       " '2020-02-10',\n",
       " '2020-02-11',\n",
       " '2020-02-12',\n",
       " '2020-02-13',\n",
       " '2020-02-14',\n",
       " '2020-02-18',\n",
       " '2020-02-19',\n",
       " '2020-02-20',\n",
       " '2020-02-21',\n",
       " '2020-02-24',\n",
       " '2020-02-25',\n",
       " '2020-02-26',\n",
       " '2020-02-27',\n",
       " '2020-02-28',\n",
       " '2020-03-02',\n",
       " '2020-03-03',\n",
       " '2020-03-04',\n",
       " '2020-03-05',\n",
       " '2020-03-06',\n",
       " '2020-03-09',\n",
       " '2020-03-10',\n",
       " '2020-03-11',\n",
       " '2020-03-12',\n",
       " '2020-03-13',\n",
       " '2020-03-16',\n",
       " '2020-03-17',\n",
       " '2020-03-18',\n",
       " '2020-03-19',\n",
       " '2020-03-20',\n",
       " '2020-03-23',\n",
       " '2020-03-24',\n",
       " '2020-03-25',\n",
       " '2020-03-26',\n",
       " '2020-03-27',\n",
       " '2020-03-30',\n",
       " '2020-03-31',\n",
       " '2020-04-01',\n",
       " '2020-04-02',\n",
       " '2020-04-03',\n",
       " '2020-04-06',\n",
       " '2020-04-07',\n",
       " '2020-04-08',\n",
       " '2020-04-09',\n",
       " '2020-04-13',\n",
       " '2020-04-14',\n",
       " '2020-04-15',\n",
       " '2020-04-16',\n",
       " '2020-04-17',\n",
       " '2020-04-20',\n",
       " '2020-04-21',\n",
       " '2020-04-22',\n",
       " '2020-04-23',\n",
       " '2020-04-24',\n",
       " '2020-04-27',\n",
       " '2020-04-28',\n",
       " '2020-04-29',\n",
       " '2020-04-30',\n",
       " '2020-05-01',\n",
       " '2020-05-04',\n",
       " '2020-05-05',\n",
       " '2020-05-06',\n",
       " '2020-05-07',\n",
       " '2020-05-08',\n",
       " '2020-05-11',\n",
       " '2020-05-12',\n",
       " '2020-05-13',\n",
       " '2020-05-14',\n",
       " '2020-05-15',\n",
       " '2020-05-18',\n",
       " '2020-05-19',\n",
       " '2020-05-20',\n",
       " '2020-05-21',\n",
       " '2020-05-22',\n",
       " '2020-05-26',\n",
       " '2020-05-27',\n",
       " '2020-05-28',\n",
       " '2020-05-29',\n",
       " '2020-06-01',\n",
       " '2020-06-02',\n",
       " '2020-06-03',\n",
       " '2020-06-04',\n",
       " '2020-06-05',\n",
       " '2020-06-08',\n",
       " '2020-06-09',\n",
       " '2020-06-10',\n",
       " '2020-06-11',\n",
       " '2020-06-12',\n",
       " '2020-06-15',\n",
       " '2020-06-16',\n",
       " '2020-06-17',\n",
       " '2020-06-18',\n",
       " '2020-06-19',\n",
       " '2020-06-22',\n",
       " '2020-06-23',\n",
       " '2020-06-24',\n",
       " '2020-06-25',\n",
       " '2020-06-26',\n",
       " '2020-06-29',\n",
       " '2020-06-30',\n",
       " '2020-07-01',\n",
       " '2020-07-02',\n",
       " '2020-07-06',\n",
       " '2020-07-07',\n",
       " '2020-07-08',\n",
       " '2020-07-09',\n",
       " '2020-07-10',\n",
       " '2020-07-13',\n",
       " '2020-07-14',\n",
       " '2020-07-15',\n",
       " '2020-07-16',\n",
       " '2020-07-17',\n",
       " '2020-07-20',\n",
       " '2020-07-21',\n",
       " '2020-07-22',\n",
       " '2020-07-23',\n",
       " '2020-07-24',\n",
       " '2020-07-27',\n",
       " '2020-07-28',\n",
       " '2020-07-29',\n",
       " '2020-07-30',\n",
       " '2020-07-31',\n",
       " '2020-08-03',\n",
       " '2020-08-04',\n",
       " '2020-08-05',\n",
       " '2020-08-06',\n",
       " '2020-08-07',\n",
       " '2020-08-10',\n",
       " '2020-08-11',\n",
       " '2020-08-12',\n",
       " '2020-08-13',\n",
       " '2020-08-14',\n",
       " '2020-08-17',\n",
       " '2020-08-18',\n",
       " '2020-08-19',\n",
       " '2020-08-20',\n",
       " '2020-08-21',\n",
       " '2020-08-24',\n",
       " '2020-08-25',\n",
       " '2020-08-26',\n",
       " '2020-08-27',\n",
       " '2020-08-28',\n",
       " '2020-08-31',\n",
       " '2020-09-01',\n",
       " '2020-09-02',\n",
       " '2020-09-03',\n",
       " '2020-09-04',\n",
       " '2020-09-08',\n",
       " '2020-09-09',\n",
       " '2020-09-10',\n",
       " '2020-09-11',\n",
       " '2020-09-14',\n",
       " '2020-09-15',\n",
       " '2020-09-16',\n",
       " '2020-09-17',\n",
       " '2020-09-18',\n",
       " '2020-09-21',\n",
       " '2020-09-22',\n",
       " '2020-09-23',\n",
       " '2020-09-24',\n",
       " '2020-09-25',\n",
       " '2020-09-28',\n",
       " '2020-09-29',\n",
       " '2020-09-30',\n",
       " '2020-10-01',\n",
       " '2020-10-02',\n",
       " '2020-10-05',\n",
       " '2020-10-06',\n",
       " '2020-10-07',\n",
       " '2020-10-08',\n",
       " '2020-10-09',\n",
       " '2020-10-12',\n",
       " '2020-10-13',\n",
       " '2020-10-14',\n",
       " '2020-10-15',\n",
       " '2020-10-16',\n",
       " '2020-10-19',\n",
       " '2020-10-20',\n",
       " '2020-10-21',\n",
       " '2020-10-22',\n",
       " '2020-10-23',\n",
       " '2020-10-26',\n",
       " '2020-10-27',\n",
       " '2020-10-28',\n",
       " '2020-10-29',\n",
       " '2020-10-30',\n",
       " '2020-11-02',\n",
       " '2020-11-03',\n",
       " '2020-11-04',\n",
       " '2020-11-05',\n",
       " '2020-11-06',\n",
       " '2020-11-09',\n",
       " '2020-11-10',\n",
       " '2020-11-11',\n",
       " '2020-11-12',\n",
       " '2020-11-13',\n",
       " '2020-11-16',\n",
       " '2020-11-17',\n",
       " '2020-11-18',\n",
       " '2020-11-19',\n",
       " '2020-11-20',\n",
       " '2020-11-23',\n",
       " '2020-11-24',\n",
       " '2020-11-25',\n",
       " '2020-11-27',\n",
       " '2020-11-30',\n",
       " '2020-12-01',\n",
       " '2020-12-02',\n",
       " '2020-12-03',\n",
       " '2020-12-04',\n",
       " '2020-12-07',\n",
       " '2020-12-08',\n",
       " '2020-12-09',\n",
       " '2020-12-10',\n",
       " '2020-12-11',\n",
       " '2020-12-14',\n",
       " '2020-12-15',\n",
       " '2020-12-16',\n",
       " '2020-12-17',\n",
       " '2020-12-18',\n",
       " '2020-12-21',\n",
       " '2020-12-22',\n",
       " '2020-12-23',\n",
       " '2020-12-24',\n",
       " '2020-12-28',\n",
       " '2020-12-29',\n",
       " '2020-12-30',\n",
       " '2020-12-31',\n",
       " '2021-01-04',\n",
       " '2021-01-05',\n",
       " '2021-01-06',\n",
       " '2021-01-07',\n",
       " '2021-01-08',\n",
       " '2021-01-11',\n",
       " '2021-01-12',\n",
       " '2021-01-13',\n",
       " '2021-01-14',\n",
       " '2021-01-15',\n",
       " '2021-01-19',\n",
       " '2021-01-20',\n",
       " '2021-01-21',\n",
       " '2021-01-22',\n",
       " '2021-01-25',\n",
       " '2021-01-26',\n",
       " '2021-01-27',\n",
       " '2021-01-28',\n",
       " '2021-01-29',\n",
       " '2021-02-01',\n",
       " '2021-02-02',\n",
       " '2021-02-03',\n",
       " '2021-02-04',\n",
       " '2021-02-05',\n",
       " '2021-02-08',\n",
       " '2021-02-09',\n",
       " '2021-02-10',\n",
       " '2021-02-11',\n",
       " '2021-02-12',\n",
       " '2021-02-16',\n",
       " '2021-02-17',\n",
       " '2021-02-18',\n",
       " '2021-02-19',\n",
       " '2021-02-22',\n",
       " '2021-02-23',\n",
       " '2021-02-24',\n",
       " '2021-02-25',\n",
       " '2021-02-26',\n",
       " '2021-03-01',\n",
       " '2021-03-02',\n",
       " '2021-03-03',\n",
       " '2021-03-04',\n",
       " '2021-03-05',\n",
       " '2021-03-08',\n",
       " '2021-03-09',\n",
       " '2021-03-10',\n",
       " '2021-03-11',\n",
       " '2021-03-12',\n",
       " '2021-03-15',\n",
       " '2021-03-16',\n",
       " '2021-03-17',\n",
       " '2021-03-18',\n",
       " '2021-03-19',\n",
       " '2021-03-22',\n",
       " '2021-03-23',\n",
       " '2021-03-24',\n",
       " '2021-03-25',\n",
       " '2021-03-26',\n",
       " '2021-03-29',\n",
       " '2021-03-30',\n",
       " '2021-03-31',\n",
       " '2021-04-01',\n",
       " '2021-04-05',\n",
       " '2021-04-06',\n",
       " '2021-04-07',\n",
       " '2021-04-08',\n",
       " '2021-04-09',\n",
       " '2021-04-12',\n",
       " '2021-04-13',\n",
       " '2021-04-14',\n",
       " '2021-04-15',\n",
       " '2021-04-16',\n",
       " '2021-04-19',\n",
       " '2021-04-20',\n",
       " '2021-04-21',\n",
       " '2021-04-22',\n",
       " '2021-04-23',\n",
       " '2021-04-26',\n",
       " '2021-04-27',\n",
       " '2021-04-28',\n",
       " '2021-04-29',\n",
       " '2021-04-30',\n",
       " '2021-05-03',\n",
       " '2021-05-04',\n",
       " '2021-05-05',\n",
       " '2021-05-06',\n",
       " '2021-05-07',\n",
       " '2021-05-10',\n",
       " '2021-05-11',\n",
       " '2021-05-12',\n",
       " '2021-05-13',\n",
       " '2021-05-14',\n",
       " '2021-05-17',\n",
       " '2021-05-18',\n",
       " '2021-05-19',\n",
       " '2021-05-20',\n",
       " '2021-05-21',\n",
       " '2021-05-24',\n",
       " '2021-05-25',\n",
       " '2021-05-26',\n",
       " '2021-05-27',\n",
       " '2021-05-28',\n",
       " '2021-06-01',\n",
       " '2021-06-02',\n",
       " '2021-06-03',\n",
       " '2021-06-04',\n",
       " '2021-06-07',\n",
       " '2021-06-08',\n",
       " '2021-06-09',\n",
       " '2021-06-10',\n",
       " '2021-06-11',\n",
       " '2021-06-14',\n",
       " '2021-06-15',\n",
       " '2021-06-16',\n",
       " '2021-06-17',\n",
       " '2021-06-18',\n",
       " '2021-06-21',\n",
       " '2021-06-22',\n",
       " '2021-06-23',\n",
       " '2021-06-24',\n",
       " '2021-06-25',\n",
       " '2021-06-28',\n",
       " '2021-06-29',\n",
       " '2021-06-30',\n",
       " '2021-07-01',\n",
       " '2021-07-02',\n",
       " '2021-07-06',\n",
       " '2021-07-07',\n",
       " '2021-07-08',\n",
       " '2021-07-09',\n",
       " '2021-07-12',\n",
       " '2021-07-13',\n",
       " '2021-07-14',\n",
       " '2021-07-15',\n",
       " '2021-07-16',\n",
       " '2021-07-19',\n",
       " '2021-07-20',\n",
       " '2021-07-21',\n",
       " '2021-07-22',\n",
       " '2021-07-23',\n",
       " '2021-07-26',\n",
       " '2021-07-27',\n",
       " '2021-07-28',\n",
       " '2021-07-29',\n",
       " '2021-07-30',\n",
       " '2021-08-02',\n",
       " '2021-08-03',\n",
       " '2021-08-04',\n",
       " '2021-08-05',\n",
       " '2021-08-06',\n",
       " '2021-08-09',\n",
       " '2021-08-10',\n",
       " '2021-08-11',\n",
       " '2021-08-12',\n",
       " '2021-08-13',\n",
       " '2021-08-16',\n",
       " '2021-08-17',\n",
       " '2021-08-18',\n",
       " '2021-08-19',\n",
       " '2021-08-20',\n",
       " '2021-08-23',\n",
       " '2021-08-24',\n",
       " '2021-08-25',\n",
       " '2021-08-26',\n",
       " '2021-08-27',\n",
       " '2021-08-30',\n",
       " '2021-08-31',\n",
       " '2021-09-01',\n",
       " '2021-09-02',\n",
       " '2021-09-03',\n",
       " '2021-09-07',\n",
       " '2021-09-08',\n",
       " '2021-09-09',\n",
       " '2021-09-10',\n",
       " '2021-09-13',\n",
       " '2021-09-14',\n",
       " '2021-09-15',\n",
       " '2021-09-16',\n",
       " '2021-09-17',\n",
       " '2021-09-20',\n",
       " '2021-09-21',\n",
       " '2021-09-22',\n",
       " '2021-09-23',\n",
       " '2021-09-24',\n",
       " '2021-09-27',\n",
       " '2021-09-28',\n",
       " '2021-09-29',\n",
       " '2021-09-30',\n",
       " '2021-10-01',\n",
       " '2021-10-04',\n",
       " '2021-10-05',\n",
       " '2021-10-06',\n",
       " '2021-10-07',\n",
       " '2021-10-08',\n",
       " '2021-10-11',\n",
       " '2021-10-12',\n",
       " '2021-10-13',\n",
       " '2021-10-14',\n",
       " '2021-10-15',\n",
       " '2021-10-18',\n",
       " '2021-10-19',\n",
       " '2021-10-20',\n",
       " '2021-10-21',\n",
       " '2021-10-22',\n",
       " '2021-10-25',\n",
       " '2021-10-26',\n",
       " '2021-10-27',\n",
       " '2021-10-28',\n",
       " '2021-10-29',\n",
       " '2021-11-01',\n",
       " '2021-11-02',\n",
       " '2021-11-03',\n",
       " '2021-11-04',\n",
       " '2021-11-05',\n",
       " '2021-11-08',\n",
       " '2021-11-09',\n",
       " '2021-11-10',\n",
       " '2021-11-11',\n",
       " '2021-11-12',\n",
       " '2021-11-15',\n",
       " '2021-11-16',\n",
       " '2021-11-17',\n",
       " '2021-11-18',\n",
       " '2021-11-19',\n",
       " '2021-11-22',\n",
       " '2021-11-23',\n",
       " '2021-11-24',\n",
       " '2021-11-26',\n",
       " '2021-11-29',\n",
       " '2021-11-30',\n",
       " '2021-12-01',\n",
       " '2021-12-02',\n",
       " '2021-12-03',\n",
       " '2021-12-06',\n",
       " '2021-12-07',\n",
       " '2021-12-08',\n",
       " '2021-12-09',\n",
       " '2021-12-10',\n",
       " '2021-12-13',\n",
       " '2021-12-14',\n",
       " '2021-12-15',\n",
       " '2021-12-16',\n",
       " '2021-12-17',\n",
       " '2021-12-20',\n",
       " '2021-12-21',\n",
       " '2021-12-22',\n",
       " '2021-12-23',\n",
       " '2021-12-27',\n",
       " '2021-12-28',\n",
       " '2021-12-29',\n",
       " '2021-12-30',\n",
       " '2021-12-31',\n",
       " '2022-01-03',\n",
       " '2022-01-04',\n",
       " '2022-01-05',\n",
       " '2022-01-06',\n",
       " '2022-01-07',\n",
       " '2022-01-10',\n",
       " '2022-01-11',\n",
       " '2022-01-12',\n",
       " '2022-01-13',\n",
       " '2022-01-14',\n",
       " '2022-01-18',\n",
       " '2022-01-19',\n",
       " '2022-01-20',\n",
       " '2022-01-21',\n",
       " '2022-01-24',\n",
       " '2022-01-25',\n",
       " '2022-01-26',\n",
       " '2022-01-27',\n",
       " '2022-01-28',\n",
       " '2022-01-31',\n",
       " '2022-02-01',\n",
       " '2022-02-02',\n",
       " '2022-02-03',\n",
       " '2022-02-04',\n",
       " '2022-02-07',\n",
       " '2022-02-08',\n",
       " '2022-02-09',\n",
       " '2022-02-10',\n",
       " '2022-02-11',\n",
       " '2022-02-14',\n",
       " '2022-02-15',\n",
       " '2022-02-16',\n",
       " '2022-02-17',\n",
       " '2022-02-18',\n",
       " '2022-02-22',\n",
       " '2022-02-23',\n",
       " '2022-02-24',\n",
       " '2022-02-25',\n",
       " '2022-02-28',\n",
       " '2022-03-01',\n",
       " '2022-03-02',\n",
       " '2022-03-03',\n",
       " '2022-03-04',\n",
       " '2022-03-07',\n",
       " '2022-03-08',\n",
       " '2022-03-09',\n",
       " '2022-03-10',\n",
       " '2022-03-11',\n",
       " '2022-03-14',\n",
       " '2022-03-15',\n",
       " '2022-03-16',\n",
       " '2022-03-17',\n",
       " '2022-03-18',\n",
       " '2022-03-21',\n",
       " '2022-03-22',\n",
       " '2022-03-23',\n",
       " '2022-03-24',\n",
       " '2022-03-25',\n",
       " '2022-03-28',\n",
       " '2022-03-29',\n",
       " '2022-03-30',\n",
       " '2022-03-31',\n",
       " '2022-04-01',\n",
       " '2022-04-04',\n",
       " '2022-04-05',\n",
       " '2022-04-06',\n",
       " '2022-04-07',\n",
       " '2022-04-08',\n",
       " '2022-04-11',\n",
       " '2022-04-12',\n",
       " '2022-04-13',\n",
       " '2022-04-14',\n",
       " '2022-04-18',\n",
       " '2022-04-19',\n",
       " '2022-04-20',\n",
       " '2022-04-21',\n",
       " '2022-04-22',\n",
       " '2022-04-25',\n",
       " '2022-04-26',\n",
       " '2022-04-27',\n",
       " '2022-04-28',\n",
       " '2022-04-29',\n",
       " '2022-05-02',\n",
       " '2022-05-03',\n",
       " '2022-05-04',\n",
       " '2022-05-05',\n",
       " '2022-05-06',\n",
       " '2022-05-09',\n",
       " '2022-05-10',\n",
       " '2022-05-11',\n",
       " '2022-05-12',\n",
       " '2022-05-13',\n",
       " '2022-05-16',\n",
       " '2022-05-17',\n",
       " '2022-05-18',\n",
       " '2022-05-19',\n",
       " '2022-05-20',\n",
       " '2022-05-23',\n",
       " '2022-05-24',\n",
       " '2022-05-25',\n",
       " '2022-05-26',\n",
       " '2022-05-27',\n",
       " '2022-05-31',\n",
       " '2022-06-01',\n",
       " '2022-06-02',\n",
       " '2022-06-03',\n",
       " '2022-06-06',\n",
       " '2022-06-07',\n",
       " '2022-06-08',\n",
       " '2022-06-09',\n",
       " '2022-06-10',\n",
       " '2022-06-13',\n",
       " '2022-06-14',\n",
       " '2022-06-15',\n",
       " '2022-06-16',\n",
       " '2022-06-17',\n",
       " '2022-06-21',\n",
       " '2022-06-22',\n",
       " '2022-06-23',\n",
       " '2022-06-24',\n",
       " '2022-06-27',\n",
       " '2022-06-28',\n",
       " '2022-06-29',\n",
       " '2022-06-30',\n",
       " '2022-07-01',\n",
       " '2022-07-05',\n",
       " '2022-07-06',\n",
       " '2022-07-07',\n",
       " '2022-07-08',\n",
       " '2022-07-11',\n",
       " '2022-07-12',\n",
       " '2022-07-13',\n",
       " '2022-07-14',\n",
       " '2022-07-15',\n",
       " '2022-07-18',\n",
       " '2022-07-19',\n",
       " '2022-07-20',\n",
       " '2022-07-21',\n",
       " '2022-07-22',\n",
       " '2022-07-25',\n",
       " '2022-07-26',\n",
       " '2022-07-27',\n",
       " '2022-07-28',\n",
       " '2022-07-29',\n",
       " '2022-08-01',\n",
       " '2022-08-02',\n",
       " '2022-08-03',\n",
       " '2022-08-04',\n",
       " '2022-08-05',\n",
       " '2022-08-08',\n",
       " '2022-08-09',\n",
       " '2022-08-10',\n",
       " '2022-08-11',\n",
       " '2022-08-12',\n",
       " '2022-08-15',\n",
       " '2022-08-16',\n",
       " '2022-08-17',\n",
       " '2022-08-18',\n",
       " '2022-08-19',\n",
       " '2022-08-22',\n",
       " '2022-08-23',\n",
       " '2022-08-24',\n",
       " '2022-08-25',\n",
       " '2022-08-26',\n",
       " '2022-08-29',\n",
       " '2022-08-30',\n",
       " '2022-08-31',\n",
       " '2022-09-01',\n",
       " '2022-09-02',\n",
       " '2022-09-06',\n",
       " '2022-09-07',\n",
       " '2022-09-08',\n",
       " '2022-09-09',\n",
       " '2022-09-12',\n",
       " '2022-09-13',\n",
       " '2022-09-14',\n",
       " '2022-09-15',\n",
       " '2022-09-16',\n",
       " '2022-09-19',\n",
       " '2022-09-20',\n",
       " '2022-09-21',\n",
       " '2022-09-22',\n",
       " '2022-09-23',\n",
       " '2022-09-26',\n",
       " '2022-09-27',\n",
       " '2022-09-28',\n",
       " '2022-09-29',\n",
       " '2022-09-30',\n",
       " '2022-10-03',\n",
       " '2022-10-04',\n",
       " '2022-10-05',\n",
       " '2022-10-06',\n",
       " '2022-10-07',\n",
       " '2022-10-10',\n",
       " '2022-10-11',\n",
       " '2022-10-12',\n",
       " '2022-10-13',\n",
       " '2022-10-14',\n",
       " '2022-10-17',\n",
       " '2022-10-18',\n",
       " '2022-10-19',\n",
       " '2022-10-20',\n",
       " '2022-10-21',\n",
       " '2022-10-24',\n",
       " '2022-10-25',\n",
       " '2022-10-26',\n",
       " '2022-10-27',\n",
       " '2022-10-28',\n",
       " '2022-10-31',\n",
       " '2022-11-01',\n",
       " '2022-11-02',\n",
       " '2022-11-03',\n",
       " '2022-11-04',\n",
       " '2022-11-07',\n",
       " '2022-11-08',\n",
       " '2022-11-09',\n",
       " '2022-11-10',\n",
       " '2022-11-11',\n",
       " '2022-11-14',\n",
       " '2022-11-15',\n",
       " '2022-11-16',\n",
       " '2022-11-17',\n",
       " '2022-11-18',\n",
       " '2022-11-21',\n",
       " '2022-11-22',\n",
       " '2022-11-23',\n",
       " '2022-11-25',\n",
       " '2022-11-28',\n",
       " '2022-11-29',\n",
       " '2022-11-30',\n",
       " '2022-12-01',\n",
       " '2022-12-02',\n",
       " '2022-12-05',\n",
       " '2022-12-06',\n",
       " '2022-12-07',\n",
       " '2022-12-08',\n",
       " '2022-12-09',\n",
       " '2022-12-12',\n",
       " '2022-12-13',\n",
       " '2022-12-14',\n",
       " '2022-12-15',\n",
       " '2022-12-16',\n",
       " '2022-12-19',\n",
       " '2022-12-20',\n",
       " '2022-12-21',\n",
       " '2022-12-22',\n",
       " '2022-12-23',\n",
       " '2022-12-27',\n",
       " '2022-12-28',\n",
       " '2022-12-29',\n",
       " '2022-12-30',\n",
       " '2023-01-03',\n",
       " '2023-01-04',\n",
       " '2023-01-05',\n",
       " '2023-01-06',\n",
       " '2023-01-09',\n",
       " '2023-01-10',\n",
       " '2023-01-11',\n",
       " '2023-01-12',\n",
       " '2023-01-13',\n",
       " '2023-01-17',\n",
       " '2023-01-18',\n",
       " '2023-01-19',\n",
       " '2023-01-20',\n",
       " '2023-01-23',\n",
       " '2023-01-24',\n",
       " '2023-01-25',\n",
       " '2023-01-26',\n",
       " '2023-01-27',\n",
       " '2023-01-30',\n",
       " '2023-01-31',\n",
       " '2023-02-01',\n",
       " '2023-02-02',\n",
       " '2023-02-03',\n",
       " '2023-02-06',\n",
       " '2023-02-07',\n",
       " '2023-02-08',\n",
       " '2023-02-09',\n",
       " '2023-02-10',\n",
       " '2023-02-13',\n",
       " '2023-02-14',\n",
       " '2023-02-15',\n",
       " '2023-02-16',\n",
       " '2023-02-17',\n",
       " '2023-02-21',\n",
       " '2023-02-22',\n",
       " '2023-02-23',\n",
       " '2023-02-24',\n",
       " '2023-02-27',\n",
       " '2023-02-28',\n",
       " '2023-03-01',\n",
       " '2023-03-02',\n",
       " '2023-03-03',\n",
       " '2023-03-06',\n",
       " '2023-03-07',\n",
       " '2023-03-08',\n",
       " '2023-03-09',\n",
       " '2023-03-10',\n",
       " '2023-03-13',\n",
       " '2023-03-14',\n",
       " '2023-03-15',\n",
       " '2023-03-16',\n",
       " '2023-03-17',\n",
       " '2023-03-20',\n",
       " '2023-03-21',\n",
       " '2023-03-22',\n",
       " '2023-03-23',\n",
       " '2023-03-24',\n",
       " '2023-03-27',\n",
       " '2023-03-28',\n",
       " '2023-03-29',\n",
       " '2023-03-30',\n",
       " '2023-03-31',\n",
       " '2023-04-03',\n",
       " '2023-04-04',\n",
       " '2023-04-05',\n",
       " '2023-04-06',\n",
       " '2023-04-10',\n",
       " '2023-04-11',\n",
       " '2023-04-12',\n",
       " '2023-04-13',\n",
       " '2023-04-14',\n",
       " '2023-04-17',\n",
       " '2023-04-18',\n",
       " '2023-04-19',\n",
       " '2023-04-20',\n",
       " '2023-04-21',\n",
       " '2023-04-24',\n",
       " '2023-04-25',\n",
       " '2023-04-26',\n",
       " '2023-04-27',\n",
       " '2023-04-28',\n",
       " '2023-05-01',\n",
       " '2023-05-02',\n",
       " '2023-05-03',\n",
       " '2023-05-04',\n",
       " '2023-05-05',\n",
       " '2023-05-08',\n",
       " '2023-05-09',\n",
       " '2023-05-10',\n",
       " '2023-05-11',\n",
       " '2023-05-12',\n",
       " '2023-05-15',\n",
       " '2023-05-16',\n",
       " '2023-05-17',\n",
       " '2023-05-18',\n",
       " '2023-05-19',\n",
       " '2023-05-22',\n",
       " '2023-05-23',\n",
       " '2023-05-24',\n",
       " '2023-05-25',\n",
       " '2023-05-26',\n",
       " '2023-05-30',\n",
       " '2023-05-31',\n",
       " '2023-06-01',\n",
       " '2023-06-02',\n",
       " '2023-06-05',\n",
       " '2023-06-06',\n",
       " '2023-06-07',\n",
       " '2023-06-08',\n",
       " '2023-06-09',\n",
       " '2023-06-12',\n",
       " '2023-06-13',\n",
       " '2023-06-14',\n",
       " '2023-06-15',\n",
       " '2023-06-16',\n",
       " '2023-06-20',\n",
       " '2023-06-21',\n",
       " '2023-06-22',\n",
       " '2023-06-23',\n",
       " '2023-06-26',\n",
       " '2023-06-27',\n",
       " '2023-06-28',\n",
       " '2023-06-29',\n",
       " '2023-06-30',\n",
       " '2023-07-03',\n",
       " '2023-07-05',\n",
       " '2023-07-06',\n",
       " '2023-07-07',\n",
       " '2023-07-10',\n",
       " '2023-07-11',\n",
       " '2023-07-12',\n",
       " '2023-07-13',\n",
       " '2023-07-14',\n",
       " '2023-07-17',\n",
       " '2023-07-18',\n",
       " '2023-07-19',\n",
       " '2023-07-20',\n",
       " '2023-07-21',\n",
       " '2023-07-24',\n",
       " '2023-07-25',\n",
       " '2023-07-26',\n",
       " '2023-07-27',\n",
       " '2023-07-28',\n",
       " '2023-07-31',\n",
       " '2023-08-01',\n",
       " '2023-08-02',\n",
       " '2023-08-03',\n",
       " '2023-08-04',\n",
       " '2023-08-07',\n",
       " '2023-08-08',\n",
       " '2023-08-09',\n",
       " '2023-08-10',\n",
       " '2023-08-11',\n",
       " '2023-08-14',\n",
       " '2023-08-15',\n",
       " '2023-08-16',\n",
       " '2023-08-17',\n",
       " '2023-08-18',\n",
       " '2023-08-21',\n",
       " '2023-08-22',\n",
       " '2023-08-23',\n",
       " '2023-08-24',\n",
       " '2023-08-25',\n",
       " '2023-08-28',\n",
       " '2023-08-29',\n",
       " '2023-08-30',\n",
       " '2023-08-31',\n",
       " '2023-09-01',\n",
       " '2023-09-05',\n",
       " '2023-09-06',\n",
       " '2023-09-07',\n",
       " '2023-09-08',\n",
       " '2023-09-11',\n",
       " '2023-09-12',\n",
       " '2023-09-13',\n",
       " '2023-09-14',\n",
       " '2023-09-15',\n",
       " '2023-09-18',\n",
       " '2023-09-19',\n",
       " '2023-09-20',\n",
       " '2023-09-21',\n",
       " '2023-09-22',\n",
       " '2023-09-25',\n",
       " '2023-09-26',\n",
       " '2023-09-27',\n",
       " '2023-09-28',\n",
       " '2023-09-29',\n",
       " '2023-10-02',\n",
       " '2023-10-03',\n",
       " '2023-10-04',\n",
       " '2023-10-05',\n",
       " '2023-10-06',\n",
       " '2023-10-09',\n",
       " '2023-10-10',\n",
       " '2023-10-11',\n",
       " '2023-10-12',\n",
       " '2023-10-13',\n",
       " '2023-10-16',\n",
       " '2023-10-17',\n",
       " '2023-10-18',\n",
       " '2023-10-19',\n",
       " '2023-10-20',\n",
       " '2023-10-23',\n",
       " '2023-10-24',\n",
       " '2023-10-25',\n",
       " '2023-10-26',\n",
       " '2023-10-27',\n",
       " '2023-10-30',\n",
       " '2023-10-31',\n",
       " '2023-11-01',\n",
       " '2023-11-02',\n",
       " '2023-11-03',\n",
       " '2023-11-06',\n",
       " '2023-11-07',\n",
       " '2023-11-08',\n",
       " '2023-11-09',\n",
       " '2023-11-10',\n",
       " '2023-11-13',\n",
       " '2023-11-14',\n",
       " '2023-11-15',\n",
       " '2023-11-16',\n",
       " '2023-11-17',\n",
       " '2023-11-20',\n",
       " '2023-11-21',\n",
       " '2023-11-22',\n",
       " '2023-11-24',\n",
       " '2023-11-27',\n",
       " '2023-11-28',\n",
       " '2023-11-29',\n",
       " '2023-11-30',\n",
       " '2023-12-01',\n",
       " '2023-12-04',\n",
       " '2023-12-05',\n",
       " '2023-12-06',\n",
       " '2023-12-07',\n",
       " '2023-12-08',\n",
       " '2023-12-11',\n",
       " '2023-12-12',\n",
       " '2023-12-13',\n",
       " '2023-12-14',\n",
       " '2023-12-15',\n",
       " '2023-12-18',\n",
       " '2023-12-19',\n",
       " '2023-12-20',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[_name].index.strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d413a0e-e3a8-4e96-b4dd-8cfd4563bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-06-06',\n",
       " '2023-06-07',\n",
       " '2023-06-08',\n",
       " '2023-06-09',\n",
       " '2023-06-12',\n",
       " '2023-06-13',\n",
       " '2023-06-14',\n",
       " '2023-06-15',\n",
       " '2023-06-16',\n",
       " '2023-06-20',\n",
       " '2023-06-21',\n",
       " '2023-06-22',\n",
       " '2023-06-23',\n",
       " '2023-06-26',\n",
       " '2023-06-27',\n",
       " '2023-06-28',\n",
       " '2023-06-29',\n",
       " '2023-06-30',\n",
       " '2023-07-03',\n",
       " '2023-07-05',\n",
       " '2023-07-06',\n",
       " '2023-07-07',\n",
       " '2023-07-10',\n",
       " '2023-07-11',\n",
       " '2023-07-12',\n",
       " '2023-07-13',\n",
       " '2023-07-14',\n",
       " '2023-07-17',\n",
       " '2023-07-18',\n",
       " '2023-07-19',\n",
       " '2023-07-20',\n",
       " '2023-07-21',\n",
       " '2023-07-24',\n",
       " '2023-07-25',\n",
       " '2023-07-26',\n",
       " '2023-07-27',\n",
       " '2023-07-28',\n",
       " '2023-07-31',\n",
       " '2023-08-01',\n",
       " '2023-08-02',\n",
       " '2023-08-03',\n",
       " '2023-08-04',\n",
       " '2023-08-07',\n",
       " '2023-08-08',\n",
       " '2023-08-09',\n",
       " '2023-08-10',\n",
       " '2023-08-11',\n",
       " '2023-08-14',\n",
       " '2023-08-15',\n",
       " '2023-08-16',\n",
       " '2023-08-17',\n",
       " '2023-08-18',\n",
       " '2023-08-21',\n",
       " '2023-08-22',\n",
       " '2023-08-23',\n",
       " '2023-08-24',\n",
       " '2023-08-25',\n",
       " '2023-08-28',\n",
       " '2023-08-29',\n",
       " '2023-08-30',\n",
       " '2023-08-31',\n",
       " '2023-09-01',\n",
       " '2023-09-05',\n",
       " '2023-09-06',\n",
       " '2023-09-07',\n",
       " '2023-09-08',\n",
       " '2023-09-11',\n",
       " '2023-09-12',\n",
       " '2023-09-13',\n",
       " '2023-09-14',\n",
       " '2023-09-15',\n",
       " '2023-09-18',\n",
       " '2023-09-19',\n",
       " '2023-09-20',\n",
       " '2023-09-21',\n",
       " '2023-09-22',\n",
       " '2023-09-25',\n",
       " '2023-09-26',\n",
       " '2023-09-27',\n",
       " '2023-09-28',\n",
       " '2023-09-29',\n",
       " '2023-10-02',\n",
       " '2023-10-03',\n",
       " '2023-10-04',\n",
       " '2023-10-05',\n",
       " '2023-10-06',\n",
       " '2023-10-09',\n",
       " '2023-10-10',\n",
       " '2023-10-11',\n",
       " '2023-10-12',\n",
       " '2023-10-13',\n",
       " '2023-10-16',\n",
       " '2023-10-17',\n",
       " '2023-10-18',\n",
       " '2023-10-19',\n",
       " '2023-10-20',\n",
       " '2023-10-23',\n",
       " '2023-10-24',\n",
       " '2023-10-25',\n",
       " '2023-10-26',\n",
       " '2023-10-27',\n",
       " '2023-10-30',\n",
       " '2023-10-31',\n",
       " '2023-11-01',\n",
       " '2023-11-02',\n",
       " '2023-11-03',\n",
       " '2023-11-06',\n",
       " '2023-11-07',\n",
       " '2023-11-08',\n",
       " '2023-11-09',\n",
       " '2023-11-10',\n",
       " '2023-11-13',\n",
       " '2023-11-14',\n",
       " '2023-11-15',\n",
       " '2023-11-16',\n",
       " '2023-11-17',\n",
       " '2023-11-20',\n",
       " '2023-11-21',\n",
       " '2023-11-22',\n",
       " '2023-11-24',\n",
       " '2023-11-27',\n",
       " '2023-11-28',\n",
       " '2023-11-29',\n",
       " '2023-11-30',\n",
       " '2023-12-01',\n",
       " '2023-12-04',\n",
       " '2023-12-05',\n",
       " '2023-12-06',\n",
       " '2023-12-07',\n",
       " '2023-12-08',\n",
       " '2023-12-11',\n",
       " '2023-12-12',\n",
       " '2023-12-13',\n",
       " '2023-12-14',\n",
       " '2023-12-15',\n",
       " '2023-12-18',\n",
       " '2023-12-19',\n",
       " '2023-12-20',\n",
       " '2023-12-21',\n",
       " '2023-12-22',\n",
       " '2023-12-26',\n",
       " '2023-12-27',\n",
       " '2023-12-28',\n",
       " '2023-12-29',\n",
       " '2024-01-02',\n",
       " '2024-01-03',\n",
       " '2024-01-04',\n",
       " '2024-01-05',\n",
       " '2024-01-08',\n",
       " '2024-01-09',\n",
       " '2024-01-10',\n",
       " '2024-01-11',\n",
       " '2024-01-12',\n",
       " '2024-01-16',\n",
       " '2024-01-17',\n",
       " '2024-01-18',\n",
       " '2024-01-19',\n",
       " '2024-01-22',\n",
       " '2024-01-23',\n",
       " '2024-01-24',\n",
       " '2024-01-25',\n",
       " '2024-01-26',\n",
       " '2024-01-29',\n",
       " '2024-01-30',\n",
       " '2024-01-31',\n",
       " '2024-02-01',\n",
       " '2024-02-02',\n",
       " '2024-02-05',\n",
       " '2024-02-06',\n",
       " '2024-02-07',\n",
       " '2024-02-08',\n",
       " '2024-02-09',\n",
       " '2024-02-12',\n",
       " '2024-02-13',\n",
       " '2024-02-14',\n",
       " '2024-02-15',\n",
       " '2024-02-16',\n",
       " '2024-02-20',\n",
       " '2024-02-21',\n",
       " '2024-02-22',\n",
       " '2024-02-23',\n",
       " '2024-02-26',\n",
       " '2024-02-27',\n",
       " '2024-02-28',\n",
       " '2024-02-29',\n",
       " '2024-03-01',\n",
       " '2024-03-04',\n",
       " '2024-03-05',\n",
       " '2024-03-06',\n",
       " '2024-03-07',\n",
       " '2024-03-08',\n",
       " '2024-03-11',\n",
       " '2024-03-12',\n",
       " '2024-03-13',\n",
       " '2024-03-14',\n",
       " '2024-03-15',\n",
       " '2024-03-18',\n",
       " '2024-03-19',\n",
       " '2024-03-20',\n",
       " '2024-03-21',\n",
       " '2024-03-22',\n",
       " '2024-03-25',\n",
       " '2024-03-26',\n",
       " '2024-03-27',\n",
       " '2024-03-28',\n",
       " '2024-04-01',\n",
       " '2024-04-02',\n",
       " '2024-04-03',\n",
       " '2024-04-04',\n",
       " '2024-04-05',\n",
       " '2024-04-08',\n",
       " '2024-04-09',\n",
       " '2024-04-10',\n",
       " '2024-04-11',\n",
       " '2024-04-12']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test[_name].index.strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4aae1",
   "metadata": {},
   "source": [
    "## Load BERT embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0702b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamk/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Input ids are automatically padded from 3002 to 3072 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3002])\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# embedder = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "from transformers import LongformerModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "embedder = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "max_token_n = 4096\n",
    "\n",
    "# test model\n",
    "text = 'TWEETS' * 1000\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input.input_ids.shape)\n",
    "_  = embedder(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e2a23",
   "metadata": {},
   "source": [
    "## Dataset generation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f520e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def embed_by_bert(text):\n",
    "    _tkn = tokenizer(text, return_tensors='pt') \n",
    "    if _tkn.input_ids.shape[-1] >= max_token_n:\n",
    "        _tkn = _tkn[:,:max_token_n]\n",
    "    _emb = embedder(**_tkn).last_hidden_state[:,0,:].detach().to(th.float32)\n",
    "    return _emb\n",
    "\n",
    "def embed_one_by_one(list_list_texts, text_to_emb_dict, embed_func=None):\n",
    "    embs = []\n",
    "    for _i, _txts in enumerate(list_list_texts):\n",
    "        _embs = []\n",
    "        for _txt in _txts:\n",
    "            if _txt in text_to_emb_dict: \n",
    "                _emb = text_to_emb_dict.get(_txt)\n",
    "            else:\n",
    "                _emb = embed_func(_txt)\n",
    "                text_to_emb_dict[_txt] = _emb\n",
    "            _embs.append(_emb)\n",
    "        embs.append(_embs)\n",
    "    return embs\n",
    "\n",
    "def embed_text(dataset, list_list_texts, apply_pca=True):\n",
    "    unique_embs = dict()\n",
    "    dataset.unique_embs = unique_embs\n",
    "\n",
    "    list_list_embs_p_step = embed_one_by_one(list_list_texts, unique_embs, embed_by_bert)\n",
    "    list_embs_p_company = [th.cat(_embs, dim=0) for _embs in list_list_embs_p_step]\n",
    "    \n",
    "    #print(unique_embs)\n",
    "    \n",
    "    if apply_pca is not None:\n",
    "        apply_pca = {} if apply_pca is True else apply_pca\n",
    "        n_components = apply_pca if isinstance(apply_pca, int) else apply_pca.get('n_components', 10)\n",
    "        \n",
    "        # create concatenated embedding\n",
    "        unique_embs_txts, unique_embs_vals = list(zip(*unique_embs.items()))\n",
    "        unique_embs_cat = th.cat(unique_embs_vals, dim=0)\n",
    "        \n",
    "        # apply PCA\n",
    "        n_components = min(n_components, len(unique_embs_txts))\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(unique_embs_cat.numpy())\n",
    "        \n",
    "        #  transform\n",
    "        unique_embs_pca_cat = th.tensor(pca.transform(unique_embs_cat))\n",
    "        unique_embs_pca = dict(zip(unique_embs.keys(), th.split(unique_embs_pca_cat, 1)))\n",
    "        dataset.unique_embs_pca = unique_embs_pca\n",
    "        \n",
    "        #print(unique_embs_pca)\n",
    "        # recreate datastructure\n",
    "        list_list_embs_p_step_pca = embed_one_by_one(list_list_texts, unique_embs_pca)\n",
    "        list_embs_p_company = [th.cat(_embs, dim=0).to(th.float32) for _embs in list_list_embs_p_step_pca]\n",
    "\n",
    "    return list_embs_p_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "81b96f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, \n",
    "                 input_window=4, output_window=1,\n",
    "                 use_transformer=False, \n",
    "                 input_prices=['Close_x', 'Close_y'], output_prices=['Close_x'], \n",
    "                 include_text= False, apply_pca=10, # or False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        data (filepath of saved path)\n",
    "        data (list of pd.DataFrame): List of dataframes, each containing columns:\n",
    "                                          'time', 'stock price', 'stock index price', 'text message'\n",
    "        input_window (int): Number of timesteps in each input sequence.\n",
    "        output_window (int): Number of timesteps in each target sequence.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.sequences = [] # store chunks (data point)\n",
    "        self.sequences_raw = []   # store a company's entire time series sequence \n",
    "        self.sequences_raw_embs = [] # store a company's entire time series sequence (text embeddings including PCA if applied)\n",
    "        self.unique_embs = {}\n",
    "        self.unique_embs_pca = {}\n",
    "        \n",
    "        self.names = []\n",
    "        self.dates = []\n",
    "        \n",
    "        self.apply_pca = apply_pca\n",
    "        \n",
    "        if use_transformer:\n",
    "            output_window = 1\n",
    "        \n",
    "        if isinstance(data, str) and os.path.exists(data):\n",
    "            self.sequences, self.sequences_raw, self.sequences_raw_embs, \\\n",
    "            self.unique_embs, self.unique_embs_pca = pickle.load(open(data, 'rb'))\n",
    "        else:\n",
    "            self.input_window = input_window\n",
    "            self.output_window = output_window\n",
    "        \n",
    "            if include_text:\n",
    "                all_texts = [_df[include_text].values.tolist() for _df in data]\n",
    "                list_embs_p_company = self.embed_text(all_texts)\n",
    "\n",
    "            for _i_df, (_name, df) in enumerate(data.items()):\n",
    "                self.names.append(_name)\n",
    "                if _i_df == 0:\n",
    "                    self.dates = df.index.strftime('%Y-%m-%d').tolist()\n",
    "                \n",
    "                t = df[input_prices].shape[0]\n",
    "                seq_in = th.tensor(df[input_prices].values).reshape(t,-1).to(th.float32)\n",
    "                self.sequences_raw.append(seq_in)\n",
    "                \n",
    "                seq_tgt = th.tensor(df[output_prices].values).reshape(t,-1).to(th.float32)\n",
    "                if include_text:\n",
    "                    embs = list_embs_p_company[_i_df]\n",
    "                    self.sequences_raw_embs.append(embs)\n",
    "\n",
    "                num_sequences = t - self.input_window - self.output_window + 1\n",
    "\n",
    "                for i in range(num_sequences):\n",
    "                    input_start = i\n",
    "                    input_end = i + self.input_window\n",
    "                    \n",
    "                    target_start = input_start + 1\n",
    "                    target_end = input_end + 1\n",
    "\n",
    "                    seq_in_ = [seq_in[input_start:input_end]]\n",
    "                    if include_text:\n",
    "                        seq_in_.append(embs[input_start:input_end])\n",
    "\n",
    "                    seq_in_ = th.cat(seq_in_, dim=1)\n",
    "                    seq_tgt_ = seq_tgt[target_start:target_end]\n",
    "                    self.sequences.append((seq_in_, seq_tgt_, th.tensor([[_i_df, input_start, target_end]])))\n",
    "\n",
    "    def embed_text(self, list_list_texts):\n",
    "        return embed_text(self, list_list_texts, apply_pca=self.apply_pca)\n",
    "    \n",
    "    def save_dataset(self, filepath):\n",
    "        pickle.dump([self.sequences, self.sequences_raw, self.sequences_raw_embs, \n",
    "                     self.unique_embs, self.unique_embs_pca], open(filepath, 'wb'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence, target_sequence, idx, = self.sequences[idx]\n",
    "        return input_sequence, target_sequence, idx\n",
    "\n",
    "    def get_sequence_from_index(self, index, embed_with_empty=False):\n",
    "        i_company, i_start, _ = index.squeeze().tolist()\n",
    "        seq = seq_vals = self.sequences_raw[i_company][i_start:].unsqueeze(0)\n",
    "        len_seq = seq.shape[1]\n",
    "        \n",
    "        if self.unique_embs:\n",
    "            if embed_with_empty:\n",
    "                unique_embs = self.unique_embs_pca if self.apply_pca else self.unique_embs\n",
    "                seq_emb = unique_embs[''].to(th.float32).unsqueeze(0).repeat(1, len_seq, 1)\n",
    "            else:\n",
    "                seq_emb = self.sequences_raw_embs[i_company][i_start:].unsqueeze(0)\n",
    "            seq = th.cat((seq_vals, seq_emb), dim=2)\n",
    "        return seq\n",
    "\n",
    "    def get_sequence_by_name_date(self, name, date=None, embed_with_empty=False):\n",
    "        i_company = self.names.index(name)\n",
    "        i_start = self.dates.index(date) if date else 0\n",
    "        \n",
    "        seq = seq_vals = self.sequences_raw[i_company][i_start:].unsqueeze(0)\n",
    "        len_seq = seq.shape[1]\n",
    "        \n",
    "        if self.unique_embs:\n",
    "            if embed_with_empty:\n",
    "                unique_embs = self.unique_embs_pca if self.apply_pca else self.unique_embs\n",
    "                seq_emb = unique_embs[''].to(th.float32).unsqueeze(0).repeat(1, len_seq, 1)\n",
    "            else:\n",
    "                seq_emb = self.sequences_raw_embs[i_company][i_start:].unsqueeze(0)\n",
    "            seq = th.cat((seq_vals, seq_emb), dim=2)\n",
    "        return seq\n",
    "        \n",
    "    def get_sequences_from_index(self, index, n_future_steps=7, input_window=30, embed_with_empty=False):\n",
    "        i_company, i_start, _ = index.squeeze().tolist()\n",
    "        \n",
    "        seq_raw = self.sequences_raw[i_company]\n",
    "        len_seq_raw = seq_raw.shape[0]\n",
    "        \n",
    "        seqs = []\n",
    "        for t in range(n_future_steps):\n",
    "            _i_start = i_start + t + 1\n",
    "            if _i_start + input_window > len_seq_raw:\n",
    "                break\n",
    "            _i_end = _i_start + input_window\n",
    "            \n",
    "            seq = seq_vals = seq_raw[_i_start:_i_end].unsqueeze(0)\n",
    "    \n",
    "            if self.unique_embs:\n",
    "                if embed_with_empty:\n",
    "                    unique_embs = self.unique_embs_pca if self.apply_pca else self.unique_embs\n",
    "                    seq_emb = unique_embs[''].to(th.float32).unsqueeze(0).repeat(1, input_window, 1)\n",
    "                else:\n",
    "                    seq_emb = self.sequences_raw_embs[i_company][_i_start:_i_end].unsqueeze(0)\n",
    "                seq = th.cat((seq_vals, seq_emb), dim=2)\n",
    "            seqs.append(seq)\n",
    "\n",
    "        seqs = th.cat(seqs, dim=0).unsqueeze(0)\n",
    "        return seqs\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def input_dim(self):\n",
    "        return self.sequences[0][0].shape[-1]\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.sequences[0][1].shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "aee39dc9-6247-402c-a477-04f6c27effd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 30, 4])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.__class__.get_sequences_from_index = get_sequences_from_index\n",
    "th.cat(dataset_train.get_sequences_from_index(th.tensor([0, 0, 0])), dim=0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a56acb3-cb7a-44cf-80ed-86674f097ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging tool: ignore\n",
    "def reduce(x, apply=False):\n",
    "    if apply:\n",
    "        return th.linalg.norm(x) \n",
    "    return x\n",
    "    \n",
    "def inspect_model(model, save_data=False, apply_reduce=False, show_grad=True):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"Layer: {name}\")\n",
    "            print(\"Weights:\",reduce(param.data, apply_reduce))\n",
    "            if isinstance(save_data, dict):\n",
    "                save_data.setdefault('w', {})[name] = param.data\n",
    "                save_data.setdefault('g', {})[name] = param.grad\n",
    "            if show_grad:\n",
    "                if param.grad is not None:\n",
    "                    print(\"Gradients:\", reduce(param.grad, apply_reduce))\n",
    "                else:\n",
    "                    print(\"Gradients: None (check if backward has been called and if the parameter requires gradients)\")\n",
    "            #break\n",
    "            print('-'*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5bc09",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3ad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(DATA, open(FILEPATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff53ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = pickle.load(open(FILEPATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8aa6b5",
   "metadata": {},
   "source": [
    "## Important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b651401",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window = seq_length = 30  # e.g., 5 days input\n",
    "output_window = 1  # e.g., 2 days to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789a8b0",
   "metadata": {},
   "source": [
    "## Fake Data (no longer valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9d776c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# # Example fake data generation\n",
    "\n",
    "# np.random.seed(42)\n",
    "# data_length = 10\n",
    "# df1 = pd.DataFrame({\n",
    "#     'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "#     'price_main': np.random.rand(data_length) * 100,\n",
    "#     'price_sec': np.random.rand(data_length) * 1000,\n",
    "#     'text': np.random.choice(['news', '', 'alert', 'none'], data_length)\n",
    "# })\n",
    "\n",
    "# df2 = pd.DataFrame({\n",
    "#     'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "#     'price_main': np.random.rand(data_length) * 100,\n",
    "#     'price_sec': np.random.rand(data_length) * 1000,\n",
    "#     'text': np.random.choice(['announcement', 'report', 'alert', 'none'], data_length)\n",
    "# })\n",
    "\n",
    "# dataframes = [df1, df2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ed7fc",
   "metadata": {},
   "source": [
    "* you will need to replace this with your own data\n",
    "* each df relates to a company\n",
    "* additionally, normalise your company's price data from 0 to 1\n",
    "* the stock prices should be normalised the same way across all companies\n",
    "* here 'price_main' and 'price_sec' represents 'stock' and 'stock index'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d82fb",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09afb9",
   "metadata": {},
   "source": [
    "* the dataset generator can be used to make data for different model architecture...\n",
    "* you can have it predict from stock and index price, and output in stock price... you can also include index price in the output... adjust the output_prices accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f282a78-ba1d-4f03-a6e6-c2c2b5269b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_stock_indices = ['close_nasdaq_composite', 'close_sp_500', 'close_dow_jones']\n",
    "\n",
    "input_prices = ['close'] + name_stock_indices\n",
    "output_prices = ['close'] + name_stock_indices\n",
    "text_column = None  #'Text'\n",
    "\n",
    "apply_pca = 10  # only relevant when there are text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9cf4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (total): Train: 8320 & Test: 1850\n",
      "Dataset size (per company): Train: 862 & Test: 215\n"
     ]
    }
   ],
   "source": [
    "dataset_train = StockDataset(dfs_train, \n",
    "                             input_window, output_window, \n",
    "                             input_prices=input_prices, output_prices=output_prices, include_text=text_column,\n",
    "                             apply_pca=apply_pca)\n",
    "dataset_test = StockDataset(dfs_test, \n",
    "                            input_window, output_window, \n",
    "                            input_prices=input_prices, output_prices=output_prices, include_text=text_column,\n",
    "                            apply_pca=apply_pca)\n",
    "\n",
    "n_train = len(dataset_train)\n",
    "n_test = len(dataset_test)\n",
    "print(\"Dataset size (total): Train: {} & Test: {}\".format(n_train, n_test))\n",
    "print(\"Dataset size (per company): Train: {} & Test: {}\".format(n_train_per_company, n_test_per_company))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91330b10-a3e3-4d62-ba5a-f4d980ed3aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.014, 0.225, 0.331, 0.473],\n",
       "         [0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         ...,\n",
       "         [0.475, 0.651, 0.657, 0.682],\n",
       "         [0.492, 0.666, 0.678, 0.715],\n",
       "         [0.502, 0.665, 0.675, 0.706]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on how to get particular subsequence for date and company:\n",
    "dataset_train.get_sequence_by_name_date('tesla', '2020-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b351ec5-58f2-49ce-a8d3-ca36703db457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 857, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on how to get particular subsequence based on stored index:\n",
    "dataset_train.get_sequence_from_index(th.tensor([0, 5, 0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b724022e-471f-404f-866a-d12ceecfb905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.014, 0.225, 0.331, 0.473],\n",
       "         [0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         [0.023, 0.237, 0.337, 0.479],\n",
       "         [0.021, 0.245, 0.344, 0.489],\n",
       "         [0.020, 0.242, 0.341, 0.482],\n",
       "         [0.028, 0.252, 0.348, 0.486],\n",
       "         [0.031, 0.250, 0.347, 0.488],\n",
       "         [0.027, 0.250, 0.349, 0.492],\n",
       "         [0.026, 0.261, 0.358, 0.505],\n",
       "         [0.026, 0.264, 0.362, 0.507],\n",
       "         [0.032, 0.262, 0.359, 0.500],\n",
       "         [0.036, 0.263, 0.359, 0.499],\n",
       "         [0.036, 0.265, 0.361, 0.498],\n",
       "         [0.035, 0.256, 0.351, 0.490],\n",
       "         [0.034, 0.238, 0.334, 0.469],\n",
       "         [0.036, 0.251, 0.344, 0.478],\n",
       "         [0.038, 0.252, 0.343, 0.478],\n",
       "         [0.048, 0.254, 0.347, 0.484],\n",
       "         [0.050, 0.239, 0.328, 0.456],\n",
       "         [0.072, 0.252, 0.335, 0.462],\n",
       "         [0.091, 0.272, 0.351, 0.482],\n",
       "         [0.065, 0.276, 0.364, 0.504],\n",
       "         [0.067, 0.283, 0.367, 0.508],\n",
       "         [0.067, 0.278, 0.361, 0.495],\n",
       "         [0.071, 0.289, 0.369, 0.504],\n",
       "         [0.071, 0.290, 0.371, 0.504],\n",
       "         [0.070, 0.299, 0.379, 0.517],\n",
       "         [0.076, 0.298, 0.377, 0.511],\n",
       "         [0.076, 0.300, 0.379, 0.509]]),\n",
       " tensor([[0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         [0.023, 0.237, 0.337, 0.479],\n",
       "         [0.021, 0.245, 0.344, 0.489],\n",
       "         [0.020, 0.242, 0.341, 0.482],\n",
       "         [0.028, 0.252, 0.348, 0.486],\n",
       "         [0.031, 0.250, 0.347, 0.488],\n",
       "         [0.027, 0.250, 0.349, 0.492],\n",
       "         [0.026, 0.261, 0.358, 0.505],\n",
       "         [0.026, 0.264, 0.362, 0.507],\n",
       "         [0.032, 0.262, 0.359, 0.500],\n",
       "         [0.036, 0.263, 0.359, 0.499],\n",
       "         [0.036, 0.265, 0.361, 0.498],\n",
       "         [0.035, 0.256, 0.351, 0.490],\n",
       "         [0.034, 0.238, 0.334, 0.469],\n",
       "         [0.036, 0.251, 0.344, 0.478],\n",
       "         [0.038, 0.252, 0.343, 0.478],\n",
       "         [0.048, 0.254, 0.347, 0.484],\n",
       "         [0.050, 0.239, 0.328, 0.456],\n",
       "         [0.072, 0.252, 0.335, 0.462],\n",
       "         [0.091, 0.272, 0.351, 0.482],\n",
       "         [0.065, 0.276, 0.364, 0.504],\n",
       "         [0.067, 0.283, 0.367, 0.508],\n",
       "         [0.067, 0.278, 0.361, 0.495],\n",
       "         [0.071, 0.289, 0.369, 0.504],\n",
       "         [0.071, 0.290, 0.371, 0.504],\n",
       "         [0.070, 0.299, 0.379, 0.517],\n",
       "         [0.076, 0.298, 0.377, 0.511],\n",
       "         [0.076, 0.300, 0.379, 0.509],\n",
       "         [0.086, 0.300, 0.376, 0.502]]),\n",
       " tensor([[ 0,  1, 32]]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf4ff1-4819-4b23-b2b1-c3650257a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is text... there will be an embedding corresponding to empty/no text:\n",
    "dataset.unique_embs_pca[''].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save\n",
    "# dataset_train.save_dataset('file_name.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "0135a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = StockDataset('file_name.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fa323",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "8b418dda-ad0d-4a90-804f-608100b7901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 30, 4])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "561e9711-f882-4fae-8fe5-dec0bb1686a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_autoreg_out = model.autoregress(output, 3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "43776388-8546-4681-8c1c-383872316f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 30, 3, 4])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _autoreg_out = [_res[1] for _res in _autoreg_out]\n",
    "th.stack(_autoreg_out, dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "82d2adb2-a424-4df5-9544-0fa40e698347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def eval_autoregress(model, output, target, criterion):\n",
    "    output = th.stack(output, dim=2)\n",
    "    target = th.stack(target, dim=2)\n",
    "    loss = criterion(output, target)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e27257-1b63-459c-aef2-ceafdd14d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def autoregressive_predict_with_eval(model, initial_sequence,\n",
    "#                                      indices, dataset, n_future_steps,\n",
    "#                                      mode='eval', output_time=False):\n",
    "    \n",
    "#     tgt_p_s_p_data = [dataset.get_sequences_from_index(_idx, n_future_steps=n_future_steps) for _idx in idx]\n",
    "#     steps_min = min([_tgt.shape[1] for _tgt in tgt_p_s_p_data])\n",
    "\n",
    "    \n",
    "#     tgt = th.cat([_tgt[:,:steps_min,:,:] for _tgt in tgt_p_s_p_data], dim=0)\n",
    "\n",
    "#     # truth??\n",
    "#     seq_future, seq_p_s = model.autoregressive_predict(model, initial_sequence, n_future_steps=steps_min, \n",
    "#                                                        truth=None, mode=mode, output_time=False)\n",
    "\n",
    "#     out = th.stack(seq_p_s, dim=2)\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0bf3ee02-b675-412e-96ef-4c473bb9c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def autoregressive_predict(model, initial_sequence, n_future_steps, truth=None, \n",
    "                           mode='eval', output_time=True):\n",
    "                           #with_text_embed=None):\n",
    "    \"\"\"\n",
    "    Predict 'future_steps' into the future based on the 'initial_sequence' using the provided model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained time series forecasting model.\n",
    "        initial_sequence (torch.Tensor): The initial data sequence used for the first prediction, shape [1, seq_length, 1].\n",
    "        future_steps (int): Number of future steps to predict.\n",
    "\n",
    "        with_test_embed: text embedding: 2 options\n",
    "          'empty': always feed in 'empty' for future\n",
    "          'truth': feed in entire sequence of embedding beginning with first time step of input token\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Predicted values for 'future_steps', shape [1, future_steps, 1].\n",
    "    \"\"\"\n",
    "    _ = model.eval() if mode == 'eval' else model.train()\n",
    "\n",
    "    if initial_sequence.dim() == 1:\n",
    "        initial_sequence = initial_sequence.unsqueeze(0).unsqueeze(2)\n",
    "    elif initial_sequence.dim() == 2:\n",
    "        initial_sequence = initial_sequence.unsqueeze(0)\n",
    "    current_sequence = initial_sequence.clone().detach()\n",
    "        \n",
    "    dim_truth = 0\n",
    "    dim_in = initial_sequence.shape[-1]\n",
    "    if truth is not None:\n",
    "        dim_truth = truth.shape[-1]\n",
    "        \n",
    "    len_inp = initial_sequence.shape[1]\n",
    "    t = th.arange(len_inp).reshape(len_inp)\n",
    "    #print('seq len: {} // dim in: {}'.format(len_inp, dim_in))\n",
    "    \n",
    "    all_sequences = []\n",
    "    predictions = []\n",
    "    \n",
    "    for step in range(n_future_steps):\n",
    "        # Predict the next step\n",
    "        with torch.no_grad():\n",
    "            next_value = model(current_sequence)\n",
    "        dim_out = next_value.shape[-1]\n",
    "        \n",
    "        # Append the prediction\n",
    "        predictions.append(next_value[:, -1, :].unsqueeze(1))\n",
    "    \n",
    "        # Update the current sequence for the next prediction\n",
    "        if dim_out < dim_in:\n",
    "            assert truth is not None # make sure truth is provided when output dim is different than input dim\n",
    "            _next_value = next_value[:,-1,:].unsqueeze(1)\n",
    "            _next_value_truth = truth[:, len_inp + step: len_inp + step + 1, dim_out:]\n",
    "            #print(_next_value.shape, _next_value_truth.shape)\n",
    "            next_value = th.cat((_next_value, _next_value_truth), dim=2)\n",
    "            current_sequence = torch.cat((current_sequence[:,1:,:], next_value), dim=1)\n",
    "        else:\n",
    "            a, b = (current_sequence[:, 1:, :], next_value[:, -1, :input_dim].unsqueeze(1))\n",
    "            current_sequence = torch.cat((a, b), dim=1)\n",
    "\n",
    "        out = (t + step + 1, current_sequence) if output_time else current_sequence\n",
    "        all_sequences.append(out)\n",
    "    \n",
    "    return torch.cat(predictions, dim=1), all_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc403cd-760d-4e17-a95c-159e501064d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, num_layers, dropout=0.1, apply_input_mask=None):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Separate embeddings for input and output dimensions\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.output_linear = nn.Linear(d_model, output_dim)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.apply_input_mask = apply_input_mask\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=4,  # Adjust number of heads as needed\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        if model.training and self.apply_input_mask is not None:  # look ahead mask; for transformer\n",
    "            input_window = src.shape[1]\n",
    "            n_tks_to_mask = randint(*self.apply_input_mask)\n",
    "            mask = torch.ones(input_window, input_window).triu(diagonal=n_tks_to_mask)\n",
    " \n",
    "        # src shape expected: [batch_size, seq_length, input_dim]\n",
    "        src = self.input_linear(src)  # Transform input to feature space\n",
    "        src *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))  # Scale input\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)  # Pass through transformer\n",
    "        output = self.output_linear(output)  # Map output to the target dimension\n",
    "        return output\n",
    "\n",
    "    autoregress = autoregressive_predict\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "        self.batch_first = batch_first\n",
    "        if batch_first:\n",
    "            pe = torch.zeros(1, max_len, d_model) # batch_first\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        else:\n",
    "            pe = torch.zeros(max_len, 1, d_model) # batch_first\n",
    "            pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "            pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:,:x.size(1),:]\n",
    "        else:\n",
    "            x = x + self.pe[x.size(0),:,:]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a66e64-2270-42ec-aa38-38f31e7d2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, d_model=50, num_layers=2):\n",
    "        super(TimeSeriesLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, d_model, batch_first=True, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "    def forward(self, x, **kwargs):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "    autoregress = autoregressive_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b9f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# class TimeSeriesTransformer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "#         super(TimeSeriesTransformer, self).__init__()\n",
    "#         self.input_linear = nn.Linear(input_dim, d_model)\n",
    "#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "#         encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "#         self.output_linear = nn.Linear(d_model, output_dim)\n",
    "\n",
    "#     def forward(self, src):\n",
    "#         #print(src.dtype)\n",
    "#         src = self.input_linear(src)  # [batch_size, seq_len, d_model]\n",
    "#         src = self.pos_encoder(src)\n",
    "#         output = self.transformer_encoder(src)\n",
    "#         output = self.output_linear(output)\n",
    "#         return output\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         for name, param in self.named_parameters():\n",
    "#             if 'weight' in name:\n",
    "#                 if param.dim() > 1:\n",
    "#                     nn.init.kaiming_normal_(param, mode='fan_out', nonlinearity='relu')\n",
    "#                 elif 'norm' in name:\n",
    "#                     nn.init.constant_(param, 1)\n",
    "#             elif 'bias' in name:\n",
    "#                 nn.init.constant_(param, 0)\n",
    "\n",
    "#         # Optionally set a different initialization for embeddings if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5046c",
   "metadata": {},
   "source": [
    "## Key Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9d94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc0a8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = dataset_train.input_dim # dim_1\n",
    "output_dim = dataset_train.output_dim   # dim_2\n",
    "d_model = 32  # Size of the embedding\n",
    "\n",
    "model_type = 'transformer' # or 'lstm'\n",
    "\n",
    "# for both models\n",
    "num_layers = 3\n",
    "\n",
    "# only for transformers\n",
    "apply_input_mask = (2, 5) # make sure upper limit is lower than input_window\n",
    "dim_feedforward = 256\n",
    "nhead = 4\n",
    "\n",
    "if model_type == 'lstm':\n",
    "    learning_rate = 0.01\n",
    "elif model_type == 'transformer':\n",
    "    learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d3dbbe3-ce6b-4c0d-8be2-42bfe1bec630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dim: input 4 output 4\n"
     ]
    }
   ],
   "source": [
    "print('Current dim: input {} output {}'.format(input_dim, output_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5505f",
   "metadata": {},
   "source": [
    "\n",
    "### Create fake model & data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b12d2575-9786-40ef-bc56-7bd8732fc0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "  tensor([[[0.625, 0.645, 0.676, 0.693],\n",
       "           [0.610, 0.697, 0.671, 0.702],\n",
       "           [0.640, 0.703, 0.697, 0.729],\n",
       "           ...,\n",
       "           [0.605, 0.760, 0.751, 0.766],\n",
       "           [0.606, 0.799, 0.770, 0.767],\n",
       "           [0.610, 0.785, 0.754, 0.775]],\n",
       "  \n",
       "          [[0.687, 0.477, 0.554, 0.597],\n",
       "           [0.708, 0.492, 0.559, 0.606],\n",
       "           [0.694, 0.506, 0.562, 0.617],\n",
       "           ...,\n",
       "           [0.611, 0.407, 0.468, 0.517],\n",
       "           [0.571, 0.379, 0.443, 0.520],\n",
       "           [0.580, 0.380, 0.444, 0.515]],\n",
       "  \n",
       "          [[0.153, 0.462, 0.387, 0.453],\n",
       "           [0.168, 0.449, 0.390, 0.440],\n",
       "           [0.154, 0.409, 0.365, 0.419],\n",
       "           ...,\n",
       "           [0.171, 0.514, 0.411, 0.479],\n",
       "           [0.174, 0.514, 0.421, 0.482],\n",
       "           [0.174, 0.509, 0.416, 0.483]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.691, 0.688, 0.584, 0.676],\n",
       "           [0.719, 0.690, 0.576, 0.679],\n",
       "           [0.702, 0.672, 0.577, 0.696],\n",
       "           ...,\n",
       "           [0.635, 0.742, 0.638, 0.745],\n",
       "           [0.635, 0.765, 0.651, 0.742],\n",
       "           [0.643, 0.758, 0.643, 0.743]],\n",
       "  \n",
       "          [[0.651, 0.743, 0.653, 0.729],\n",
       "           [0.615, 0.733, 0.637, 0.741],\n",
       "           [0.606, 0.714, 0.639, 0.731],\n",
       "           ...,\n",
       "           [0.622, 0.737, 0.654, 0.753],\n",
       "           [0.632, 0.750, 0.669, 0.764],\n",
       "           [0.632, 0.747, 0.670, 0.767]],\n",
       "  \n",
       "          [[0.381, 0.680, 0.689, 0.706],\n",
       "           [0.283, 0.620, 0.644, 0.690],\n",
       "           [0.297, 0.642, 0.648, 0.698],\n",
       "           ...,\n",
       "           [0.469, 0.686, 0.714, 0.752],\n",
       "           [0.510, 0.721, 0.744, 0.762],\n",
       "           [0.505, 0.721, 0.738, 0.767]]])),\n",
       " (tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "          20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       "  tensor([[[0.610, 0.697, 0.671, 0.702],\n",
       "           [0.640, 0.703, 0.697, 0.729],\n",
       "           [0.632, 0.709, 0.696, 0.719],\n",
       "           ...,\n",
       "           [0.606, 0.799, 0.770, 0.767],\n",
       "           [0.610, 0.785, 0.754, 0.775],\n",
       "           [0.613, 0.779, 0.750, 0.781]],\n",
       "  \n",
       "          [[0.708, 0.492, 0.559, 0.606],\n",
       "           [0.694, 0.506, 0.562, 0.617],\n",
       "           [0.717, 0.525, 0.603, 0.655],\n",
       "           ...,\n",
       "           [0.571, 0.379, 0.443, 0.520],\n",
       "           [0.580, 0.380, 0.444, 0.515],\n",
       "           [0.586, 0.380, 0.441, 0.509]],\n",
       "  \n",
       "          [[0.168, 0.449, 0.390, 0.440],\n",
       "           [0.154, 0.409, 0.365, 0.419],\n",
       "           [0.168, 0.435, 0.383, 0.450],\n",
       "           ...,\n",
       "           [0.174, 0.514, 0.421, 0.482],\n",
       "           [0.174, 0.509, 0.416, 0.483],\n",
       "           [0.174, 0.507, 0.415, 0.484]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.719, 0.690, 0.576, 0.679],\n",
       "           [0.702, 0.672, 0.577, 0.696],\n",
       "           [0.678, 0.674, 0.558, 0.671],\n",
       "           ...,\n",
       "           [0.635, 0.765, 0.651, 0.742],\n",
       "           [0.643, 0.758, 0.643, 0.743],\n",
       "           [0.651, 0.754, 0.641, 0.743]],\n",
       "  \n",
       "          [[0.615, 0.733, 0.637, 0.741],\n",
       "           [0.606, 0.714, 0.639, 0.731],\n",
       "           [0.606, 0.697, 0.631, 0.736],\n",
       "           ...,\n",
       "           [0.632, 0.750, 0.669, 0.764],\n",
       "           [0.632, 0.747, 0.670, 0.767],\n",
       "           [0.633, 0.745, 0.671, 0.769]],\n",
       "  \n",
       "          [[0.283, 0.620, 0.644, 0.690],\n",
       "           [0.297, 0.642, 0.648, 0.698],\n",
       "           [0.333, 0.677, 0.687, 0.717],\n",
       "           ...,\n",
       "           [0.510, 0.721, 0.744, 0.762],\n",
       "           [0.505, 0.721, 0.738, 0.767],\n",
       "           [0.502, 0.724, 0.740, 0.771]]])),\n",
       " (tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "          21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
       "  tensor([[[0.640, 0.703, 0.697, 0.729],\n",
       "           [0.632, 0.709, 0.696, 0.719],\n",
       "           [0.606, 0.690, 0.689, 0.723],\n",
       "           ...,\n",
       "           [0.610, 0.785, 0.754, 0.775],\n",
       "           [0.613, 0.779, 0.750, 0.781],\n",
       "           [0.617, 0.775, 0.749, 0.784]],\n",
       "  \n",
       "          [[0.694, 0.506, 0.562, 0.617],\n",
       "           [0.717, 0.525, 0.603, 0.655],\n",
       "           [0.726, 0.550, 0.597, 0.638],\n",
       "           ...,\n",
       "           [0.580, 0.380, 0.444, 0.515],\n",
       "           [0.586, 0.380, 0.441, 0.509],\n",
       "           [0.590, 0.380, 0.438, 0.505]],\n",
       "  \n",
       "          [[0.154, 0.409, 0.365, 0.419],\n",
       "           [0.168, 0.435, 0.383, 0.450],\n",
       "           [0.148, 0.436, 0.367, 0.426],\n",
       "           ...,\n",
       "           [0.174, 0.509, 0.416, 0.483],\n",
       "           [0.174, 0.507, 0.415, 0.484],\n",
       "           [0.175, 0.506, 0.415, 0.485]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.702, 0.672, 0.577, 0.696],\n",
       "           [0.678, 0.674, 0.558, 0.671],\n",
       "           [0.668, 0.687, 0.582, 0.668],\n",
       "           ...,\n",
       "           [0.643, 0.758, 0.643, 0.743],\n",
       "           [0.651, 0.754, 0.641, 0.743],\n",
       "           [0.658, 0.752, 0.640, 0.743]],\n",
       "  \n",
       "          [[0.606, 0.714, 0.639, 0.731],\n",
       "           [0.606, 0.697, 0.631, 0.736],\n",
       "           [0.601, 0.700, 0.641, 0.730],\n",
       "           ...,\n",
       "           [0.632, 0.747, 0.670, 0.767],\n",
       "           [0.633, 0.745, 0.671, 0.769],\n",
       "           [0.634, 0.744, 0.673, 0.772]],\n",
       "  \n",
       "          [[0.297, 0.642, 0.648, 0.698],\n",
       "           [0.333, 0.677, 0.687, 0.717],\n",
       "           [0.328, 0.656, 0.678, 0.706],\n",
       "           ...,\n",
       "           [0.505, 0.721, 0.738, 0.767],\n",
       "           [0.502, 0.724, 0.740, 0.771],\n",
       "           [0.499, 0.728, 0.742, 0.774]]])),\n",
       " (tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "          22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
       "  tensor([[[0.632, 0.709, 0.696, 0.719],\n",
       "           [0.606, 0.690, 0.689, 0.723],\n",
       "           [0.659, 0.725, 0.707, 0.724],\n",
       "           ...,\n",
       "           [0.613, 0.779, 0.750, 0.781],\n",
       "           [0.617, 0.775, 0.749, 0.784],\n",
       "           [0.620, 0.774, 0.749, 0.786]],\n",
       "  \n",
       "          [[0.717, 0.525, 0.603, 0.655],\n",
       "           [0.726, 0.550, 0.597, 0.638],\n",
       "           [0.691, 0.477, 0.554, 0.600],\n",
       "           ...,\n",
       "           [0.586, 0.380, 0.441, 0.509],\n",
       "           [0.590, 0.380, 0.438, 0.505],\n",
       "           [0.595, 0.379, 0.435, 0.503]],\n",
       "  \n",
       "          [[0.168, 0.435, 0.383, 0.450],\n",
       "           [0.148, 0.436, 0.367, 0.426],\n",
       "           [0.161, 0.426, 0.375, 0.421],\n",
       "           ...,\n",
       "           [0.174, 0.507, 0.415, 0.484],\n",
       "           [0.175, 0.506, 0.415, 0.485],\n",
       "           [0.175, 0.506, 0.416, 0.486]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.678, 0.674, 0.558, 0.671],\n",
       "           [0.668, 0.687, 0.582, 0.668],\n",
       "           [0.639, 0.684, 0.569, 0.665],\n",
       "           ...,\n",
       "           [0.651, 0.754, 0.641, 0.743],\n",
       "           [0.658, 0.752, 0.640, 0.743],\n",
       "           [0.665, 0.751, 0.640, 0.744]],\n",
       "  \n",
       "          [[0.606, 0.697, 0.631, 0.736],\n",
       "           [0.601, 0.700, 0.641, 0.730],\n",
       "           [0.602, 0.693, 0.635, 0.739],\n",
       "           ...,\n",
       "           [0.633, 0.745, 0.671, 0.769],\n",
       "           [0.634, 0.744, 0.673, 0.772],\n",
       "           [0.636, 0.742, 0.675, 0.774]],\n",
       "  \n",
       "          [[0.333, 0.677, 0.687, 0.717],\n",
       "           [0.328, 0.656, 0.678, 0.706],\n",
       "           [0.319, 0.646, 0.668, 0.702],\n",
       "           ...,\n",
       "           [0.502, 0.724, 0.740, 0.771],\n",
       "           [0.499, 0.728, 0.742, 0.774],\n",
       "           [0.498, 0.731, 0.745, 0.777]]])),\n",
       " (tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "          23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]),\n",
       "  tensor([[[0.606, 0.690, 0.689, 0.723],\n",
       "           [0.659, 0.725, 0.707, 0.724],\n",
       "           [0.629, 0.697, 0.697, 0.720],\n",
       "           ...,\n",
       "           [0.617, 0.775, 0.749, 0.784],\n",
       "           [0.620, 0.774, 0.749, 0.786],\n",
       "           [0.622, 0.773, 0.749, 0.787]],\n",
       "  \n",
       "          [[0.726, 0.550, 0.597, 0.638],\n",
       "           [0.691, 0.477, 0.554, 0.600],\n",
       "           [0.690, 0.496, 0.551, 0.612],\n",
       "           ...,\n",
       "           [0.590, 0.380, 0.438, 0.505],\n",
       "           [0.595, 0.379, 0.435, 0.503],\n",
       "           [0.599, 0.379, 0.433, 0.502]],\n",
       "  \n",
       "          [[0.148, 0.436, 0.367, 0.426],\n",
       "           [0.161, 0.426, 0.375, 0.421],\n",
       "           [0.162, 0.439, 0.368, 0.437],\n",
       "           ...,\n",
       "           [0.175, 0.506, 0.415, 0.485],\n",
       "           [0.175, 0.506, 0.416, 0.486],\n",
       "           [0.176, 0.507, 0.416, 0.488]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.668, 0.687, 0.582, 0.668],\n",
       "           [0.639, 0.684, 0.569, 0.665],\n",
       "           [0.630, 0.635, 0.559, 0.657],\n",
       "           ...,\n",
       "           [0.658, 0.752, 0.640, 0.743],\n",
       "           [0.665, 0.751, 0.640, 0.744],\n",
       "           [0.671, 0.750, 0.641, 0.745]],\n",
       "  \n",
       "          [[0.601, 0.700, 0.641, 0.730],\n",
       "           [0.602, 0.693, 0.635, 0.739],\n",
       "           [0.622, 0.713, 0.651, 0.750],\n",
       "           ...,\n",
       "           [0.634, 0.744, 0.673, 0.772],\n",
       "           [0.636, 0.742, 0.675, 0.774],\n",
       "           [0.637, 0.742, 0.676, 0.776]],\n",
       "  \n",
       "          [[0.328, 0.656, 0.678, 0.706],\n",
       "           [0.319, 0.646, 0.668, 0.702],\n",
       "           [0.318, 0.624, 0.665, 0.694],\n",
       "           ...,\n",
       "           [0.499, 0.728, 0.742, 0.774],\n",
       "           [0.498, 0.731, 0.745, 0.777],\n",
       "           [0.497, 0.734, 0.747, 0.779]]])),\n",
       " (tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "          24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]),\n",
       "  tensor([[[0.659, 0.725, 0.707, 0.724],\n",
       "           [0.629, 0.697, 0.697, 0.720],\n",
       "           [0.593, 0.685, 0.678, 0.707],\n",
       "           ...,\n",
       "           [0.620, 0.774, 0.749, 0.786],\n",
       "           [0.622, 0.773, 0.749, 0.787],\n",
       "           [0.625, 0.773, 0.751, 0.789]],\n",
       "  \n",
       "          [[0.691, 0.477, 0.554, 0.600],\n",
       "           [0.690, 0.496, 0.551, 0.612],\n",
       "           [0.679, 0.475, 0.539, 0.581],\n",
       "           ...,\n",
       "           [0.595, 0.379, 0.435, 0.503],\n",
       "           [0.599, 0.379, 0.433, 0.502],\n",
       "           [0.603, 0.378, 0.431, 0.502]],\n",
       "  \n",
       "          [[0.161, 0.426, 0.375, 0.421],\n",
       "           [0.162, 0.439, 0.368, 0.437],\n",
       "           [0.166, 0.452, 0.375, 0.448],\n",
       "           ...,\n",
       "           [0.175, 0.506, 0.416, 0.486],\n",
       "           [0.176, 0.507, 0.416, 0.488],\n",
       "           [0.176, 0.508, 0.417, 0.489]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.639, 0.684, 0.569, 0.665],\n",
       "           [0.630, 0.635, 0.559, 0.657],\n",
       "           [0.648, 0.643, 0.548, 0.661],\n",
       "           ...,\n",
       "           [0.665, 0.751, 0.640, 0.744],\n",
       "           [0.671, 0.750, 0.641, 0.745],\n",
       "           [0.676, 0.749, 0.643, 0.747]],\n",
       "  \n",
       "          [[0.602, 0.693, 0.635, 0.739],\n",
       "           [0.622, 0.713, 0.651, 0.750],\n",
       "           [0.579, 0.669, 0.635, 0.737],\n",
       "           ...,\n",
       "           [0.636, 0.742, 0.675, 0.774],\n",
       "           [0.637, 0.742, 0.676, 0.776],\n",
       "           [0.639, 0.741, 0.677, 0.777]],\n",
       "  \n",
       "          [[0.319, 0.646, 0.668, 0.702],\n",
       "           [0.318, 0.624, 0.665, 0.694],\n",
       "           [0.351, 0.674, 0.690, 0.741],\n",
       "           ...,\n",
       "           [0.498, 0.731, 0.745, 0.777],\n",
       "           [0.497, 0.734, 0.747, 0.779],\n",
       "           [0.496, 0.736, 0.749, 0.782]]])),\n",
       " (tensor([ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "          25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]),\n",
       "  tensor([[[0.629, 0.697, 0.697, 0.720],\n",
       "           [0.593, 0.685, 0.678, 0.707],\n",
       "           [0.571, 0.636, 0.665, 0.684],\n",
       "           ...,\n",
       "           [0.622, 0.773, 0.749, 0.787],\n",
       "           [0.625, 0.773, 0.751, 0.789],\n",
       "           [0.627, 0.773, 0.752, 0.790]],\n",
       "  \n",
       "          [[0.690, 0.496, 0.551, 0.612],\n",
       "           [0.679, 0.475, 0.539, 0.581],\n",
       "           [0.668, 0.467, 0.521, 0.582],\n",
       "           ...,\n",
       "           [0.599, 0.379, 0.433, 0.502],\n",
       "           [0.603, 0.378, 0.431, 0.502],\n",
       "           [0.607, 0.378, 0.430, 0.501]],\n",
       "  \n",
       "          [[0.162, 0.439, 0.368, 0.437],\n",
       "           [0.166, 0.452, 0.375, 0.448],\n",
       "           [0.157, 0.446, 0.374, 0.440],\n",
       "           ...,\n",
       "           [0.176, 0.507, 0.416, 0.488],\n",
       "           [0.176, 0.508, 0.417, 0.489],\n",
       "           [0.177, 0.509, 0.419, 0.491]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.630, 0.635, 0.559, 0.657],\n",
       "           [0.648, 0.643, 0.548, 0.661],\n",
       "           [0.669, 0.666, 0.578, 0.693],\n",
       "           ...,\n",
       "           [0.671, 0.750, 0.641, 0.745],\n",
       "           [0.676, 0.749, 0.643, 0.747],\n",
       "           [0.681, 0.749, 0.644, 0.748]],\n",
       "  \n",
       "          [[0.622, 0.713, 0.651, 0.750],\n",
       "           [0.579, 0.669, 0.635, 0.737],\n",
       "           [0.585, 0.692, 0.642, 0.745],\n",
       "           ...,\n",
       "           [0.637, 0.742, 0.676, 0.776],\n",
       "           [0.639, 0.741, 0.677, 0.777],\n",
       "           [0.640, 0.741, 0.678, 0.779]],\n",
       "  \n",
       "          [[0.318, 0.624, 0.665, 0.694],\n",
       "           [0.351, 0.674, 0.690, 0.741],\n",
       "           [0.418, 0.696, 0.695, 0.727],\n",
       "           ...,\n",
       "           [0.497, 0.734, 0.747, 0.779],\n",
       "           [0.496, 0.736, 0.749, 0.782],\n",
       "           [0.496, 0.737, 0.750, 0.784]]]))]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.autoregress(output, 7)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b98d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (input_linear): Linear(in_features=4, out_features=32, bias=True)\n",
       "  (output_linear): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing \n",
      "testing autoregress...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.207, -0.384,  0.044, -0.911],\n",
       "         [ 0.157, -0.028, -0.053, -0.753],\n",
       "         [ 0.016,  0.095,  0.057, -0.460],\n",
       "         [-0.126,  0.029,  0.164, -0.384],\n",
       "         [-0.109, -0.025,  0.142, -0.491],\n",
       "         [-0.039,  0.013,  0.100, -0.587],\n",
       "         [ 0.004,  0.076,  0.069, -0.590]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 4]) torch.Size([1, 30, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model Test\n",
    "if model_type == 'transformer':\n",
    "    model = TimeSeriesTransformer(input_dim, output_dim, d_model, num_layers, apply_input_mask = apply_input_mask)\n",
    "elif model_type == 'lstm':\n",
    "    model  = TimeSeriesLSTM(input_dim, output_dim, d_model, num_layers)\n",
    "\n",
    "# Forward pass with dummy data\n",
    "# input_data = torch.randn(8, seq_length, input_dim)  \n",
    "# target_data = torch.randn(8, seq_length, input_dim)  \n",
    "# Forward pass with real data\n",
    "input_data = dataset_train[0][0].unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "print ('testing ')\n",
    "output = model(input_data)\n",
    "print ('testing autoregress...')\n",
    "model.autoregress(output, 7)[0]\n",
    "print(input_data.shape, output.shape)  # Should be torch.Size([batch_size, seq_len, output_dim])\n",
    "\n",
    "# model.init_weights()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf26a0",
   "metadata": {},
   "source": [
    "# Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8860374e-69c1-46ed-9096-ee00422cf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loss\n",
    "# symmetrical mean absolute percentage error\n",
    "def SMAPELoss(output, target,tol=1e-4):\n",
    "    denominator = (torch.abs(target) + torch.abs(output) + tol) / 2\n",
    "    diff = torch.abs(output - target) / denominator\n",
    "    diff[denominator == 0] = 0.0  # Handle the case to avoid division by zero\n",
    "    smape = torch.mean(diff)\n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d02bb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24   # make bigger\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39151773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8169b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SMAPELoss\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd249366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.3948916176796993, Testing Loss: 0.050449474896122885\n",
      "Epoch 2, Training Loss: 0.11336063800347333, Testing Loss: 0.03724119913848964\n",
      "Epoch 3, Training Loss: 0.08759794328254082, Testing Loss: 0.03153624049351587\n",
      "Epoch 4, Training Loss: 0.07531480482547959, Testing Loss: 0.029318979614740844\n",
      "Epoch 5, Training Loss: 0.06805693382946397, Testing Loss: 0.025126178156245838\n",
      "Epoch 6, Training Loss: 0.06297628583677242, Testing Loss: 0.02346032928046468\n",
      "Epoch 7, Training Loss: 0.059298274123427495, Testing Loss: 0.021030664710061892\n",
      "Epoch 8, Training Loss: 0.05643070349200612, Testing Loss: 0.021218975219730433\n",
      "Epoch 9, Training Loss: 0.054176939317601265, Testing Loss: 0.019564155948820054\n",
      "Epoch 10, Training Loss: 0.05241748905401526, Testing Loss: 0.018236153674396603\n",
      "Epoch 11, Training Loss: 0.050883886495852744, Testing Loss: 0.017473463295632367\n",
      "Epoch 12, Training Loss: 0.0497253744383854, Testing Loss: 0.01878996563518976\n",
      "Epoch 13, Training Loss: 0.04878162368701373, Testing Loss: 0.018123905247004777\n",
      "Epoch 14, Training Loss: 0.047838164805676896, Testing Loss: 0.01689677924982139\n",
      "Epoch 15, Training Loss: 0.04699529628296291, Testing Loss: 0.018020635881981294\n",
      "Epoch 16, Training Loss: 0.046379207439634494, Testing Loss: 0.016436487690291622\n",
      "Epoch 17, Training Loss: 0.045842295458723356, Testing Loss: 0.01719962154793275\n",
      "Epoch 18, Training Loss: 0.04533819315384406, Testing Loss: 0.017404750340267436\n",
      "Epoch 19, Training Loss: 0.04501043502887377, Testing Loss: 0.01728567468945856\n",
      "Epoch 20, Training Loss: 0.044500313753079127, Testing Loss: 0.017057638917747257\n",
      "Epoch 21, Training Loss: 0.0441661583410436, Testing Loss: 0.018917014870744247\n",
      "Epoch 22, Training Loss: 0.04380683558912291, Testing Loss: 0.01564611475189011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (src, tgt, idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader_train):\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, tgt)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug_data_save:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.forward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m src \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))  \u001b[38;5;66;03m# Scale input\u001b[39;00m\n\u001b[1;32m     35\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass through transformer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear(output)  \u001b[38;5;66;03m# Map output to the target dimension\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:719\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x,\n\u001b[1;32m    716\u001b[0m                        attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    717\u001b[0m                        key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    718\u001b[0m                        need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_causal\u001b[38;5;241m=\u001b[39mis_causal)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Training and Testing Loop\n",
    "losses = {}\n",
    "\n",
    "debug_data_save = False\n",
    "data = []\n",
    "data_test = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_e_train = 0.\n",
    "    _data = [] \n",
    "    _ = model.train()\n",
    "    for batch, (src, tgt, idx) in enumerate(dataloader_train):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        \n",
    "        if debug_data_save:\n",
    "            _data.append((src, output.detach(), tgt))\n",
    "        \n",
    "        loss.backward()\n",
    "        _ = clip_grad_norm_(model.parameters(), max_norm=1.) \n",
    "        optimizer.step()\n",
    "        loss_e_train += loss.detach().item()\n",
    "\n",
    "    data.append(_data)\n",
    "    loss_e_train /= batch\n",
    "    losses.setdefault('train', {})[epoch]=loss_e_train\n",
    "    \n",
    "    loss_e_test = 0\n",
    "    _ = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (src, tgt, idx) in enumerate(dataloader_test):\n",
    "            _data = []\n",
    "            output = model(src)\n",
    "            loss = criterion(output, tgt)\n",
    "            loss_e_test += loss.item()\n",
    "            if debug_data_save:\n",
    "                _data.append((src, output.detach(), tgt))\n",
    "        data_test.append(_data)\n",
    "    loss_e_test /= batch\n",
    "    losses.setdefault('test', {})[epoch]=loss_e_test\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {loss_e_train}, Testing Loss: {loss_e_test}\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2673a73-4e53-4dc1-903b-1f33a2339f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0cdee1-e2a6-4e33-b4d1-4435cd0c2889",
   "metadata": {},
   "source": [
    "# VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2ff5c9a0-00d8-4101-8e29-8427590805d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import pow\n",
    "\n",
    "def visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth):\n",
    "    seq_to_test_truth = seq_to_test_truth[0,:,0]\n",
    "    len_seq_truth = seq_to_test_truth.shape[-1]\n",
    "    \n",
    "    seq_len_pred = len(seq_to_test_pred_per_step)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    i_truth_end = min(input_window+seq_len_pred, len_seq_truth)\n",
    "    ax.plot(th.arange(input_window).tolist(), seq_to_test_truth[:input_window], c='black')\n",
    "    ax.plot(th.arange(input_window-1,i_truth_end), seq_to_test_truth[input_window-1:i_truth_end], c='red')\n",
    "    \n",
    "    for _step, (_t, _seq) in enumerate(seq_to_test_pred_per_step):\n",
    "        _seq = _seq[0,:,:1]  # only show stock price (first dimension of output)\n",
    "        _is_future = _t >= (input_window - 1)\n",
    "        _ = ax.plot(_t[_is_future], _seq[_is_future], c='magenta', alpha=pow(0.8, _step))\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.show()\n",
    "visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f48da-a2a2-493f-8cbd-c76678c59711",
   "metadata": {},
   "source": [
    "# INSPECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3aa73-8a89-492a-8388-c9112bc34a2d",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "ef74315b-6c49-47a2-b500-3ef70443db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data point information: company: 1 & time: 99\n",
      "salesforce 2023-10-26\n"
     ]
    }
   ],
   "source": [
    "dataloader_test_shuffled = DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
    "seq_to_test = next(iter(dataloader_test_shuffled))\n",
    "#seq_to_test = dataset_test[0] # a random test dataset point\n",
    "\n",
    "n_future_steps = 10 # how many steps to forecast into the future\n",
    "use_empty_text = True   # future text is assumed to be empty if True; otherwise, use true text from future\n",
    "\n",
    "seq_to_test_idx = seq_to_test[2].squeeze() # get the index\n",
    "print(\"Test data point information: company: {} & time: {}\".format(seq_to_test_idx[0].item(), seq_to_test_idx[1].item()))\n",
    "print(dataset_test.names[seq_to_test_idx[0].item()], dataset_test.dates[seq_to_test_idx[1].item()])\n",
    "\n",
    "# get the corresponding raw data sequence from the dat/aset beginning from the start of this subsequence\n",
    "seq_to_test_truth = dataset_test.get_sequence_from_index(seq_to_test_idx, use_empty_text) \n",
    "seq_to_test_input = seq_to_test[0]\n",
    "\n",
    "#run model autoregressively\n",
    "seq_to_test_pred, seq_to_test_pred_per_step =  model.autoregress(seq_to_test_input, n_future_steps, truth=seq_to_test_truth,\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6dfcdda1-1d70-4708-bd20-0d8089074a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "f36a3af0-b5fb-49e1-a896-ac6472f85663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.386, 0.977, 0.967, 0.966],\n",
       "         [0.387, 0.967, 0.958, 0.960],\n",
       "         [0.387, 0.960, 0.953, 0.955],\n",
       "         [0.387, 0.955, 0.950, 0.951],\n",
       "         [0.386, 0.951, 0.948, 0.948],\n",
       "         [0.385, 0.947, 0.945, 0.945],\n",
       "         [0.384, 0.945, 0.944, 0.942],\n",
       "         [0.383, 0.942, 0.943, 0.940],\n",
       "         [0.381, 0.940, 0.942, 0.939],\n",
       "         [0.380, 0.937, 0.941, 0.937]]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d82ee26c-0a23-4a83-9ea7-f47cef3cf06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "  tensor([[[0.859, 0.912, 0.897, 0.933],\n",
       "           [0.865, 0.913, 0.901, 0.939],\n",
       "           [0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933]]])),\n",
       " (tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "          20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       "  tensor([[[0.865, 0.913, 0.901, 0.939],\n",
       "           [0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924]]])),\n",
       " (tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "          21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
       "  tensor([[[0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917]]])),\n",
       " (tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "          22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
       "  tensor([[[0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912]]])),\n",
       " (tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "          23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]),\n",
       "  tensor([[[0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908]]])),\n",
       " (tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "          24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]),\n",
       "  tensor([[[0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908],\n",
       "           [0.837, 0.917, 0.908, 0.904]]])),\n",
       " (tensor([ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "          25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]),\n",
       "  tensor([[[0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908],\n",
       "           [0.837, 0.917, 0.908, 0.904],\n",
       "           [0.833, 0.913, 0.905, 0.901]]]))]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_test_pred_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0dca929-dc9b-4db1-abd8-298702f50eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273f140-982f-4cc9-a041-008126c7180a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c56d05-a795-4eac-8542-009d82a4b655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87f8be-f843-4cfa-a8ba-63171f2f9647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
