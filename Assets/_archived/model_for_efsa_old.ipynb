{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23194c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "th = torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b0352",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1367aa6b-b28b-4dc0-a6f4-bdb890e0afda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Link</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1778881361...</td>\n",
       "      <td>Supervised full self-driving now $99/month</td>\n",
       "      <td>Apr 12, 2024 路 8:22 PM UTC</td>\n",
       "      <td>55501</td>\n",
       "      <td>7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1779535730...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 14, 2024 路 3:42 PM UTC</td>\n",
       "      <td>212175</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1779480889...</td>\n",
       "      <td></td>\n",
       "      <td>Apr 14, 2024 路 12:04 PM UTC</td>\n",
       "      <td>307993</td>\n",
       "      <td>15783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1779435508...</td>\n",
       "      <td>The refreshing breeze of the Overton window op...</td>\n",
       "      <td>Apr 14, 2024 路 9:04 AM UTC</td>\n",
       "      <td>68232</td>\n",
       "      <td>4452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1779422441...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 14, 2024 路 8:12 AM UTC</td>\n",
       "      <td>121904</td>\n",
       "      <td>5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1777100344...</td>\n",
       "      <td>Using a VPN is very easy</td>\n",
       "      <td>Apr 7, 2024 路 10:25 PM UTC</td>\n",
       "      <td>161635</td>\n",
       "      <td>8206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>https://twitter.com/SpaceX/status/177709821367...</td>\n",
       "      <td>T-1 hour until Falcon 9s launch of the Bandwa...</td>\n",
       "      <td>Apr 7, 2024 路 10:16 PM UTC</td>\n",
       "      <td>14059</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1777089879...</td>\n",
       "      <td>To ensure that you can still access the  plat...</td>\n",
       "      <td>Apr 7, 2024 路 9:43 PM UTC</td>\n",
       "      <td>185577</td>\n",
       "      <td>15515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1777080103...</td>\n",
       "      <td>These are the most draconian demands of any co...</td>\n",
       "      <td>Apr 7, 2024 路 9:04 PM UTC</td>\n",
       "      <td>139731</td>\n",
       "      <td>6988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>https://twitter.com/elonmusk/status/1777011744...</td>\n",
       "      <td>Well said</td>\n",
       "      <td>Apr 7, 2024 路 4:33 PM UTC</td>\n",
       "      <td>126342</td>\n",
       "      <td>6067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               Link  \\\n",
       "0            0  https://twitter.com/elonmusk/status/1778881361...   \n",
       "1            1  https://twitter.com/elonmusk/status/1779535730...   \n",
       "2            2  https://twitter.com/elonmusk/status/1779480889...   \n",
       "3            3  https://twitter.com/elonmusk/status/1779435508...   \n",
       "4            4  https://twitter.com/elonmusk/status/1779422441...   \n",
       "..         ...                                                ...   \n",
       "95          95  https://twitter.com/elonmusk/status/1777100344...   \n",
       "96          96  https://twitter.com/SpaceX/status/177709821367...   \n",
       "97          97  https://twitter.com/elonmusk/status/1777089879...   \n",
       "98          98  https://twitter.com/elonmusk/status/1777080103...   \n",
       "99          99  https://twitter.com/elonmusk/status/1777011744...   \n",
       "\n",
       "                                                 Text  \\\n",
       "0          Supervised full self-driving now $99/month   \n",
       "1                                                 NaN   \n",
       "2                                                      \n",
       "3   The refreshing breeze of the Overton window op...   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "95                           Using a VPN is very easy   \n",
       "96  T-1 hour until Falcon 9s launch of the Bandwa...   \n",
       "97  To ensure that you can still access the  plat...   \n",
       "98  These are the most draconian demands of any co...   \n",
       "99                                          Well said   \n",
       "\n",
       "                           Date   Likes  Comment  \n",
       "0    Apr 12, 2024 路 8:22 PM UTC   55501     7981  \n",
       "1    Apr 14, 2024 路 3:42 PM UTC  212175     6536  \n",
       "2   Apr 14, 2024 路 12:04 PM UTC  307993    15783  \n",
       "3    Apr 14, 2024 路 9:04 AM UTC   68232     4452  \n",
       "4    Apr 14, 2024 路 8:12 AM UTC  121904     5636  \n",
       "..                          ...     ...      ...  \n",
       "95   Apr 7, 2024 路 10:25 PM UTC  161635     8206  \n",
       "96   Apr 7, 2024 路 10:16 PM UTC   14059      792  \n",
       "97    Apr 7, 2024 路 9:43 PM UTC  185577    15515  \n",
       "98    Apr 7, 2024 路 9:04 PM UTC  139731     6988  \n",
       "99    Apr 7, 2024 路 4:33 PM UTC  126342     6067  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "FILEPATH = '/Users/Shared/tweets.csv'\n",
    "df1 = pd.read_csv(FILEPATH)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7dac37-164f-4630-a3f0-5669719a0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_x</th>\n",
       "      <th>Close_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>28.684000</td>\n",
       "      <td>35.939999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>29.534000</td>\n",
       "      <td>36.093334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>30.102667</td>\n",
       "      <td>36.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>31.270666</td>\n",
       "      <td>35.473331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>32.809334</td>\n",
       "      <td>35.276669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-08</th>\n",
       "      <td>172.979996</td>\n",
       "      <td>62.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09</th>\n",
       "      <td>176.880005</td>\n",
       "      <td>63.560001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-10</th>\n",
       "      <td>171.759995</td>\n",
       "      <td>63.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-11</th>\n",
       "      <td>174.600006</td>\n",
       "      <td>63.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-12</th>\n",
       "      <td>171.050003</td>\n",
       "      <td>61.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1077 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close_x    Close_y\n",
       "Date                             \n",
       "2020-01-02   28.684000  35.939999\n",
       "2020-01-03   29.534000  36.093334\n",
       "2020-01-06   30.102667  36.070000\n",
       "2020-01-07   31.270666  35.473331\n",
       "2020-01-08   32.809334  35.276669\n",
       "...                ...        ...\n",
       "2024-04-08  172.979996  62.139999\n",
       "2024-04-09  176.880005  63.560001\n",
       "2024-04-10  171.759995  63.009998\n",
       "2024-04-11  174.600006  63.060001\n",
       "2024-04-12  171.050003  61.520000\n",
       "\n",
       "[1077 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for df1 (daily data)\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime(2020, 1, 1)\n",
    "end = datetime(2024, 4, 15)\n",
    "\n",
    "# Convert datetime to date (if necessary, though yfinance can handle datetime objects)\n",
    "start_date = start.date()\n",
    "end_date = end.date()\n",
    "\n",
    "# Download the stock data\n",
    "df2 = yf.download('TSLA', start=start_date, end=end_date)\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "\n",
    "\n",
    "# Define the start and end dates\n",
    "start = datetime(2020, 1, 1)\n",
    "end = datetime(2024, 4, 15)\n",
    "\n",
    "# Convert datetime to date (if necessary, though yfinance can handle datetime objects)\n",
    "start_date = start.date()\n",
    "end_date = end.date()\n",
    "\n",
    "# Download the stock data\n",
    "df3 = yf.download('NDAQ', start=start_date, end=end_date)\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "\n",
    "\n",
    "merged_df = pd.merge(df2, df3, how='left', left_index=True, right_on='Date');\n",
    "merged_df\n",
    "\n",
    "merge_df2 = merged_df[['Close_x', 'Close_y']]\n",
    "merge_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dce8c8-3613-4cff-8f5f-fc6503136fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Link', 'Text', 'Date', 'Likes', 'Comment'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supervised full self-driving now $99/month</td>\n",
       "      <td>Apr 12, 2024 路 8:22 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 14, 2024 路 3:42 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Apr 14, 2024 路 12:04 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The refreshing breeze of the Overton window op...</td>\n",
       "      <td>Apr 14, 2024 路 9:04 AM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr 14, 2024 路 8:12 AM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Using a VPN is very easy</td>\n",
       "      <td>Apr 7, 2024 路 10:25 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>T-1 hour until Falcon 9s launch of the Bandwa...</td>\n",
       "      <td>Apr 7, 2024 路 10:16 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>To ensure that you can still access the  plat...</td>\n",
       "      <td>Apr 7, 2024 路 9:43 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>These are the most draconian demands of any co...</td>\n",
       "      <td>Apr 7, 2024 路 9:04 PM UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Well said</td>\n",
       "      <td>Apr 7, 2024 路 4:33 PM UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "0          Supervised full self-driving now $99/month   \n",
       "1                                                 NaN   \n",
       "2                                                      \n",
       "3   The refreshing breeze of the Overton window op...   \n",
       "4                                                 NaN   \n",
       "..                                                ...   \n",
       "95                           Using a VPN is very easy   \n",
       "96  T-1 hour until Falcon 9s launch of the Bandwa...   \n",
       "97  To ensure that you can still access the  plat...   \n",
       "98  These are the most draconian demands of any co...   \n",
       "99                                          Well said   \n",
       "\n",
       "                           Date  \n",
       "0    Apr 12, 2024 路 8:22 PM UTC  \n",
       "1    Apr 14, 2024 路 3:42 PM UTC  \n",
       "2   Apr 14, 2024 路 12:04 PM UTC  \n",
       "3    Apr 14, 2024 路 9:04 AM UTC  \n",
       "4    Apr 14, 2024 路 8:12 AM UTC  \n",
       "..                          ...  \n",
       "95   Apr 7, 2024 路 10:25 PM UTC  \n",
       "96   Apr 7, 2024 路 10:16 PM UTC  \n",
       "97    Apr 7, 2024 路 9:43 PM UTC  \n",
       "98    Apr 7, 2024 路 9:04 PM UTC  \n",
       "99    Apr 7, 2024 路 4:33 PM UTC  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "df1.columns = df1.columns.str.strip()\n",
    "tweets = df1[['Text', 'Date']]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f925e4-bd04-454f-986d-ed57bae54f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2024-04-12 20:22:00\n",
      "1    2024-04-14 15:42:00\n",
      "2    2024-04-14 12:04:00\n",
      "3    2024-04-14 09:04:00\n",
      "4    2024-04-14 08:12:00\n",
      "             ...        \n",
      "95   2024-04-07 22:25:00\n",
      "96   2024-04-07 22:16:00\n",
      "97   2024-04-07 21:43:00\n",
      "98   2024-04-07 21:04:00\n",
      "99   2024-04-07 16:33:00\n",
      "Name: Date, Length: 100, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Format of the datetime strings\n",
    "date_format = \"%b %d, %Y 路 %I:%M %p UTC\"\n",
    "\n",
    "# Convert the 'date' column\n",
    "df1['Date'] = pd.to_datetime(df1['Date'], format=date_format)\n",
    "\n",
    "# Check the result\n",
    "print(df1['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee870eff-80ce-4f52-ab81-62d44c7acfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Link  \\\n",
      "0   https://twitter.com/elonmusk/status/1778881361...   \n",
      "1   https://twitter.com/elonmusk/status/1779535730...   \n",
      "2   https://twitter.com/elonmusk/status/1779480889...   \n",
      "3   https://twitter.com/elonmusk/status/1779435508...   \n",
      "4   https://twitter.com/elonmusk/status/1779422441...   \n",
      "..                                                ...   \n",
      "95  https://twitter.com/elonmusk/status/1777100344...   \n",
      "96  https://twitter.com/SpaceX/status/177709821367...   \n",
      "97  https://twitter.com/elonmusk/status/1777089879...   \n",
      "98  https://twitter.com/elonmusk/status/1777080103...   \n",
      "99  https://twitter.com/elonmusk/status/1777011744...   \n",
      "\n",
      "                                                 Text        Date   Likes  \\\n",
      "0          Supervised full self-driving now $99/month  2024-04-12   55501   \n",
      "1                                                 NaN  2024-04-14  212175   \n",
      "2                                                     2024-04-14  307993   \n",
      "3   The refreshing breeze of the Overton window op...  2024-04-14   68232   \n",
      "4                                                 NaN  2024-04-14  121904   \n",
      "..                                                ...         ...     ...   \n",
      "95                           Using a VPN is very easy  2024-04-07  161635   \n",
      "96  T-1 hour until Falcon 9s launch of the Bandwa...  2024-04-07   14059   \n",
      "97  To ensure that you can still access the  plat...  2024-04-07  185577   \n",
      "98  These are the most draconian demands of any co...  2024-04-07  139731   \n",
      "99                                          Well said  2024-04-07  126342   \n",
      "\n",
      "    Comment  \n",
      "0      7981  \n",
      "1      6536  \n",
      "2     15783  \n",
      "3      4452  \n",
      "4      5636  \n",
      "..      ...  \n",
      "95     8206  \n",
      "96      792  \n",
      "97    15515  \n",
      "98     6988  \n",
      "99     6067  \n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column from string to datetime\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "\n",
    "# Format the datetime object to 'YYYY-MM-DD' string format\n",
    "df1['formatted_date'] = df1['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Display the original and formatted dates\n",
    "\n",
    "df1['Date'] = df1['formatted_date']\n",
    "\n",
    "# Optionally, drop the 'formatted_date' column\n",
    "df1.drop(columns='formatted_date', inplace=True)\n",
    "df1.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d8d9fb-1fcc-415a-9ced-471d394e9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Text'] = df1['Text'].fillna('').astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ade9e2cf-c7f4-45cf-987e-f21168664864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_agg = df1.groupby('Date')['Text'].agg(' '.join).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "758d3f95-1995-496a-8744-b63da2c1926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([df1, df2, df3, final_df], open('test_data.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a815cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dfs = pickle.load(open('test_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d235cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_x</th>\n",
       "      <th>Close_y</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>28.684000</td>\n",
       "      <td>35.939999</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>29.534000</td>\n",
       "      <td>36.093334</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>30.102667</td>\n",
       "      <td>36.070000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>31.270666</td>\n",
       "      <td>35.473331</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>32.809334</td>\n",
       "      <td>35.276669</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-08</th>\n",
       "      <td>172.979996</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>During todays solar eclipse, &gt;10 Megapack sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09</th>\n",
       "      <td>176.880005</td>\n",
       "      <td>63.560001</td>\n",
       "      <td>Reliable high-speed internet for space station...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-10</th>\n",
       "      <td>171.759995</td>\n",
       "      <td>63.009998</td>\n",
       "      <td>Shutdown of a Raptor vacuum engine in slow mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-11</th>\n",
       "      <td>174.600006</td>\n",
       "      <td>63.060001</td>\n",
       "      <td>One of the few companies I don't mind getting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-12</th>\n",
       "      <td>171.050003</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>Supervised full self-driving now $99/month We ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1077 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close_x    Close_y  \\\n",
       "Date                                \n",
       "2020-01-02   28.684000  35.939999   \n",
       "2020-01-03   29.534000  36.093334   \n",
       "2020-01-06   30.102667  36.070000   \n",
       "2020-01-07   31.270666  35.473331   \n",
       "2020-01-08   32.809334  35.276669   \n",
       "...                ...        ...   \n",
       "2024-04-08  172.979996  62.139999   \n",
       "2024-04-09  176.880005  63.560001   \n",
       "2024-04-10  171.759995  63.009998   \n",
       "2024-04-11  174.600006  63.060001   \n",
       "2024-04-12  171.050003  61.520000   \n",
       "\n",
       "                                                         Text  \n",
       "Date                                                           \n",
       "2020-01-02                                                     \n",
       "2020-01-03                                                     \n",
       "2020-01-06                                                     \n",
       "2020-01-07                                                     \n",
       "2020-01-08                                                     \n",
       "...                                                       ...  \n",
       "2024-04-08  During todays solar eclipse, >10 Megapack sit...  \n",
       "2024-04-09  Reliable high-speed internet for space station...  \n",
       "2024-04-10  Shutdown of a Raptor vacuum engine in slow mot...  \n",
       "2024-04-11  One of the few companies I don't mind getting ...  \n",
       "2024-04-12  Supervised full self-driving now $99/month We ...  \n",
       "\n",
       "[1077 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abe7ef48-308f-4181-b780-923a2afcc2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_x</th>\n",
       "      <th>Close_y</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>28.684000</td>\n",
       "      <td>35.939999</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>29.534000</td>\n",
       "      <td>36.093334</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>30.102667</td>\n",
       "      <td>36.070000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>31.270666</td>\n",
       "      <td>35.473331</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>32.809334</td>\n",
       "      <td>35.276669</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-08</th>\n",
       "      <td>172.979996</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>During todays solar eclipse, &gt;10 Megapack sit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09</th>\n",
       "      <td>176.880005</td>\n",
       "      <td>63.560001</td>\n",
       "      <td>Reliable high-speed internet for space station...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-10</th>\n",
       "      <td>171.759995</td>\n",
       "      <td>63.009998</td>\n",
       "      <td>Shutdown of a Raptor vacuum engine in slow mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-11</th>\n",
       "      <td>174.600006</td>\n",
       "      <td>63.060001</td>\n",
       "      <td>One of the few companies I don't mind getting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-12</th>\n",
       "      <td>171.050003</td>\n",
       "      <td>61.520000</td>\n",
       "      <td>Supervised full self-driving now $99/month We ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1077 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close_x    Close_y  \\\n",
       "Date                                \n",
       "2020-01-02   28.684000  35.939999   \n",
       "2020-01-03   29.534000  36.093334   \n",
       "2020-01-06   30.102667  36.070000   \n",
       "2020-01-07   31.270666  35.473331   \n",
       "2020-01-08   32.809334  35.276669   \n",
       "...                ...        ...   \n",
       "2024-04-08  172.979996  62.139999   \n",
       "2024-04-09  176.880005  63.560001   \n",
       "2024-04-10  171.759995  63.009998   \n",
       "2024-04-11  174.600006  63.060001   \n",
       "2024-04-12  171.050003  61.520000   \n",
       "\n",
       "                                                         Text  \n",
       "Date                                                           \n",
       "2020-01-02                                                     \n",
       "2020-01-03                                                     \n",
       "2020-01-06                                                     \n",
       "2020-01-07                                                     \n",
       "2020-01-08                                                     \n",
       "...                                                       ...  \n",
       "2024-04-08  During todays solar eclipse, >10 Megapack sit...  \n",
       "2024-04-09  Reliable high-speed internet for space station...  \n",
       "2024-04-10  Shutdown of a Raptor vacuum engine in slow mot...  \n",
       "2024-04-11  One of the few companies I don't mind getting ...  \n",
       "2024-04-12  Supervised full self-driving now $99/month We ...  \n",
       "\n",
       "[1077 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' column in df2 to datetime\n",
    "df1_agg['Date'] = pd.to_datetime(df1_agg['Date'])\n",
    "\n",
    "# Merge df1 and df2\n",
    "final_df = pd.merge(merged_df[['Close_x','Close_y']], df1_agg[['Text','Date']], how='left', left_index=True, right_on='Date');\n",
    "final_df\n",
    "\n",
    "# Fill NaN values in merged_df with 0 (for missing sporadic data)\n",
    "final_df.fillna('', inplace=True)\n",
    "\n",
    "# Set 'Date' column as index again\n",
    "final_df.set_index('Date', inplace=True)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4aae1",
   "metadata": {},
   "source": [
    "## Load BERT embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0702b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamk/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Input ids are automatically padded from 3002 to 3072 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3002])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_embedder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoded_input\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m _  \u001b[38;5;241m=\u001b[39m embedder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)\n\u001b[0;32m---> 17\u001b[0m \u001b[43m_embedder\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name '_embedder' is not defined"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# embedder = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "from transformers import LongformerModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "embedder = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "max_token_n = 4096\n",
    "\n",
    "# test model\n",
    "text = 'TWEETS' * 1000\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input.input_ids.shape)\n",
    "_  = embedder(**encoded_input)\n",
    "_embedder(**encoded_input)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e2a23",
   "metadata": {},
   "source": [
    "## Dataset generation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f520e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def embed_by_bert(text):\n",
    "    _tkn = tokenizer(text, return_tensors='pt') \n",
    "    if _tkn.input_ids.shape[-1] >= max_token_n:\n",
    "        _tkn = _tkn[:,:max_token_n]\n",
    "    _emb = embedder(**_tkn).last_hidden_state[:,0,:].detach().to(th.float32)\n",
    "    return _emb\n",
    "\n",
    "def embed_one_by_one(list_list_texts, text_to_emb_dict, embed_func=None):\n",
    "    embs = []\n",
    "    for _i, _txts in enumerate(list_list_texts):\n",
    "        _embs = []\n",
    "        for _txt in _txts:\n",
    "            if _txt in text_to_emb_dict: \n",
    "                _emb = text_to_emb_dict.get(_txt)\n",
    "            else:\n",
    "                _emb = embed_func(_txt)\n",
    "                text_to_emb_dict[_txt] = _emb\n",
    "            _embs.append(_emb)\n",
    "        embs.append(_embs)\n",
    "    return embs\n",
    "\n",
    "def embed_text(dataset, list_list_texts, apply_pca=True):\n",
    "    unique_embs = dict()\n",
    "    dataset.unique_embs = unique_embs\n",
    "\n",
    "    list_list_embs_p_step = embed_one_by_one(list_list_texts, unique_embs, embed_by_bert)\n",
    "    list_embs_p_company = [th.cat(_embs, dim=0) for _embs in list_list_embs_p_step]\n",
    "    \n",
    "    #print(unique_embs)\n",
    "    \n",
    "    if apply_pca is not None:\n",
    "        apply_pca = {} if apply_pca is True else apply_pca\n",
    "        n_components = apply_pca.get('n_components', 10)\n",
    "        \n",
    "        # create concatenated embedding\n",
    "        unique_embs_txts, unique_embs_vals = list(zip(*unique_embs.items()))\n",
    "        unique_embs_cat = th.cat(unique_embs_vals, dim=0)\n",
    "        \n",
    "        # apply PCA\n",
    "        n_components = min(n_components, len(unique_embs_txts))\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(unique_embs_cat.numpy())\n",
    "        \n",
    "        #  transform\n",
    "        unique_embs_pca_cat = th.tensor(pca.transform(unique_embs_cat))\n",
    "        unique_embs_pca = dict(zip(unique_embs.keys(), th.split(unique_embs_pca_cat, 1)))\n",
    "        \n",
    "        #print(unique_embs_pca)\n",
    "        # recreate datastructure\n",
    "        list_list_embs_p_step_pca = embed_one_by_one(list_list_texts, unique_embs_pca)\n",
    "        list_embs_p_company = [th.cat(_embs, dim=0).to(th.float32) for _embs in list_list_embs_p_step_pca]\n",
    "\n",
    "    return list_embs_p_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b96f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, \n",
    "                 input_window=4, output_window=1,\n",
    "                 use_transformer=False, \n",
    "                 input_prices=['Close_x', 'Close_y'], output_prices=['Close_x'], \n",
    "                 include_text= False, # or False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        data (filepath of saved path)\n",
    "        data (list of pd.DataFrame): List of dataframes, each containing columns:\n",
    "                                          'time', 'stock price', 'stock index price', 'text message'\n",
    "        input_window (int): Number of timesteps in each input sequence.\n",
    "        output_window (int): Number of timesteps in each target sequence.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.sequences = []\n",
    "        \n",
    "        if use_transformer:\n",
    "            output_window = 1\n",
    "        \n",
    "        if isinstance(data, str) and os.path.exists(data):\n",
    "            self.sequences, self.unique_embs = pickle.load(open(data, 'rb'))\n",
    "        else:\n",
    "            self.input_window = input_window\n",
    "            self.output_window = output_window\n",
    "        \n",
    "            if include_text:\n",
    "                all_texts = [_df[include_text].values.tolist() for _df in data]\n",
    "                list_embs_p_company = self.embed_text(all_texts)\n",
    "\n",
    "            for _i_df, df in enumerate(data):\n",
    "                t = df[input_prices].shape[0]\n",
    "                seq_in = th.tensor(df[input_prices].values).reshape(t,-1).to(th.float32)\n",
    "                seq_tgt = th.tensor(df[output_prices].values).reshape(t,-1).to(th.float32)\n",
    "                if include_text:\n",
    "                    embs = list_embs_p_company[_i_df]\n",
    "\n",
    "                num_sequences = t - self.input_window - self.output_window + 1\n",
    "\n",
    "                for i in range(num_sequences):\n",
    "                    input_start = i\n",
    "                    input_end = i + self.input_window\n",
    "                    \n",
    "                    if use_transformer:\n",
    "                        target_start = 1\n",
    "                        target_end = 1 + self.input_window\n",
    "                    else:\n",
    "                        target_start = input_end\n",
    "                        target_end = target_start + self.output_window\n",
    "\n",
    "                    seq_in_ = [seq_in[input_start:input_end]]\n",
    "                    if include_text:\n",
    "                        seq_in_.append(embs[input_start:input_end])\n",
    "\n",
    "                    seq_in_ = th.cat(seq_in_, dim=1)\n",
    "                    seq_tgt_ = seq_tgt[target_start:target_end]\n",
    "                    self.sequences.append((seq_in_, seq_tgt_))\n",
    "\n",
    "\n",
    "    def embed_text(self, list_list_texts):\n",
    "        return embed_text(self, list_list_texts)\n",
    "    \n",
    "    def save_dataset(self, filepath):\n",
    "        pickle.dump([self.sequences, self.unique_embs], open(filepath, 'wb'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence, target_sequence = self.sequences[idx]\n",
    "        return input_sequence, target_sequence\n",
    "    \n",
    "    @property\n",
    "    def input_dim(self):\n",
    "        return self.sequences[0][0].shape[-1]\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.sequences[0][1].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5bc09",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd3ad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(DATA, open(FILEPATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ff53ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = pickle.load(open(FILEPATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8aa6b5",
   "metadata": {},
   "source": [
    "## Important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b651401",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window = seq_length = 10  # e.g., 5 days input\n",
    "output_window = 1  # e.g., 2 days to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789a8b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d776c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example fake data generation\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "data_length = 10\n",
    "df1 = pd.DataFrame({\n",
    "    'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "    'price_main': np.random.rand(data_length) * 100,\n",
    "    'price_sec': np.random.rand(data_length) * 1000,\n",
    "    'text': np.random.choice(['news', '', 'alert', 'none'], data_length)\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "    'price_main': np.random.rand(data_length) * 100,\n",
    "    'price_sec': np.random.rand(data_length) * 1000,\n",
    "    'text': np.random.choice(['announcement', 'report', 'alert', 'none'], data_length)\n",
    "})\n",
    "\n",
    "dataframes = [df1, df2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d486b01-ad79-4a94-ae49-aab2a8dfe4c3",
   "metadata": {},
   "source": [
    "## RealData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e43aa3e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m price_main \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose_x\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      2\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose_x\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ((price_main \u001b[38;5;241m-\u001b[39m price_main\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (price_main\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m price_main\u001b[38;5;241m.\u001b[39mmin()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "price_main = final_df['Close_x'].values\n",
    "final_df['Close_x'] = ((price_main - price_main.min()) / (price_main.max() - price_main.min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b28b0a0-28b7-4878-b09b-4e4d6fd6d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_sec = final_df['Close_y'].values\n",
    "final_df['Close_y'] = ((price_sec - price_sec.min()) / (price_sec.max() - price_sec.min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64cc595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.68400002,  29.5340004 ,  30.10266685, ..., 171.75999451,\n",
       "       174.6000061 , 171.05000305])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4a8dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.93999863, 36.0933342 , 36.06999969, ..., 63.00999832,\n",
       "       63.06000137, 61.52000046])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ed7fc",
   "metadata": {},
   "source": [
    "* you will need to replace this with your own data\n",
    "* each df relates to a company\n",
    "* additionally, normalise your company's price data from 0 to 1\n",
    "* the stock prices should be normalised the same way across all companies\n",
    "* here 'price_main' and 'price_sec' represents 'stock' and 'stock index'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d82fb",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09afb9",
   "metadata": {},
   "source": [
    "* the dataset generator can be used to make data for different model architecture...\n",
    "* you can have it predict from stock and index price, and output in stock price... you can also include index price in the output... adjust the output_prices accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9cf4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 2 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 40 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 327 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 2041 to 2048 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 217 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 274 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 480 to 512 to be a multiple of `config.attention_window`: 512\n"
     ]
    }
   ],
   "source": [
    "input_prices = ['Close_x']\n",
    "output_prices = ['Close_x']\n",
    "text_column = 'Text'\n",
    "dataset = StockDataset([dfs[3]], \n",
    "                       input_window, output_window, \n",
    "                       input_prices=input_prices, output_prices=output_prices, include_text=text_column,\n",
    "                       use_transformer=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115706bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.unique_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "683b6479",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m StockDataset(\u001b[43mdataframes\u001b[49m, \n\u001b[1;32m      2\u001b[0m                        input_window, output_window, \n\u001b[1;32m      3\u001b[0m                        input_prices\u001b[38;5;241m=\u001b[39minput_prices, output_prices\u001b[38;5;241m=\u001b[39moutput_prices, include_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                        use_transformer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = StockDataset(dataframes, \n",
    "                       input_window, output_window, \n",
    "                       input_prices=input_prices, output_prices=output_prices, include_text=False,\n",
    "                       use_transformer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c1d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # dataset.save_dataset('test.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0135a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = StockDataset('test.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fa323",
   "metadata": {},
   "source": [
    "# TRANSFORMER ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b9f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "        self.output_linear = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        #print(src.dtype)\n",
    "        src = self.input_linear(src)  # [seq_len, batch_size, d_model]\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.output_linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5046c",
   "metadata": {},
   "source": [
    "## Crucial model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e9d94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc0a8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = dataset.input_dim # dim_1\n",
    "output_dim = dataset.output_dim   # dim_2\n",
    "d_model = 256  # Size of the embedding\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "dim_feedforward = 512\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5505f",
   "metadata": {},
   "source": [
    "### Create fake model & data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b98d979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8]) torch.Size([10, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_ = TimeSeriesTransformer(input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward)\n",
    "\n",
    "# Dummy data\n",
    "input_data = torch.randn(seq_length, batch_size, input_dim)  # [seq_length, batch_size, input_dim]\n",
    "target_data = torch.randn(seq_length, batch_size, output_dim)  # [seq_length, batch_size, output_dim]\n",
    "\n",
    "# Forward pass\n",
    "input_data = dataset[0][0]\n",
    "output = model_(input_data)\n",
    "print(input_data.shape, output.shape)  # Should be torch.Size([seq_length, batch_size, output_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf26a0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d02bb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split_ratio = 0.9\n",
    "batch_size = 4   # make bigger\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39151773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataset\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "train_size = int(len(dataset) * train_test_split_ratio)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8169b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = TimeSeriesTransformer(input_dim, output_dim, d_model, \n",
    "                              nhead, num_encoder_layers, dim_feedforward)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537c5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd249366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 93.29218477904797, Testing Loss: 4.1651168929206\n",
      "Epoch 2, Training Loss: 4.095358773072561, Testing Loss: 4.093663074352123\n",
      "Epoch 3, Training Loss: 4.093760361274083, Testing Loss: 4.0930511863143355\n",
      "Epoch 4, Training Loss: 4.094056657950083, Testing Loss: 4.092964578557898\n",
      "Epoch 5, Training Loss: 4.111930701136589, Testing Loss: 4.093897219057436\n",
      "Epoch 6, Training Loss: 4.093895041942597, Testing Loss: 4.093894799550374\n",
      "Epoch 7, Training Loss: 4.095431031783422, Testing Loss: 4.093894658265291\n",
      "Epoch 8, Training Loss: 4.093895397583643, Testing Loss: 4.0938953117088035\n",
      "Epoch 9, Training Loss: 4.093895041942597, Testing Loss: 4.093895205744991\n",
      "Epoch 10, Training Loss: 4.093894942601522, Testing Loss: 4.093894799550374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training and Testing Loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for batch, (src, tgt) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_train_loss += loss.detach().item()\n",
    "    \n",
    "    total_test_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_dataloader:\n",
    "            output = model(src)\n",
    "            loss = criterion(output, tgt)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_train_loss/len(train_dataloader)}, Testing Loss: {total_test_loss/len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5288139f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensor\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4869c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
