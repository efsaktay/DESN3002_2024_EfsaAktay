{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa82fc7e-10d4-4cb2-bb1c-7c5d3b360882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       User              Date Created  Number of Likes Source of Tweet  \\\n",
      "0  Tim Cook 2024-04-15 13:57:59+00:00             5019            None   \n",
      "1  Tim Cook 2024-04-15 12:22:25+00:00             3855            None   \n",
      "2  Tim Cook 2024-04-15 09:47:36+00:00             7648            None   \n",
      "3  Tim Cook 2024-04-15 06:15:57+00:00            12755            None   \n",
      "4  Tim Cook 2024-04-15 04:20:50+00:00            17550            None   \n",
      "5  Tim Cook 2024-04-09 19:23:30+00:00             5959            None   \n",
      "6  Tim Cook 2024-03-31 21:00:02+00:00             8877            None   \n",
      "7  Tim Cook 2024-03-31 15:00:00+00:00            15914            None   \n",
      "8  Tim Cook 2024-03-25 05:46:56+00:00            19010            None   \n",
      "9  Tim Cook 2024-03-17 19:27:21+00:00             5050            None   \n",
      "\n",
      "                                               Tweet  \n",
      "0  Thanks to the very talented VietMax for showin...  \n",
      "1  Developers CollaNote &amp; ELSA Speak walked m...  \n",
      "2  Phuong Vu and his team are wildly creative. Th...  \n",
      "3  Hoan Kiem Lake in Hanoi is as beautiful as it ...  \n",
      "4  Xin ch√†o, Vietnam! Thank you to the very talen...  \n",
      "5  Leading companies in every industry are levera...  \n",
      "6  Today and every day, let's commit to creating ...  \n",
      "7                                    Happy Easter! üêá  \n",
      "8  Happy Holi to all who celebrate! Thank you @jo...  \n",
      "9  Congratulations!! @coachbrucepearl @AuburnMBB ...  \n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Enter your credentials here\n",
    "#bearer_token = 'AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAADcz9vgczEZMZ7q6u5aGQ4UstazE%3DOSybzlXB9L8nCDM6XRgLlZSTqsJ1GaOV8UAoMqZgk9Zc5sODJQ'\n",
    "\n",
    "# Initialize Tweepy with Twitter API v2\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Tim Cook's Twitter user ID\n",
    "user_id = \"1636590253\"  # This is Tim Cook's user ID; replace if different\n",
    "\n",
    "# Define the time range\n",
    "start_time = \"2020-01-01T00:00:00Z\"\n",
    "end_time = \"2024-04-15T23:59:59Z\"\n",
    "\n",
    "# Collect tweets\n",
    "try:\n",
    "    tweets = client.get_users_tweets(id=user_id, \n",
    "                                     start_time=start_time, \n",
    "                                     end_time=end_time, \n",
    "                                     max_results=10, \n",
    "                                     tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], \n",
    "                                     exclude=[\"retweets\", \"replies\"], \n",
    "                                     expansions='author_id')\n",
    "\n",
    "    # Prepare tweet and user data\n",
    "    tweets_data = tweets.data\n",
    "    users = {u[\"id\"]: u for u in tweets.includes[\"users\"]} if tweets.includes and \"users\" in tweets.includes else {}\n",
    "\n",
    "    attributes_container = []\n",
    "    if tweets_data:\n",
    "        for tweet in tweets_data:\n",
    "            user = users[tweet.author_id]\n",
    "            attributes_container.append([user.name, tweet.created_at, tweet.public_metrics[\"like_count\"], tweet.source, tweet.text])\n",
    "\n",
    "    # Create DataFrame\n",
    "    columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"]\n",
    "    tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "    print(tweets_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print('Failed to fetch tweets:', str(e))\n",
    "\n",
    "print(\"Data saved to 'tweets.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f9883d-b35b-48f8-9d17-fc463ce302be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "tweets_df.to_csv('tweets.csv', index=False)\n",
    "print(\"Data saved to 'tweets.csv'.\")\n",
    "\n",
    "# Save to Pickle\n",
    "tweets_df.to_pickle('tweets_tim cook 10 tweet.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e8bd35-33d3-4cad-985a-e819d23c820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets_next100_timcook.csv'.\n",
      "Data saved to 'tweets_next100_timcook.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter credentials\n",
    "#bearer_token = 'AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAADcz9vgczEZMZ7q6u5aGQ4UstazE%3DOSybzlXB9L8nCDM6XRgLlZSTqsJ1GaOV8UAoMqZgk9Zc5sODJQ'\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# User ID for which to fetch tweets\n",
    "user_id = \"1636590253\"  # Example: Tim Cook's user ID\n",
    "\n",
    "# Define time range\n",
    "start_time = \"2024-01-01T00:00:00Z\"\n",
    "end_time = \"2024-03-17T00:00:00Z\"\n",
    "\n",
    "def fetch_tweets(user_id, start_time, end_time, max_results=100):\n",
    "    all_tweets = []\n",
    "    includes_users = {}\n",
    "    response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                       tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], exclude=[\"retweets\", \"replies\"],\n",
    "                                       expansions=\"author_id\")\n",
    "    if response.data:\n",
    "        all_tweets.extend(response.data)\n",
    "        if 'users' in response.includes:\n",
    "            for user in response.includes['users']:\n",
    "                includes_users[user.id] = user\n",
    "\n",
    "    while 'next_token' in response.meta:\n",
    "        response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                           pagination_token=response.meta['next_token'], tweet_fields=[\"created_at\", \"public_metrics\", \"source\"],\n",
    "                                           exclude=[\"retweets\", \"replies\"], expansions=\"author_id\")\n",
    "        if response.data:\n",
    "            all_tweets.extend(response.data)\n",
    "            if 'users' in response.includes:\n",
    "                for user in response.includes['users']:\n",
    "                    includes_users[user.id] = user\n",
    "\n",
    "    return all_tweets, includes_users\n",
    "    \n",
    "tweets, users = fetch_tweets(user_id, start_time, end_time)\n",
    "\n",
    "attributes_container = [\n",
    "    [\n",
    "        users[tweet.author_id].name,\n",
    "        tweet.created_at,\n",
    "        tweet.public_metrics['like_count'],\n",
    "        tweet.public_metrics['retweet_count'],\n",
    "        tweet.source,\n",
    "        tweet.text\n",
    "    ]\n",
    "    for tweet in tweets\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"]\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "\n",
    "# Save to CSV and Pickle\n",
    "tweets_df.to_csv('tweets_next100_timcook.csv', index=False)\n",
    "print(\"Data saved to 'tweets_next100_timcook.csv'.\")\n",
    "tweets_df.to_pickle('tweets_next100_timcook.pkl')\n",
    "print(\"Data saved to 'tweets_next100_timcook.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ceeb4-b674-454d-85b5-cca06ecb51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
