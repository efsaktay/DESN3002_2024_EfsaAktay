{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e8bd35-33d3-4cad-985a-e819d23c820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets_2019_timcook.csv'.\n",
      "Data saved to 'tweets_2019_timcook.pkl'.\n",
      "        User              Date Created  Number of Likes  Number of Retweets  \\\n",
      "0   Tim Cook 2019-12-30 02:22:58+00:00             3129                 283   \n",
      "1   Tim Cook 2019-12-26 23:31:38+00:00             5968                 636   \n",
      "2   Tim Cook 2019-12-25 15:11:39+00:00            11680                1101   \n",
      "3   Tim Cook 2019-12-23 00:48:57+00:00             3064                 297   \n",
      "4   Tim Cook 2019-12-20 04:11:21+00:00             2332                 359   \n",
      "5   Tim Cook 2019-12-18 04:56:26+00:00             1784                 147   \n",
      "6   Tim Cook 2019-12-18 02:53:23+00:00             2306                 199   \n",
      "7   Tim Cook 2019-12-17 01:03:24+00:00             5034                 752   \n",
      "8   Tim Cook 2019-12-13 13:42:39+00:00             5397                4100   \n",
      "9   Tim Cook 2019-12-13 12:33:18+00:00             2636                 646   \n",
      "10  Tim Cook 2019-12-13 10:49:03+00:00             2263                 692   \n",
      "11  Tim Cook 2019-12-13 07:11:32+00:00             3450                1755   \n",
      "12  Tim Cook 2019-12-13 05:55:43+00:00             2940                1293   \n",
      "13  Tim Cook 2019-12-13 02:50:43+00:00             6096                3619   \n",
      "14  Tim Cook 2019-12-12 08:17:53+00:00             4618                 583   \n",
      "15  Tim Cook 2019-12-12 06:20:13+00:00             3796                 327   \n",
      "16  Tim Cook 2019-12-12 03:39:56+00:00             1660                 170   \n",
      "17  Tim Cook 2019-12-12 02:34:37+00:00             2591                 237   \n",
      "18  Tim Cook 2019-12-11 10:36:05+00:00             1735                 168   \n",
      "19  Tim Cook 2019-12-11 09:35:23+00:00             2372                 232   \n",
      "20  Tim Cook 2019-12-11 07:57:18+00:00             1716                 186   \n",
      "21  Tim Cook 2019-12-11 03:33:58+00:00             4033                 559   \n",
      "22  Tim Cook 2019-12-11 02:24:06+00:00             7232                 938   \n",
      "23  Tim Cook 2019-12-10 15:37:06+00:00             2339                 385   \n",
      "24  Tim Cook 2019-12-10 08:12:44+00:00             4318                 438   \n",
      "25  Tim Cook 2019-12-10 07:52:13+00:00             2109                 391   \n",
      "26  Tim Cook 2019-12-10 03:50:38+00:00             4481                1175   \n",
      "27  Tim Cook 2019-12-10 01:31:40+00:00             3466                 451   \n",
      "28  Tim Cook 2019-12-09 11:54:03+00:00             4547                 614   \n",
      "29  Tim Cook 2019-12-09 07:28:39+00:00             6721                 666   \n",
      "\n",
      "   Source of Tweet                                              Tweet  \n",
      "0             None  John Lewis has fought great evils with resolve...  \n",
      "1             None  Our hearts are with those impacted by the Aust...  \n",
      "2             None  Our most meaningful gift is the time we share ...  \n",
      "3             None  Happy #Hanukkah to all those celebrating the F...  \n",
      "4             None  Stunning work showcasing the strength and sign...  \n",
      "5             None  Thank you to the extraordinary @JoshGroban for...  \n",
      "6             None  The holiday cheer @ToysForTots_USA brings to c...  \n",
      "7             None  .@Malala is an unparalleled champion for acces...  \n",
      "8             None  Thanks to @YodWongnai and food bloggers Yota a...  \n",
      "9             None  Amazing to see the next generation of develope...  \n",
      "10            None  It made my heart sing to spend time with Thail...  \n",
      "11            None  Congratulations to the Thai women’s national v...  \n",
      "12            None  Beyond impressed with the students at Satit-Ch...  \n",
      "13            None  สวัสดี Thailand! My journey this morning along...  \n",
      "14            None  .@SingaporeAir has transformed the cockpit wit...  \n",
      "15            None  40 years, 3200 people and countless great idea...  \n",
      "16            None  Just got a preview of @sezairi’s new track She...  \n",
      "17            None  When you bring everything you are to everythin...  \n",
      "18            None  Three of our amazing @AppleArcade launch title...  \n",
      "19            None  I am so impressed with the high school student...  \n",
      "20            None  If we can visualize a greener future, we can m...  \n",
      "21            None  Hello Singapore! Thanks to iPhone photographer...  \n",
      "22            None  Every child deserves the opportunity to create...  \n",
      "23            None  The Universal Declaration of Human Rights is o...  \n",
      "24            None  Our very first store outside of the US, Apple ...  \n",
      "25            None  Thanks to @mistwalker and the legendary Hirono...  \n",
      "26            None  TOHO Co. has been on the cutting edge of speci...  \n",
      "27            None  Seiko Advance is a great example of our invalu...  \n",
      "28            None  Coding is one of the most important skills you...  \n",
      "29            None  It’s always wonderful to be with our Apple fam...  \n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter credentials\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAFvetgEAAAAAKdqytrqUINlUsBc7pvj%2B3PYOvuk%3DWoYFUqhY76K1MdeA2WbIE6fjmKXeSWSIWRZrg51slj0ss8zkTI'\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# User ID for which to fetch tweets\n",
    "user_id = \"1636590253\"  # Example: Tim Cook's user ID\n",
    "\n",
    "#user_id = \"44196397\" # Example: Elon Musk's user ID\n",
    "\n",
    "# Define time range\n",
    "start_time = \"2019-01-01T00:00:00Z\"\n",
    "end_time = \"2020-01-01T00:00:00Z\"\n",
    "\n",
    "def fetch_tweets(user_id, start_time, end_time, max_results=100):\n",
    "    all_tweets = []\n",
    "    includes_users = {}\n",
    "    response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                       tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], exclude=[\"retweets\", \"replies\"],\n",
    "                                       expansions=\"author_id\")\n",
    "    if response.data:\n",
    "        all_tweets.extend(response.data)\n",
    "        if 'users' in response.includes:\n",
    "            for user in response.includes['users']:\n",
    "                includes_users[user.id] = user\n",
    "\n",
    "    while 'next_token' in response.meta:\n",
    "        response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                           pagination_token=response.meta['next_token'], tweet_fields=[\"created_at\", \"public_metrics\", \"source\"],\n",
    "                                           exclude=[\"retweets\", \"replies\"], expansions=\"author_id\")\n",
    "        if response.data:\n",
    "            all_tweets.extend(response.data)\n",
    "            if 'users' in response.includes:\n",
    "                for user in response.includes['users']:\n",
    "                    includes_users[user.id] = user\n",
    "\n",
    "    return all_tweets, includes_users\n",
    "    \n",
    "tweets, users = fetch_tweets(user_id, start_time, end_time)\n",
    "\n",
    "attributes_container = [\n",
    "    [\n",
    "        users[tweet.author_id].name,\n",
    "        tweet.created_at,\n",
    "        tweet.public_metrics['like_count'],\n",
    "        tweet.public_metrics['retweet_count'],\n",
    "        tweet.source,\n",
    "        tweet.text\n",
    "    ]\n",
    "    for tweet in tweets\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"]\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "\n",
    "# Save to CSV and Pickle\n",
    "tweets_df.to_csv('tweets_2019_timcook.csv', index=False)\n",
    "print(\"Data saved to 'tweets_2019_timcook.csv'.\")\n",
    "tweets_df.to_pickle('tweets_2019_timcook.pkl')\n",
    "print(\"Data saved to 'tweets_2019_timcook.pkl'.\")\n",
    "\n",
    "print(tweets_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ed899ba9-734a-477b-9094-ea87623fc8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'elon_musk_tweets_2023_2024.csv'.\n",
      "Data saved to 'elon_musk_tweets_2023_2024.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter credentials\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAA9p4zte8a8fgkwgQ70SrTEidX8lU%3D9s6MEpCT2gScE35s3Zap06cKMuKsj0P57NFhn19muUJC1X5l9d'\n",
    "\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Define the username and time range\n",
    "username = \"elonmusk\"  # Example: Elon Musk's username\n",
    "start_time = \"2023-09-01T00:00:00Z\"\n",
    "end_time = \"2024-01-01T00:00:00Z\"\n",
    "\n",
    "def fetch_tweets(username, start_time, end_time, max_results=100):\n",
    "    all_tweets = []\n",
    "    includes_users = {}\n",
    "    \n",
    "    # Resolve username to user ID\n",
    "    user = client.get_user(username=username)\n",
    "    user_id = user.data.id\n",
    "    \n",
    "    response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                       tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], exclude=[\"retweets\", \"replies\"],\n",
    "                                       expansions=\"author_id\")\n",
    "    while response:\n",
    "        if response.data:\n",
    "            all_tweets.extend(response.data)\n",
    "            if 'users' in response.includes:\n",
    "                for user in response.includes['users']:\n",
    "                    includes_users[user.id] = user\n",
    "        if 'next_token' in response.meta:\n",
    "            response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                               pagination_token=response.meta['next_token'], tweet_fields=[\"created_at\", \"public_metrics\", \"source\"],\n",
    "                                               exclude=[\"retweets\", \"replies\"], expansions=\"author_id\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return all_tweets, includes_users\n",
    "\n",
    "tweets, users = fetch_tweets(username, start_time, end_time)\n",
    "\n",
    "attributes_container = [\n",
    "    [\n",
    "        users[tweet.author_id].name,\n",
    "        tweet.created_at,\n",
    "        tweet.public_metrics['like_count'],\n",
    "        tweet.public_metrics['retweet_count'],\n",
    "        tweet.source,\n",
    "        tweet.text\n",
    "    ]\n",
    "    for tweet in tweets if tweet.author_id in users\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"]\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "tweets_df.to_csv('elon_musk_tweets_2023_2024.csv', index=False)\n",
    "print(\"Data saved to 'elon_musk_tweets_2023_2024.csv'.\")\n",
    "tweets_df.to_pickle('elon_musk_tweets_2023_2024.pkl')\n",
    "print(\"Data saved to 'elon_musk_tweets_2023_2024.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abdc2ad6-6976-450e-bf85-1ce4e0e8e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets23_4_elonmusk.csv'.\n",
      "Data saved to 'tweets23_4_elonmusk.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter credentials\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAA9p4zte8a8fgkwgQ70SrTEidX8lU%3D9s6MEpCT2gScE35s3Zap06cKMuKsj0P57NFhn19muUJC1X5l9d'\n",
    " \n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Elon Musk's Twitter user ID\n",
    "user_id = \"44196397\"\n",
    "\n",
    "# Define time range\n",
    "start_time = \"2023-09-01T00:00:00Z\"\n",
    "end_time = \"2024-01-01T00:00:00Z\"\n",
    "\n",
    "def fetch_tweets(user_id, start_time, end_time, max_results=50):\n",
    "    all_tweets = []\n",
    "    includes_users = {}\n",
    "    try:\n",
    "        response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                           tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], exclude=[\"retweets\", \"replies\"],\n",
    "                                           expansions=\"author_id\")\n",
    "        while response:\n",
    "            if response.data:\n",
    "                all_tweets.extend(response.data)\n",
    "                if 'users' in response.includes:\n",
    "                    for user in response.includes['users']:\n",
    "                        includes_users[user.id] = user\n",
    "            if 'next_token' in response.meta:\n",
    "                response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                                   pagination_token=response.meta['next_token'], tweet_fields=[\"created_at\", \"public_metrics\", \"source\"],\n",
    "                                                   exclude=[\"retweets\", \"replies\"], expansions=\"author_id\")\n",
    "            else:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch tweets: {str(e)}\")\n",
    "        return [], {}\n",
    "\n",
    "    return all_tweets, includes_users\n",
    "\n",
    "tweets, users = fetch_tweets(user_id, start_time, end_time)\n",
    "\n",
    "attributes_container = [\n",
    "    [\n",
    "        users[tweet.author_id].name,\n",
    "        tweet.created_at,\n",
    "        tweet.public_metrics['like_count'],\n",
    "        tweet.public_metrics['retweet_count'],\n",
    "        tweet.source,\n",
    "        tweet.text\n",
    "    ]\n",
    "    for tweet in tweets if tweet.author_id in users\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"]\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "\n",
    "# Save to CSV and Pickle\n",
    "tweets_df.to_csv('tweets23_4_elonmusk.csv', index=False)\n",
    "print(\"Data saved to 'tweets23_4_elonmusk.csv'.\")\n",
    "tweets_df.to_pickle('tweets23_4_elonmusk.pkl')\n",
    "print(\"Data saved to 'tweets23_4_elonmusk.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d43ceeb4-b674-454d-85b5-cca06ecb51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dfs_23_el = pickle.load(open('tweets23_4_elonmusk.pkl', 'rb'))\n",
    "dfs_24_el = pickle.load(open('tweetsleftover_elonmusk.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "443a4acb-b691-455f-b7fb-09bfe2aa5e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Number of Retweets</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [User, Date Created, Number of Likes, Number of Retweets, Source of Tweet, Tweet]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d7c6a9a-e7dd-4cac-a103-55287361a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_20_tim = pickle.load(open('tweets2020_timcook.pkl', 'rb'))\n",
    "dfs_21_tim = pickle.load(open('tweets2021_timcook.pkl', 'rb'))\n",
    "dfs_22_tim = pickle.load(open('tweets2022_timcook.pkl', 'rb'))\n",
    "dfs_23_tim = pickle.load(open('tweets2023_timcook.pkl', 'rb'))\n",
    "dfs_24_p_tim = pickle.load(open('tweets_next100_timcook.pkl', 'rb'))\n",
    "dfs_24_p_tim = pickle.load(open('tweets_tim cook 10 tweet.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d35b6f-22c4-4c45-bae1-12793f081b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
