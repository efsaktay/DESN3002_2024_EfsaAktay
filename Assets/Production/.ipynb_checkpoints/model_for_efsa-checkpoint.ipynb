{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23194c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "th = torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from random import randint\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b0352",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a815cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dfs = pickle.load(open('scaled_companies_data.pkl', 'rb'))\n",
    "dfs_text = pickle.load(open('ceo_tweets_date.pkl','rb))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0491f777-b444-483d-b53c-71ad9f6d5197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tesla':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.011927                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.014130                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.015604                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.018631                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.022618                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.385859                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.395966                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.382698                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.390057                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.380858                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'salesforce':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.221674                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.217416                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.255219                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.268460                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.275366                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.921331                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.924655                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.910375                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.907934                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.882854                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'goldman_sachs':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.343914                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.334430                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.342634                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.347965                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.355822                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.953926                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.954514                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.920071                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.908716                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.881058                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'microsoft':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.085729                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.078925                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.080320                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.075387                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.083926                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.983739                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.989488                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.979214                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.995101                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.974588                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'delta_airlines':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.930205                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.907330                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.897993                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.896825                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.925770                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.649393                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.656629                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.631419                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.663866                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.645892                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'apple':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.133751                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.128611                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.132783                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.130301                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.138751                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.791152                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.799743                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.786435                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.837555                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.848188                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'visa':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.358145                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.348315                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.345664                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.342430                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.363319                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.918451                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.911725                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.897239                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.904999                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.906810                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'ford':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.255430                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.245515                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.243154                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.247403                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.247403                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.443815                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.449953                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.427290                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.426346                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.406043                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'dell':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.100521                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.093138                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.095327                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.089834                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.090692                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.952832                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.923870                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.920821                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.926495                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.873314                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'alphabet':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.147394                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.144039                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.161044                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.159779                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.164432                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.957265                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.973665                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.969354                0.971629      0.968939         0.936562\n",
       " 2024-04-11  1.000000                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.984255                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c47022fe-ce6f-41f6-b629-0be82f098483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Companies: 10 | # of Price Points: 1077\n",
      "Companies: \n",
      "['tesla', 'salesforce', 'goldman_sachs', 'microsoft', 'delta_airlines', 'apple', 'visa', 'ford', 'dell', 'alphabet']\n",
      "number to be assigned as train: 862 | test: 215\n"
     ]
    }
   ],
   "source": [
    "pc_train = 0.2\n",
    "\n",
    "names = list(dfs.keys())\n",
    "T = len(dfs[names[0]])\n",
    "n_train = int(pc_train * T)\n",
    "\n",
    "dfs_train, dfs_test = {}, {}\n",
    "for _name, _df in dfs.items():\n",
    "    dfs_train[_name] = _df.iloc[:len(_df) - n_train]\n",
    "    dfs_test[_name] = _df.iloc[len(_df) - n_train:]\n",
    "\n",
    "n_train_per_company = len(dfs_train[_name])\n",
    "n_test_per_company = len(dfs_test[_name])\n",
    "\n",
    "print('# of Companies: {} | # of Price Points: {}'.format(len(names), T))\n",
    "print('Companies: ')\n",
    "print(names)\n",
    "print('# to be assigned as train: {} | test: {}'.format(len(dfs_train[_name]), len(dfs_test[_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a77a41f7-7bad-4d9b-891f-ccbd7515a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-01-02',\n",
       " '2020-01-03',\n",
       " '2020-01-06',\n",
       " '2020-01-07',\n",
       " '2020-01-08',\n",
       " '2020-01-09',\n",
       " '2020-01-10',\n",
       " '2020-01-13',\n",
       " '2020-01-14',\n",
       " '2020-01-15',\n",
       " '2020-01-16',\n",
       " '2020-01-17',\n",
       " '2020-01-21',\n",
       " '2020-01-22',\n",
       " '2020-01-23',\n",
       " '2020-01-24',\n",
       " '2020-01-27',\n",
       " '2020-01-28',\n",
       " '2020-01-29',\n",
       " '2020-01-30',\n",
       " '2020-01-31',\n",
       " '2020-02-03',\n",
       " '2020-02-04',\n",
       " '2020-02-05',\n",
       " '2020-02-06',\n",
       " '2020-02-07',\n",
       " '2020-02-10',\n",
       " '2020-02-11',\n",
       " '2020-02-12',\n",
       " '2020-02-13',\n",
       " '2020-02-14',\n",
       " '2020-02-18',\n",
       " '2020-02-19',\n",
       " '2020-02-20',\n",
       " '2020-02-21',\n",
       " '2020-02-24',\n",
       " '2020-02-25',\n",
       " '2020-02-26',\n",
       " '2020-02-27',\n",
       " '2020-02-28',\n",
       " '2020-03-02',\n",
       " '2020-03-03',\n",
       " '2020-03-04',\n",
       " '2020-03-05',\n",
       " '2020-03-06',\n",
       " '2020-03-09',\n",
       " '2020-03-10',\n",
       " '2020-03-11',\n",
       " '2020-03-12',\n",
       " '2020-03-13',\n",
       " '2020-03-16',\n",
       " '2020-03-17',\n",
       " '2020-03-18',\n",
       " '2020-03-19',\n",
       " '2020-03-20',\n",
       " '2020-03-23',\n",
       " '2020-03-24',\n",
       " '2020-03-25',\n",
       " '2020-03-26',\n",
       " '2020-03-27',\n",
       " '2020-03-30',\n",
       " '2020-03-31',\n",
       " '2020-04-01',\n",
       " '2020-04-02',\n",
       " '2020-04-03',\n",
       " '2020-04-06',\n",
       " '2020-04-07',\n",
       " '2020-04-08',\n",
       " '2020-04-09',\n",
       " '2020-04-13',\n",
       " '2020-04-14',\n",
       " '2020-04-15',\n",
       " '2020-04-16',\n",
       " '2020-04-17',\n",
       " '2020-04-20',\n",
       " '2020-04-21',\n",
       " '2020-04-22',\n",
       " '2020-04-23',\n",
       " '2020-04-24',\n",
       " '2020-04-27',\n",
       " '2020-04-28',\n",
       " '2020-04-29',\n",
       " '2020-04-30',\n",
       " '2020-05-01',\n",
       " '2020-05-04',\n",
       " '2020-05-05',\n",
       " '2020-05-06',\n",
       " '2020-05-07',\n",
       " '2020-05-08',\n",
       " '2020-05-11',\n",
       " '2020-05-12',\n",
       " '2020-05-13',\n",
       " '2020-05-14',\n",
       " '2020-05-15',\n",
       " '2020-05-18',\n",
       " '2020-05-19',\n",
       " '2020-05-20',\n",
       " '2020-05-21',\n",
       " '2020-05-22',\n",
       " '2020-05-26',\n",
       " '2020-05-27',\n",
       " '2020-05-28',\n",
       " '2020-05-29',\n",
       " '2020-06-01',\n",
       " '2020-06-02',\n",
       " '2020-06-03',\n",
       " '2020-06-04',\n",
       " '2020-06-05',\n",
       " '2020-06-08',\n",
       " '2020-06-09',\n",
       " '2020-06-10',\n",
       " '2020-06-11',\n",
       " '2020-06-12',\n",
       " '2020-06-15',\n",
       " '2020-06-16',\n",
       " '2020-06-17',\n",
       " '2020-06-18',\n",
       " '2020-06-19',\n",
       " '2020-06-22',\n",
       " '2020-06-23',\n",
       " '2020-06-24',\n",
       " '2020-06-25',\n",
       " '2020-06-26',\n",
       " '2020-06-29',\n",
       " '2020-06-30',\n",
       " '2020-07-01',\n",
       " '2020-07-02',\n",
       " '2020-07-06',\n",
       " '2020-07-07',\n",
       " '2020-07-08',\n",
       " '2020-07-09',\n",
       " '2020-07-10',\n",
       " '2020-07-13',\n",
       " '2020-07-14',\n",
       " '2020-07-15',\n",
       " '2020-07-16',\n",
       " '2020-07-17',\n",
       " '2020-07-20',\n",
       " '2020-07-21',\n",
       " '2020-07-22',\n",
       " '2020-07-23',\n",
       " '2020-07-24',\n",
       " '2020-07-27',\n",
       " '2020-07-28',\n",
       " '2020-07-29',\n",
       " '2020-07-30',\n",
       " '2020-07-31',\n",
       " '2020-08-03',\n",
       " '2020-08-04',\n",
       " '2020-08-05',\n",
       " '2020-08-06',\n",
       " '2020-08-07',\n",
       " '2020-08-10',\n",
       " '2020-08-11',\n",
       " '2020-08-12',\n",
       " '2020-08-13',\n",
       " '2020-08-14',\n",
       " '2020-08-17',\n",
       " '2020-08-18',\n",
       " '2020-08-19',\n",
       " '2020-08-20',\n",
       " '2020-08-21',\n",
       " '2020-08-24',\n",
       " '2020-08-25',\n",
       " '2020-08-26',\n",
       " '2020-08-27',\n",
       " '2020-08-28',\n",
       " '2020-08-31',\n",
       " '2020-09-01',\n",
       " '2020-09-02',\n",
       " '2020-09-03',\n",
       " '2020-09-04',\n",
       " '2020-09-08',\n",
       " '2020-09-09',\n",
       " '2020-09-10',\n",
       " '2020-09-11',\n",
       " '2020-09-14',\n",
       " '2020-09-15',\n",
       " '2020-09-16',\n",
       " '2020-09-17',\n",
       " '2020-09-18',\n",
       " '2020-09-21',\n",
       " '2020-09-22',\n",
       " '2020-09-23',\n",
       " '2020-09-24',\n",
       " '2020-09-25',\n",
       " '2020-09-28',\n",
       " '2020-09-29',\n",
       " '2020-09-30',\n",
       " '2020-10-01',\n",
       " '2020-10-02',\n",
       " '2020-10-05',\n",
       " '2020-10-06',\n",
       " '2020-10-07',\n",
       " '2020-10-08',\n",
       " '2020-10-09',\n",
       " '2020-10-12',\n",
       " '2020-10-13',\n",
       " '2020-10-14',\n",
       " '2020-10-15',\n",
       " '2020-10-16',\n",
       " '2020-10-19',\n",
       " '2020-10-20',\n",
       " '2020-10-21',\n",
       " '2020-10-22',\n",
       " '2020-10-23',\n",
       " '2020-10-26',\n",
       " '2020-10-27',\n",
       " '2020-10-28',\n",
       " '2020-10-29',\n",
       " '2020-10-30',\n",
       " '2020-11-02',\n",
       " '2020-11-03',\n",
       " '2020-11-04',\n",
       " '2020-11-05',\n",
       " '2020-11-06',\n",
       " '2020-11-09',\n",
       " '2020-11-10',\n",
       " '2020-11-11',\n",
       " '2020-11-12',\n",
       " '2020-11-13',\n",
       " '2020-11-16',\n",
       " '2020-11-17',\n",
       " '2020-11-18',\n",
       " '2020-11-19',\n",
       " '2020-11-20',\n",
       " '2020-11-23',\n",
       " '2020-11-24',\n",
       " '2020-11-25',\n",
       " '2020-11-27',\n",
       " '2020-11-30',\n",
       " '2020-12-01',\n",
       " '2020-12-02',\n",
       " '2020-12-03',\n",
       " '2020-12-04',\n",
       " '2020-12-07',\n",
       " '2020-12-08',\n",
       " '2020-12-09',\n",
       " '2020-12-10',\n",
       " '2020-12-11',\n",
       " '2020-12-14',\n",
       " '2020-12-15',\n",
       " '2020-12-16',\n",
       " '2020-12-17',\n",
       " '2020-12-18',\n",
       " '2020-12-21',\n",
       " '2020-12-22',\n",
       " '2020-12-23',\n",
       " '2020-12-24',\n",
       " '2020-12-28',\n",
       " '2020-12-29',\n",
       " '2020-12-30',\n",
       " '2020-12-31',\n",
       " '2021-01-04',\n",
       " '2021-01-05',\n",
       " '2021-01-06',\n",
       " '2021-01-07',\n",
       " '2021-01-08',\n",
       " '2021-01-11',\n",
       " '2021-01-12',\n",
       " '2021-01-13',\n",
       " '2021-01-14',\n",
       " '2021-01-15',\n",
       " '2021-01-19',\n",
       " '2021-01-20',\n",
       " '2021-01-21',\n",
       " '2021-01-22',\n",
       " '2021-01-25',\n",
       " '2021-01-26',\n",
       " '2021-01-27',\n",
       " '2021-01-28',\n",
       " '2021-01-29',\n",
       " '2021-02-01',\n",
       " '2021-02-02',\n",
       " '2021-02-03',\n",
       " '2021-02-04',\n",
       " '2021-02-05',\n",
       " '2021-02-08',\n",
       " '2021-02-09',\n",
       " '2021-02-10',\n",
       " '2021-02-11',\n",
       " '2021-02-12',\n",
       " '2021-02-16',\n",
       " '2021-02-17',\n",
       " '2021-02-18',\n",
       " '2021-02-19',\n",
       " '2021-02-22',\n",
       " '2021-02-23',\n",
       " '2021-02-24',\n",
       " '2021-02-25',\n",
       " '2021-02-26',\n",
       " '2021-03-01',\n",
       " '2021-03-02',\n",
       " '2021-03-03',\n",
       " '2021-03-04',\n",
       " '2021-03-05',\n",
       " '2021-03-08',\n",
       " '2021-03-09',\n",
       " '2021-03-10',\n",
       " '2021-03-11',\n",
       " '2021-03-12',\n",
       " '2021-03-15',\n",
       " '2021-03-16',\n",
       " '2021-03-17',\n",
       " '2021-03-18',\n",
       " '2021-03-19',\n",
       " '2021-03-22',\n",
       " '2021-03-23',\n",
       " '2021-03-24',\n",
       " '2021-03-25',\n",
       " '2021-03-26',\n",
       " '2021-03-29',\n",
       " '2021-03-30',\n",
       " '2021-03-31',\n",
       " '2021-04-01',\n",
       " '2021-04-05',\n",
       " '2021-04-06',\n",
       " '2021-04-07',\n",
       " '2021-04-08',\n",
       " '2021-04-09',\n",
       " '2021-04-12',\n",
       " '2021-04-13',\n",
       " '2021-04-14',\n",
       " '2021-04-15',\n",
       " '2021-04-16',\n",
       " '2021-04-19',\n",
       " '2021-04-20',\n",
       " '2021-04-21',\n",
       " '2021-04-22',\n",
       " '2021-04-23',\n",
       " '2021-04-26',\n",
       " '2021-04-27',\n",
       " '2021-04-28',\n",
       " '2021-04-29',\n",
       " '2021-04-30',\n",
       " '2021-05-03',\n",
       " '2021-05-04',\n",
       " '2021-05-05',\n",
       " '2021-05-06',\n",
       " '2021-05-07',\n",
       " '2021-05-10',\n",
       " '2021-05-11',\n",
       " '2021-05-12',\n",
       " '2021-05-13',\n",
       " '2021-05-14',\n",
       " '2021-05-17',\n",
       " '2021-05-18',\n",
       " '2021-05-19',\n",
       " '2021-05-20',\n",
       " '2021-05-21',\n",
       " '2021-05-24',\n",
       " '2021-05-25',\n",
       " '2021-05-26',\n",
       " '2021-05-27',\n",
       " '2021-05-28',\n",
       " '2021-06-01',\n",
       " '2021-06-02',\n",
       " '2021-06-03',\n",
       " '2021-06-04',\n",
       " '2021-06-07',\n",
       " '2021-06-08',\n",
       " '2021-06-09',\n",
       " '2021-06-10',\n",
       " '2021-06-11',\n",
       " '2021-06-14',\n",
       " '2021-06-15',\n",
       " '2021-06-16',\n",
       " '2021-06-17',\n",
       " '2021-06-18',\n",
       " '2021-06-21',\n",
       " '2021-06-22',\n",
       " '2021-06-23',\n",
       " '2021-06-24',\n",
       " '2021-06-25',\n",
       " '2021-06-28',\n",
       " '2021-06-29',\n",
       " '2021-06-30',\n",
       " '2021-07-01',\n",
       " '2021-07-02',\n",
       " '2021-07-06',\n",
       " '2021-07-07',\n",
       " '2021-07-08',\n",
       " '2021-07-09',\n",
       " '2021-07-12',\n",
       " '2021-07-13',\n",
       " '2021-07-14',\n",
       " '2021-07-15',\n",
       " '2021-07-16',\n",
       " '2021-07-19',\n",
       " '2021-07-20',\n",
       " '2021-07-21',\n",
       " '2021-07-22',\n",
       " '2021-07-23',\n",
       " '2021-07-26',\n",
       " '2021-07-27',\n",
       " '2021-07-28',\n",
       " '2021-07-29',\n",
       " '2021-07-30',\n",
       " '2021-08-02',\n",
       " '2021-08-03',\n",
       " '2021-08-04',\n",
       " '2021-08-05',\n",
       " '2021-08-06',\n",
       " '2021-08-09',\n",
       " '2021-08-10',\n",
       " '2021-08-11',\n",
       " '2021-08-12',\n",
       " '2021-08-13',\n",
       " '2021-08-16',\n",
       " '2021-08-17',\n",
       " '2021-08-18',\n",
       " '2021-08-19',\n",
       " '2021-08-20',\n",
       " '2021-08-23',\n",
       " '2021-08-24',\n",
       " '2021-08-25',\n",
       " '2021-08-26',\n",
       " '2021-08-27',\n",
       " '2021-08-30',\n",
       " '2021-08-31',\n",
       " '2021-09-01',\n",
       " '2021-09-02',\n",
       " '2021-09-03',\n",
       " '2021-09-07',\n",
       " '2021-09-08',\n",
       " '2021-09-09',\n",
       " '2021-09-10',\n",
       " '2021-09-13',\n",
       " '2021-09-14',\n",
       " '2021-09-15',\n",
       " '2021-09-16',\n",
       " '2021-09-17',\n",
       " '2021-09-20',\n",
       " '2021-09-21',\n",
       " '2021-09-22',\n",
       " '2021-09-23',\n",
       " '2021-09-24',\n",
       " '2021-09-27',\n",
       " '2021-09-28',\n",
       " '2021-09-29',\n",
       " '2021-09-30',\n",
       " '2021-10-01',\n",
       " '2021-10-04',\n",
       " '2021-10-05',\n",
       " '2021-10-06',\n",
       " '2021-10-07',\n",
       " '2021-10-08',\n",
       " '2021-10-11',\n",
       " '2021-10-12',\n",
       " '2021-10-13',\n",
       " '2021-10-14',\n",
       " '2021-10-15',\n",
       " '2021-10-18',\n",
       " '2021-10-19',\n",
       " '2021-10-20',\n",
       " '2021-10-21',\n",
       " '2021-10-22',\n",
       " '2021-10-25',\n",
       " '2021-10-26',\n",
       " '2021-10-27',\n",
       " '2021-10-28',\n",
       " '2021-10-29',\n",
       " '2021-11-01',\n",
       " '2021-11-02',\n",
       " '2021-11-03',\n",
       " '2021-11-04',\n",
       " '2021-11-05',\n",
       " '2021-11-08',\n",
       " '2021-11-09',\n",
       " '2021-11-10',\n",
       " '2021-11-11',\n",
       " '2021-11-12',\n",
       " '2021-11-15',\n",
       " '2021-11-16',\n",
       " '2021-11-17',\n",
       " '2021-11-18',\n",
       " '2021-11-19',\n",
       " '2021-11-22',\n",
       " '2021-11-23',\n",
       " '2021-11-24',\n",
       " '2021-11-26',\n",
       " '2021-11-29',\n",
       " '2021-11-30',\n",
       " '2021-12-01',\n",
       " '2021-12-02',\n",
       " '2021-12-03',\n",
       " '2021-12-06',\n",
       " '2021-12-07',\n",
       " '2021-12-08',\n",
       " '2021-12-09',\n",
       " '2021-12-10',\n",
       " '2021-12-13',\n",
       " '2021-12-14',\n",
       " '2021-12-15',\n",
       " '2021-12-16',\n",
       " '2021-12-17',\n",
       " '2021-12-20',\n",
       " '2021-12-21',\n",
       " '2021-12-22',\n",
       " '2021-12-23',\n",
       " '2021-12-27',\n",
       " '2021-12-28',\n",
       " '2021-12-29',\n",
       " '2021-12-30',\n",
       " '2021-12-31',\n",
       " '2022-01-03',\n",
       " '2022-01-04',\n",
       " '2022-01-05',\n",
       " '2022-01-06',\n",
       " '2022-01-07',\n",
       " '2022-01-10',\n",
       " '2022-01-11',\n",
       " '2022-01-12',\n",
       " '2022-01-13',\n",
       " '2022-01-14',\n",
       " '2022-01-18',\n",
       " '2022-01-19',\n",
       " '2022-01-20',\n",
       " '2022-01-21',\n",
       " '2022-01-24',\n",
       " '2022-01-25',\n",
       " '2022-01-26',\n",
       " '2022-01-27',\n",
       " '2022-01-28',\n",
       " '2022-01-31',\n",
       " '2022-02-01',\n",
       " '2022-02-02',\n",
       " '2022-02-03',\n",
       " '2022-02-04',\n",
       " '2022-02-07',\n",
       " '2022-02-08',\n",
       " '2022-02-09',\n",
       " '2022-02-10',\n",
       " '2022-02-11',\n",
       " '2022-02-14',\n",
       " '2022-02-15',\n",
       " '2022-02-16',\n",
       " '2022-02-17',\n",
       " '2022-02-18',\n",
       " '2022-02-22',\n",
       " '2022-02-23',\n",
       " '2022-02-24',\n",
       " '2022-02-25',\n",
       " '2022-02-28',\n",
       " '2022-03-01',\n",
       " '2022-03-02',\n",
       " '2022-03-03',\n",
       " '2022-03-04',\n",
       " '2022-03-07',\n",
       " '2022-03-08',\n",
       " '2022-03-09',\n",
       " '2022-03-10',\n",
       " '2022-03-11',\n",
       " '2022-03-14',\n",
       " '2022-03-15',\n",
       " '2022-03-16',\n",
       " '2022-03-17',\n",
       " '2022-03-18',\n",
       " '2022-03-21',\n",
       " '2022-03-22',\n",
       " '2022-03-23',\n",
       " '2022-03-24',\n",
       " '2022-03-25',\n",
       " '2022-03-28',\n",
       " '2022-03-29',\n",
       " '2022-03-30',\n",
       " '2022-03-31',\n",
       " '2022-04-01',\n",
       " '2022-04-04',\n",
       " '2022-04-05',\n",
       " '2022-04-06',\n",
       " '2022-04-07',\n",
       " '2022-04-08',\n",
       " '2022-04-11',\n",
       " '2022-04-12',\n",
       " '2022-04-13',\n",
       " '2022-04-14',\n",
       " '2022-04-18',\n",
       " '2022-04-19',\n",
       " '2022-04-20',\n",
       " '2022-04-21',\n",
       " '2022-04-22',\n",
       " '2022-04-25',\n",
       " '2022-04-26',\n",
       " '2022-04-27',\n",
       " '2022-04-28',\n",
       " '2022-04-29',\n",
       " '2022-05-02',\n",
       " '2022-05-03',\n",
       " '2022-05-04',\n",
       " '2022-05-05',\n",
       " '2022-05-06',\n",
       " '2022-05-09',\n",
       " '2022-05-10',\n",
       " '2022-05-11',\n",
       " '2022-05-12',\n",
       " '2022-05-13',\n",
       " '2022-05-16',\n",
       " '2022-05-17',\n",
       " '2022-05-18',\n",
       " '2022-05-19',\n",
       " '2022-05-20',\n",
       " '2022-05-23',\n",
       " '2022-05-24',\n",
       " '2022-05-25',\n",
       " '2022-05-26',\n",
       " '2022-05-27',\n",
       " '2022-05-31',\n",
       " '2022-06-01',\n",
       " '2022-06-02',\n",
       " '2022-06-03',\n",
       " '2022-06-06',\n",
       " '2022-06-07',\n",
       " '2022-06-08',\n",
       " '2022-06-09',\n",
       " '2022-06-10',\n",
       " '2022-06-13',\n",
       " '2022-06-14',\n",
       " '2022-06-15',\n",
       " '2022-06-16',\n",
       " '2022-06-17',\n",
       " '2022-06-21',\n",
       " '2022-06-22',\n",
       " '2022-06-23',\n",
       " '2022-06-24',\n",
       " '2022-06-27',\n",
       " '2022-06-28',\n",
       " '2022-06-29',\n",
       " '2022-06-30',\n",
       " '2022-07-01',\n",
       " '2022-07-05',\n",
       " '2022-07-06',\n",
       " '2022-07-07',\n",
       " '2022-07-08',\n",
       " '2022-07-11',\n",
       " '2022-07-12',\n",
       " '2022-07-13',\n",
       " '2022-07-14',\n",
       " '2022-07-15',\n",
       " '2022-07-18',\n",
       " '2022-07-19',\n",
       " '2022-07-20',\n",
       " '2022-07-21',\n",
       " '2022-07-22',\n",
       " '2022-07-25',\n",
       " '2022-07-26',\n",
       " '2022-07-27',\n",
       " '2022-07-28',\n",
       " '2022-07-29',\n",
       " '2022-08-01',\n",
       " '2022-08-02',\n",
       " '2022-08-03',\n",
       " '2022-08-04',\n",
       " '2022-08-05',\n",
       " '2022-08-08',\n",
       " '2022-08-09',\n",
       " '2022-08-10',\n",
       " '2022-08-11',\n",
       " '2022-08-12',\n",
       " '2022-08-15',\n",
       " '2022-08-16',\n",
       " '2022-08-17',\n",
       " '2022-08-18',\n",
       " '2022-08-19',\n",
       " '2022-08-22',\n",
       " '2022-08-23',\n",
       " '2022-08-24',\n",
       " '2022-08-25',\n",
       " '2022-08-26',\n",
       " '2022-08-29',\n",
       " '2022-08-30',\n",
       " '2022-08-31',\n",
       " '2022-09-01',\n",
       " '2022-09-02',\n",
       " '2022-09-06',\n",
       " '2022-09-07',\n",
       " '2022-09-08',\n",
       " '2022-09-09',\n",
       " '2022-09-12',\n",
       " '2022-09-13',\n",
       " '2022-09-14',\n",
       " '2022-09-15',\n",
       " '2022-09-16',\n",
       " '2022-09-19',\n",
       " '2022-09-20',\n",
       " '2022-09-21',\n",
       " '2022-09-22',\n",
       " '2022-09-23',\n",
       " '2022-09-26',\n",
       " '2022-09-27',\n",
       " '2022-09-28',\n",
       " '2022-09-29',\n",
       " '2022-09-30',\n",
       " '2022-10-03',\n",
       " '2022-10-04',\n",
       " '2022-10-05',\n",
       " '2022-10-06',\n",
       " '2022-10-07',\n",
       " '2022-10-10',\n",
       " '2022-10-11',\n",
       " '2022-10-12',\n",
       " '2022-10-13',\n",
       " '2022-10-14',\n",
       " '2022-10-17',\n",
       " '2022-10-18',\n",
       " '2022-10-19',\n",
       " '2022-10-20',\n",
       " '2022-10-21',\n",
       " '2022-10-24',\n",
       " '2022-10-25',\n",
       " '2022-10-26',\n",
       " '2022-10-27',\n",
       " '2022-10-28',\n",
       " '2022-10-31',\n",
       " '2022-11-01',\n",
       " '2022-11-02',\n",
       " '2022-11-03',\n",
       " '2022-11-04',\n",
       " '2022-11-07',\n",
       " '2022-11-08',\n",
       " '2022-11-09',\n",
       " '2022-11-10',\n",
       " '2022-11-11',\n",
       " '2022-11-14',\n",
       " '2022-11-15',\n",
       " '2022-11-16',\n",
       " '2022-11-17',\n",
       " '2022-11-18',\n",
       " '2022-11-21',\n",
       " '2022-11-22',\n",
       " '2022-11-23',\n",
       " '2022-11-25',\n",
       " '2022-11-28',\n",
       " '2022-11-29',\n",
       " '2022-11-30',\n",
       " '2022-12-01',\n",
       " '2022-12-02',\n",
       " '2022-12-05',\n",
       " '2022-12-06',\n",
       " '2022-12-07',\n",
       " '2022-12-08',\n",
       " '2022-12-09',\n",
       " '2022-12-12',\n",
       " '2022-12-13',\n",
       " '2022-12-14',\n",
       " '2022-12-15',\n",
       " '2022-12-16',\n",
       " '2022-12-19',\n",
       " '2022-12-20',\n",
       " '2022-12-21',\n",
       " '2022-12-22',\n",
       " '2022-12-23',\n",
       " '2022-12-27',\n",
       " '2022-12-28',\n",
       " '2022-12-29',\n",
       " '2022-12-30',\n",
       " '2023-01-03',\n",
       " '2023-01-04',\n",
       " '2023-01-05',\n",
       " '2023-01-06',\n",
       " '2023-01-09',\n",
       " '2023-01-10',\n",
       " '2023-01-11',\n",
       " '2023-01-12',\n",
       " '2023-01-13',\n",
       " '2023-01-17',\n",
       " '2023-01-18',\n",
       " '2023-01-19',\n",
       " '2023-01-20',\n",
       " '2023-01-23',\n",
       " '2023-01-24',\n",
       " '2023-01-25',\n",
       " '2023-01-26',\n",
       " '2023-01-27',\n",
       " '2023-01-30',\n",
       " '2023-01-31',\n",
       " '2023-02-01',\n",
       " '2023-02-02',\n",
       " '2023-02-03',\n",
       " '2023-02-06',\n",
       " '2023-02-07',\n",
       " '2023-02-08',\n",
       " '2023-02-09',\n",
       " '2023-02-10',\n",
       " '2023-02-13',\n",
       " '2023-02-14',\n",
       " '2023-02-15',\n",
       " '2023-02-16',\n",
       " '2023-02-17',\n",
       " '2023-02-21',\n",
       " '2023-02-22',\n",
       " '2023-02-23',\n",
       " '2023-02-24',\n",
       " '2023-02-27',\n",
       " '2023-02-28',\n",
       " '2023-03-01',\n",
       " '2023-03-02',\n",
       " '2023-03-03',\n",
       " '2023-03-06',\n",
       " '2023-03-07',\n",
       " '2023-03-08',\n",
       " '2023-03-09',\n",
       " '2023-03-10',\n",
       " '2023-03-13',\n",
       " '2023-03-14',\n",
       " '2023-03-15',\n",
       " '2023-03-16',\n",
       " '2023-03-17',\n",
       " '2023-03-20',\n",
       " '2023-03-21',\n",
       " '2023-03-22',\n",
       " '2023-03-23',\n",
       " '2023-03-24',\n",
       " '2023-03-27',\n",
       " '2023-03-28',\n",
       " '2023-03-29',\n",
       " '2023-03-30',\n",
       " '2023-03-31',\n",
       " '2023-04-03',\n",
       " '2023-04-04',\n",
       " '2023-04-05',\n",
       " '2023-04-06',\n",
       " '2023-04-10',\n",
       " '2023-04-11',\n",
       " '2023-04-12',\n",
       " '2023-04-13',\n",
       " '2023-04-14',\n",
       " '2023-04-17',\n",
       " '2023-04-18',\n",
       " '2023-04-19',\n",
       " '2023-04-20',\n",
       " '2023-04-21',\n",
       " '2023-04-24',\n",
       " '2023-04-25',\n",
       " '2023-04-26',\n",
       " '2023-04-27',\n",
       " '2023-04-28',\n",
       " '2023-05-01',\n",
       " '2023-05-02',\n",
       " '2023-05-03',\n",
       " '2023-05-04',\n",
       " '2023-05-05',\n",
       " '2023-05-08',\n",
       " '2023-05-09',\n",
       " '2023-05-10',\n",
       " '2023-05-11',\n",
       " '2023-05-12',\n",
       " '2023-05-15',\n",
       " '2023-05-16',\n",
       " '2023-05-17',\n",
       " '2023-05-18',\n",
       " '2023-05-19',\n",
       " '2023-05-22',\n",
       " '2023-05-23',\n",
       " '2023-05-24',\n",
       " '2023-05-25',\n",
       " '2023-05-26',\n",
       " '2023-05-30',\n",
       " '2023-05-31',\n",
       " '2023-06-01',\n",
       " '2023-06-02',\n",
       " '2023-06-05',\n",
       " '2023-06-06',\n",
       " '2023-06-07',\n",
       " '2023-06-08',\n",
       " '2023-06-09',\n",
       " '2023-06-12',\n",
       " '2023-06-13',\n",
       " '2023-06-14',\n",
       " '2023-06-15',\n",
       " '2023-06-16',\n",
       " '2023-06-20',\n",
       " '2023-06-21',\n",
       " '2023-06-22',\n",
       " '2023-06-23',\n",
       " '2023-06-26',\n",
       " '2023-06-27',\n",
       " '2023-06-28',\n",
       " '2023-06-29',\n",
       " '2023-06-30',\n",
       " '2023-07-03',\n",
       " '2023-07-05',\n",
       " '2023-07-06',\n",
       " '2023-07-07',\n",
       " '2023-07-10',\n",
       " '2023-07-11',\n",
       " '2023-07-12',\n",
       " '2023-07-13',\n",
       " '2023-07-14',\n",
       " '2023-07-17',\n",
       " '2023-07-18',\n",
       " '2023-07-19',\n",
       " '2023-07-20',\n",
       " '2023-07-21',\n",
       " '2023-07-24',\n",
       " '2023-07-25',\n",
       " '2023-07-26',\n",
       " '2023-07-27',\n",
       " '2023-07-28',\n",
       " '2023-07-31',\n",
       " '2023-08-01',\n",
       " '2023-08-02',\n",
       " '2023-08-03',\n",
       " '2023-08-04',\n",
       " '2023-08-07',\n",
       " '2023-08-08',\n",
       " '2023-08-09',\n",
       " '2023-08-10',\n",
       " '2023-08-11',\n",
       " '2023-08-14',\n",
       " '2023-08-15',\n",
       " '2023-08-16',\n",
       " '2023-08-17',\n",
       " '2023-08-18',\n",
       " '2023-08-21',\n",
       " '2023-08-22',\n",
       " '2023-08-23',\n",
       " '2023-08-24',\n",
       " '2023-08-25',\n",
       " '2023-08-28',\n",
       " '2023-08-29',\n",
       " '2023-08-30',\n",
       " '2023-08-31',\n",
       " '2023-09-01',\n",
       " '2023-09-05',\n",
       " '2023-09-06',\n",
       " '2023-09-07',\n",
       " '2023-09-08',\n",
       " '2023-09-11',\n",
       " '2023-09-12',\n",
       " '2023-09-13',\n",
       " '2023-09-14',\n",
       " '2023-09-15',\n",
       " '2023-09-18',\n",
       " '2023-09-19',\n",
       " '2023-09-20',\n",
       " '2023-09-21',\n",
       " '2023-09-22',\n",
       " '2023-09-25',\n",
       " '2023-09-26',\n",
       " '2023-09-27',\n",
       " '2023-09-28',\n",
       " '2023-09-29',\n",
       " '2023-10-02',\n",
       " '2023-10-03',\n",
       " '2023-10-04',\n",
       " '2023-10-05',\n",
       " '2023-10-06',\n",
       " '2023-10-09',\n",
       " '2023-10-10',\n",
       " '2023-10-11',\n",
       " '2023-10-12',\n",
       " '2023-10-13',\n",
       " '2023-10-16',\n",
       " '2023-10-17',\n",
       " '2023-10-18',\n",
       " '2023-10-19',\n",
       " '2023-10-20',\n",
       " '2023-10-23',\n",
       " '2023-10-24',\n",
       " '2023-10-25',\n",
       " '2023-10-26',\n",
       " '2023-10-27',\n",
       " '2023-10-30',\n",
       " '2023-10-31',\n",
       " '2023-11-01',\n",
       " '2023-11-02',\n",
       " '2023-11-03',\n",
       " '2023-11-06',\n",
       " '2023-11-07',\n",
       " '2023-11-08',\n",
       " '2023-11-09',\n",
       " '2023-11-10',\n",
       " '2023-11-13',\n",
       " '2023-11-14',\n",
       " '2023-11-15',\n",
       " '2023-11-16',\n",
       " '2023-11-17',\n",
       " '2023-11-20',\n",
       " '2023-11-21',\n",
       " '2023-11-22',\n",
       " '2023-11-24',\n",
       " '2023-11-27',\n",
       " '2023-11-28',\n",
       " '2023-11-29',\n",
       " '2023-11-30',\n",
       " '2023-12-01',\n",
       " '2023-12-04',\n",
       " '2023-12-05',\n",
       " '2023-12-06',\n",
       " '2023-12-07',\n",
       " '2023-12-08',\n",
       " '2023-12-11',\n",
       " '2023-12-12',\n",
       " '2023-12-13',\n",
       " '2023-12-14',\n",
       " '2023-12-15',\n",
       " '2023-12-18',\n",
       " '2023-12-19',\n",
       " '2023-12-20',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[_name].index.strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d413a0e-e3a8-4e96-b4dd-8cfd4563bef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-06-06',\n",
       " '2023-06-07',\n",
       " '2023-06-08',\n",
       " '2023-06-09',\n",
       " '2023-06-12',\n",
       " '2023-06-13',\n",
       " '2023-06-14',\n",
       " '2023-06-15',\n",
       " '2023-06-16',\n",
       " '2023-06-20',\n",
       " '2023-06-21',\n",
       " '2023-06-22',\n",
       " '2023-06-23',\n",
       " '2023-06-26',\n",
       " '2023-06-27',\n",
       " '2023-06-28',\n",
       " '2023-06-29',\n",
       " '2023-06-30',\n",
       " '2023-07-03',\n",
       " '2023-07-05',\n",
       " '2023-07-06',\n",
       " '2023-07-07',\n",
       " '2023-07-10',\n",
       " '2023-07-11',\n",
       " '2023-07-12',\n",
       " '2023-07-13',\n",
       " '2023-07-14',\n",
       " '2023-07-17',\n",
       " '2023-07-18',\n",
       " '2023-07-19',\n",
       " '2023-07-20',\n",
       " '2023-07-21',\n",
       " '2023-07-24',\n",
       " '2023-07-25',\n",
       " '2023-07-26',\n",
       " '2023-07-27',\n",
       " '2023-07-28',\n",
       " '2023-07-31',\n",
       " '2023-08-01',\n",
       " '2023-08-02',\n",
       " '2023-08-03',\n",
       " '2023-08-04',\n",
       " '2023-08-07',\n",
       " '2023-08-08',\n",
       " '2023-08-09',\n",
       " '2023-08-10',\n",
       " '2023-08-11',\n",
       " '2023-08-14',\n",
       " '2023-08-15',\n",
       " '2023-08-16',\n",
       " '2023-08-17',\n",
       " '2023-08-18',\n",
       " '2023-08-21',\n",
       " '2023-08-22',\n",
       " '2023-08-23',\n",
       " '2023-08-24',\n",
       " '2023-08-25',\n",
       " '2023-08-28',\n",
       " '2023-08-29',\n",
       " '2023-08-30',\n",
       " '2023-08-31',\n",
       " '2023-09-01',\n",
       " '2023-09-05',\n",
       " '2023-09-06',\n",
       " '2023-09-07',\n",
       " '2023-09-08',\n",
       " '2023-09-11',\n",
       " '2023-09-12',\n",
       " '2023-09-13',\n",
       " '2023-09-14',\n",
       " '2023-09-15',\n",
       " '2023-09-18',\n",
       " '2023-09-19',\n",
       " '2023-09-20',\n",
       " '2023-09-21',\n",
       " '2023-09-22',\n",
       " '2023-09-25',\n",
       " '2023-09-26',\n",
       " '2023-09-27',\n",
       " '2023-09-28',\n",
       " '2023-09-29',\n",
       " '2023-10-02',\n",
       " '2023-10-03',\n",
       " '2023-10-04',\n",
       " '2023-10-05',\n",
       " '2023-10-06',\n",
       " '2023-10-09',\n",
       " '2023-10-10',\n",
       " '2023-10-11',\n",
       " '2023-10-12',\n",
       " '2023-10-13',\n",
       " '2023-10-16',\n",
       " '2023-10-17',\n",
       " '2023-10-18',\n",
       " '2023-10-19',\n",
       " '2023-10-20',\n",
       " '2023-10-23',\n",
       " '2023-10-24',\n",
       " '2023-10-25',\n",
       " '2023-10-26',\n",
       " '2023-10-27',\n",
       " '2023-10-30',\n",
       " '2023-10-31',\n",
       " '2023-11-01',\n",
       " '2023-11-02',\n",
       " '2023-11-03',\n",
       " '2023-11-06',\n",
       " '2023-11-07',\n",
       " '2023-11-08',\n",
       " '2023-11-09',\n",
       " '2023-11-10',\n",
       " '2023-11-13',\n",
       " '2023-11-14',\n",
       " '2023-11-15',\n",
       " '2023-11-16',\n",
       " '2023-11-17',\n",
       " '2023-11-20',\n",
       " '2023-11-21',\n",
       " '2023-11-22',\n",
       " '2023-11-24',\n",
       " '2023-11-27',\n",
       " '2023-11-28',\n",
       " '2023-11-29',\n",
       " '2023-11-30',\n",
       " '2023-12-01',\n",
       " '2023-12-04',\n",
       " '2023-12-05',\n",
       " '2023-12-06',\n",
       " '2023-12-07',\n",
       " '2023-12-08',\n",
       " '2023-12-11',\n",
       " '2023-12-12',\n",
       " '2023-12-13',\n",
       " '2023-12-14',\n",
       " '2023-12-15',\n",
       " '2023-12-18',\n",
       " '2023-12-19',\n",
       " '2023-12-20',\n",
       " '2023-12-21',\n",
       " '2023-12-22',\n",
       " '2023-12-26',\n",
       " '2023-12-27',\n",
       " '2023-12-28',\n",
       " '2023-12-29',\n",
       " '2024-01-02',\n",
       " '2024-01-03',\n",
       " '2024-01-04',\n",
       " '2024-01-05',\n",
       " '2024-01-08',\n",
       " '2024-01-09',\n",
       " '2024-01-10',\n",
       " '2024-01-11',\n",
       " '2024-01-12',\n",
       " '2024-01-16',\n",
       " '2024-01-17',\n",
       " '2024-01-18',\n",
       " '2024-01-19',\n",
       " '2024-01-22',\n",
       " '2024-01-23',\n",
       " '2024-01-24',\n",
       " '2024-01-25',\n",
       " '2024-01-26',\n",
       " '2024-01-29',\n",
       " '2024-01-30',\n",
       " '2024-01-31',\n",
       " '2024-02-01',\n",
       " '2024-02-02',\n",
       " '2024-02-05',\n",
       " '2024-02-06',\n",
       " '2024-02-07',\n",
       " '2024-02-08',\n",
       " '2024-02-09',\n",
       " '2024-02-12',\n",
       " '2024-02-13',\n",
       " '2024-02-14',\n",
       " '2024-02-15',\n",
       " '2024-02-16',\n",
       " '2024-02-20',\n",
       " '2024-02-21',\n",
       " '2024-02-22',\n",
       " '2024-02-23',\n",
       " '2024-02-26',\n",
       " '2024-02-27',\n",
       " '2024-02-28',\n",
       " '2024-02-29',\n",
       " '2024-03-01',\n",
       " '2024-03-04',\n",
       " '2024-03-05',\n",
       " '2024-03-06',\n",
       " '2024-03-07',\n",
       " '2024-03-08',\n",
       " '2024-03-11',\n",
       " '2024-03-12',\n",
       " '2024-03-13',\n",
       " '2024-03-14',\n",
       " '2024-03-15',\n",
       " '2024-03-18',\n",
       " '2024-03-19',\n",
       " '2024-03-20',\n",
       " '2024-03-21',\n",
       " '2024-03-22',\n",
       " '2024-03-25',\n",
       " '2024-03-26',\n",
       " '2024-03-27',\n",
       " '2024-03-28',\n",
       " '2024-04-01',\n",
       " '2024-04-02',\n",
       " '2024-04-03',\n",
       " '2024-04-04',\n",
       " '2024-04-05',\n",
       " '2024-04-08',\n",
       " '2024-04-09',\n",
       " '2024-04-10',\n",
       " '2024-04-11',\n",
       " '2024-04-12']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test[_name].index.strftime('%Y-%m-%d').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4aae1",
   "metadata": {},
   "source": [
    "## Load BERT embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0702b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tamk/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Input ids are automatically padded from 3002 to 3072 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3002])\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# embedder = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "from transformers import LongformerModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "embedder = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "max_token_n = 4096\n",
    "\n",
    "# test model\n",
    "text = 'TWEETS' * 1000\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input.input_ids.shape)\n",
    "_  = embedder(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e2a23",
   "metadata": {},
   "source": [
    "## Dataset generation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f520e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def embed_by_bert(text):\n",
    "    _tkn = tokenizer(text, return_tensors='pt') \n",
    "    if _tkn.input_ids.shape[-1] >= max_token_n:\n",
    "        _tkn = _tkn[:,:max_token_n]\n",
    "    _emb = embedder(**_tkn).last_hidden_state[:,0,:].detach().to(th.float32)\n",
    "    return _emb\n",
    "\n",
    "def embed_one_by_one(list_list_texts, text_to_emb_dict, embed_func=None):\n",
    "    embs = []\n",
    "    for _i, _txts in enumerate(list_list_texts):\n",
    "        _embs = []\n",
    "        for _txt in _txts:\n",
    "            if _txt in text_to_emb_dict: \n",
    "                _emb = text_to_emb_dict.get(_txt)\n",
    "            else:\n",
    "                _emb = embed_func(_txt)\n",
    "                text_to_emb_dict[_txt] = _emb\n",
    "            _embs.append(_emb)\n",
    "        embs.append(_embs)\n",
    "    return embs\n",
    "\n",
    "def embed_text(dataset, list_list_texts, apply_pca=True):\n",
    "    unique_embs = dict()\n",
    "    dataset.unique_embs = unique_embs\n",
    "\n",
    "    list_list_embs_p_step = embed_one_by_one(list_list_texts, unique_embs, embed_by_bert)\n",
    "    list_embs_p_company = [th.cat(_embs, dim=0) for _embs in list_list_embs_p_step]\n",
    "    \n",
    "    #print(unique_embs)\n",
    "    \n",
    "    if apply_pca is not None:\n",
    "        apply_pca = {} if apply_pca is True else apply_pca\n",
    "        n_components = apply_pca if isinstance(apply_pca, int) else apply_pca.get('n_components', 10)\n",
    "        \n",
    "        # create concatenated embedding\n",
    "        unique_embs_txts, unique_embs_vals = list(zip(*unique_embs.items()))\n",
    "        unique_embs_cat = th.cat(unique_embs_vals, dim=0)\n",
    "        \n",
    "        # apply PCA\n",
    "        n_components = min(n_components, len(unique_embs_txts))\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(unique_embs_cat.numpy())\n",
    "        \n",
    "        #  transform\n",
    "        unique_embs_pca_cat = th.tensor(pca.transform(unique_embs_cat))\n",
    "        unique_embs_pca = dict(zip(unique_embs.keys(), th.split(unique_embs_pca_cat, 1)))\n",
    "        dataset.unique_embs_pca = unique_embs_pca\n",
    "        \n",
    "        #print(unique_embs_pca)\n",
    "        # recreate datastructure\n",
    "        list_list_embs_p_step_pca = embed_one_by_one(list_list_texts, unique_embs_pca)\n",
    "        list_embs_p_company = [th.cat(_embs, dim=0).to(th.float32) for _embs in list_list_embs_p_step_pca]\n",
    "\n",
    "    return list_embs_p_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "81b96f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, \n",
    "                 input_window=4, output_window=1,\n",
    "                 use_transformer=False, \n",
    "                 input_prices=['Close_x', 'Close_y'], output_prices=['Close_x'], \n",
    "                 include_text= False, apply_pca=10, # or False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        data (filepath of saved path)\n",
    "        data (list of pd.DataFrame): List of dataframes, each containing columns:\n",
    "                                          'time', 'stock price', 'stock index price', 'text message'\n",
    "        input_window (int): Number of timesteps in each input sequence.\n",
    "        output_window (int): Number of timesteps in each target sequence.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.sequences = [] # store chunks (data point)\n",
    "        self.sequences_raw = []   # store a company's entire time series sequence \n",
    "        self.sequences_raw_embs = [] # store a company's entire time series sequence (text embeddings including PCA if applied)\n",
    "        self.unique_embs = {}\n",
    "        self.unique_embs_pca = {}\n",
    "        \n",
    "        self.names = []\n",
    "        self.dates = []\n",
    "        \n",
    "        self.apply_pca = apply_pca\n",
    "        \n",
    "        if use_transformer:\n",
    "            output_window = 1\n",
    "        \n",
    "        if isinstance(data, str) and os.path.exists(data):\n",
    "            self.sequences, self.sequences_raw, self.sequences_raw_embs, \\\n",
    "            self.unique_embs, self.unique_embs_pca = pickle.load(open(data, 'rb'))\n",
    "        else:\n",
    "            self.input_window = input_window\n",
    "            self.output_window = output_window\n",
    "        \n",
    "            if include_text:\n",
    "                all_texts = [_df[include_text].values.tolist() for _df in data]\n",
    "                list_embs_p_company = self.embed_text(all_texts)\n",
    "\n",
    "            for _i_df, (_name, df) in enumerate(data.items()):\n",
    "                self.names.append(_name)\n",
    "                if _i_df == 0:\n",
    "                    self.dates = df.index.strftime('%Y-%m-%d').tolist()\n",
    "                \n",
    "                t = df[input_prices].shape[0]\n",
    "                seq_in = th.tensor(df[input_prices].values).reshape(t,-1).to(th.float32)\n",
    "                self.sequences_raw.append(seq_in)\n",
    "                \n",
    "                seq_tgt = th.tensor(df[output_prices].values).reshape(t,-1).to(th.float32)\n",
    "                if include_text:\n",
    "                    embs = list_embs_p_company[_i_df]\n",
    "                    self.sequences_raw_embs.append(embs)\n",
    "\n",
    "                num_sequences = t - self.input_window - self.output_window + 1\n",
    "\n",
    "                for i in range(num_sequences):\n",
    "                    input_start = i\n",
    "                    input_end = i + self.input_window\n",
    "                    \n",
    "                    target_start = input_start + 1\n",
    "                    target_end = input_end + 1\n",
    "\n",
    "                    seq_in_ = [seq_in[input_start:input_end]]\n",
    "                    if include_text:\n",
    "                        seq_in_.append(embs[input_start:input_end])\n",
    "\n",
    "                    seq_in_ = th.cat(seq_in_, dim=1)\n",
    "                    seq_tgt_ = seq_tgt[target_start:target_end]\n",
    "                    self.sequences.append((seq_in_, seq_tgt_, th.tensor([[_i_df, input_start, target_end]])))\n",
    "\n",
    "    def embed_text(self, list_list_texts):\n",
    "        return embed_text(self, list_list_texts, apply_pca=self.apply_pca)\n",
    "    \n",
    "    def save_dataset(self, filepath):\n",
    "        pickle.dump([self.sequences, self.sequences_raw, self.sequences_raw_embs, \n",
    "                     self.unique_embs, self.unique_embs_pca], open(filepath, 'wb'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sequence, target_sequence, idx, = self.sequences[idx]\n",
    "        return input_sequence, target_sequence, idx\n",
    "\n",
    "    def get_sequence_from_index(self, index, embed_with_empty=False):\n",
    "        i_company, i_start, _ = index.squeeze().tolist()\n",
    "        seq = seq_vals = self.sequences_raw[i_company][i_start:].unsqueeze(0)\n",
    "        len_seq = seq.shape[1]\n",
    "        \n",
    "        if self.unique_embs:\n",
    "            if embed_with_empty:\n",
    "                unique_embs = self.unique_embs_pca if self.apply_pca else self.unique_embs\n",
    "                seq_emb = unique_embs[''].to(th.float32).unsqueeze(0).repeat(1, len_seq, 1)\n",
    "            else:\n",
    "                seq_emb = self.sequences_raw_embs[i_company][i_start:].unsqueeze(0)\n",
    "            seq = th.cat((seq_vals, seq_emb), dim=2)\n",
    "        return seq\n",
    "\n",
    "    def get_sequence_by_name_date(self, name, date=None, embed_with_empty=False):\n",
    "        i_company = self.names.index(name)\n",
    "        i_start = self.dates.index(date) if date else 0\n",
    "        \n",
    "        seq = seq_vals = self.sequences_raw[i_company][i_start:].unsqueeze(0)\n",
    "        len_seq = seq.shape[1]\n",
    "        \n",
    "        if self.unique_embs:\n",
    "            if embed_with_empty:\n",
    "                unique_embs = self.unique_embs_pca if self.apply_pca else self.unique_embs\n",
    "                seq_emb = unique_embs[''].to(th.float32).unsqueeze(0).repeat(1, len_seq, 1)\n",
    "            else:\n",
    "                seq_emb = self.sequences_raw_embs[i_company][i_start:].unsqueeze(0)\n",
    "            seq = th.cat((seq_vals, seq_emb), dim=2)\n",
    "        return seq\n",
    "        \n",
    "    @property\n",
    "    def input_dim(self):\n",
    "        return self.sequences[0][0].shape[-1]\n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        return self.sequences[0][1].shape[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee39dc9-6247-402c-a477-04f6c27effd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a56acb3-cb7a-44cf-80ed-86674f097ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging tool: ignore\n",
    "def reduce(x, apply=False):\n",
    "    if apply:\n",
    "        return th.linalg.norm(x) \n",
    "    return x\n",
    "    \n",
    "def inspect_model(model, save_data=False, apply_reduce=False, show_grad=True):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"Layer: {name}\")\n",
    "            print(\"Weights:\",reduce(param.data, apply_reduce))\n",
    "            if isinstance(save_data, dict):\n",
    "                save_data.setdefault('w', {})[name] = param.data\n",
    "                save_data.setdefault('g', {})[name] = param.grad\n",
    "            if show_grad:\n",
    "                if param.grad is not None:\n",
    "                    print(\"Gradients:\", reduce(param.grad, apply_reduce))\n",
    "                else:\n",
    "                    print(\"Gradients: None (check if backward has been called and if the parameter requires gradients)\")\n",
    "            #break\n",
    "            print('-'*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5bc09",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3ad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(DATA, open(FILEPATH, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff53ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA = pickle.load(open(FILEPATH, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8aa6b5",
   "metadata": {},
   "source": [
    "## Important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b651401",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window = seq_length = 30  # e.g., 5 days input\n",
    "output_window = 1  # e.g., 2 days to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789a8b0",
   "metadata": {},
   "source": [
    "## Fake Data (no longer valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9d776c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# # Example fake data generation\n",
    "\n",
    "# np.random.seed(42)\n",
    "# data_length = 10\n",
    "# df1 = pd.DataFrame({\n",
    "#     'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "#     'price_main': np.random.rand(data_length) * 100,\n",
    "#     'price_sec': np.random.rand(data_length) * 1000,\n",
    "#     'text': np.random.choice(['news', '', 'alert', 'none'], data_length)\n",
    "# })\n",
    "\n",
    "# df2 = pd.DataFrame({\n",
    "#     'time': pd.date_range(start='1/1/2020', periods=data_length, freq='D'),\n",
    "#     'price_main': np.random.rand(data_length) * 100,\n",
    "#     'price_sec': np.random.rand(data_length) * 1000,\n",
    "#     'text': np.random.choice(['announcement', 'report', 'alert', 'none'], data_length)\n",
    "# })\n",
    "\n",
    "# dataframes = [df1, df2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ed7fc",
   "metadata": {},
   "source": [
    "* you will need to replace this with your own data\n",
    "* each df relates to a company\n",
    "* additionally, normalise your company's price data from 0 to 1\n",
    "* the stock prices should be normalised the same way across all companies\n",
    "* here 'price_main' and 'price_sec' represents 'stock' and 'stock index'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d82fb",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09afb9",
   "metadata": {},
   "source": [
    "* the dataset generator can be used to make data for different model architecture...\n",
    "* you can have it predict from stock and index price, and output in stock price... you can also include index price in the output... adjust the output_prices accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f282a78-ba1d-4f03-a6e6-c2c2b5269b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_stock_indices = ['close_nasdaq_composite', 'close_sp_500', 'close_dow_jones']\n",
    "\n",
    "input_prices = ['close'] + name_stock_indices\n",
    "output_prices = ['close'] + name_stock_indices\n",
    "text_column = None  #'Text'\n",
    "\n",
    "apply_pca = 10  # only relevant when there are text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9cf4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (total): Train: 8320 & Test: 1850\n",
      "Dataset size (per company): Train: 862 & Test: 215\n"
     ]
    }
   ],
   "source": [
    "dataset_train = StockDataset(dfs_train, \n",
    "                             input_window, output_window, \n",
    "                             input_prices=input_prices, output_prices=output_prices, include_text=text_column,\n",
    "                             apply_pca=apply_pca)\n",
    "dataset_test = StockDataset(dfs_test, \n",
    "                            input_window, output_window, \n",
    "                            input_prices=input_prices, output_prices=output_prices, include_text=text_column,\n",
    "                            apply_pca=apply_pca)\n",
    "\n",
    "n_train = len(dataset_train)\n",
    "n_test = len(dataset_test)\n",
    "print(\"Dataset size (total): Train: {} & Test: {}\".format(n_train, n_test))\n",
    "print(\"Dataset size (per company): Train: {} & Test: {}\".format(n_train_per_company, n_test_per_company))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91330b10-a3e3-4d62-ba5a-f4d980ed3aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.014, 0.225, 0.331, 0.473],\n",
       "         [0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         ...,\n",
       "         [0.475, 0.651, 0.657, 0.682],\n",
       "         [0.492, 0.666, 0.678, 0.715],\n",
       "         [0.502, 0.665, 0.675, 0.706]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on how to get particular subsequence for date and company:\n",
    "dataset_train.get_sequence_by_name_date('tesla', '2020-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b351ec5-58f2-49ce-a8d3-ca36703db457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 857, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example on how to get particular subsequence based on stored index:\n",
    "dataset_train.get_sequence_from_index(th.tensor([0, 5, 0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b724022e-471f-404f-866a-d12ceecfb905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.014, 0.225, 0.331, 0.473],\n",
       "         [0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         [0.023, 0.237, 0.337, 0.479],\n",
       "         [0.021, 0.245, 0.344, 0.489],\n",
       "         [0.020, 0.242, 0.341, 0.482],\n",
       "         [0.028, 0.252, 0.348, 0.486],\n",
       "         [0.031, 0.250, 0.347, 0.488],\n",
       "         [0.027, 0.250, 0.349, 0.492],\n",
       "         [0.026, 0.261, 0.358, 0.505],\n",
       "         [0.026, 0.264, 0.362, 0.507],\n",
       "         [0.032, 0.262, 0.359, 0.500],\n",
       "         [0.036, 0.263, 0.359, 0.499],\n",
       "         [0.036, 0.265, 0.361, 0.498],\n",
       "         [0.035, 0.256, 0.351, 0.490],\n",
       "         [0.034, 0.238, 0.334, 0.469],\n",
       "         [0.036, 0.251, 0.344, 0.478],\n",
       "         [0.038, 0.252, 0.343, 0.478],\n",
       "         [0.048, 0.254, 0.347, 0.484],\n",
       "         [0.050, 0.239, 0.328, 0.456],\n",
       "         [0.072, 0.252, 0.335, 0.462],\n",
       "         [0.091, 0.272, 0.351, 0.482],\n",
       "         [0.065, 0.276, 0.364, 0.504],\n",
       "         [0.067, 0.283, 0.367, 0.508],\n",
       "         [0.067, 0.278, 0.361, 0.495],\n",
       "         [0.071, 0.289, 0.369, 0.504],\n",
       "         [0.071, 0.290, 0.371, 0.504],\n",
       "         [0.070, 0.299, 0.379, 0.517],\n",
       "         [0.076, 0.298, 0.377, 0.511],\n",
       "         [0.076, 0.300, 0.379, 0.509]]),\n",
       " tensor([[0.016, 0.231, 0.334, 0.477],\n",
       "         [0.019, 0.230, 0.331, 0.471],\n",
       "         [0.023, 0.237, 0.337, 0.479],\n",
       "         [0.021, 0.245, 0.344, 0.489],\n",
       "         [0.020, 0.242, 0.341, 0.482],\n",
       "         [0.028, 0.252, 0.348, 0.486],\n",
       "         [0.031, 0.250, 0.347, 0.488],\n",
       "         [0.027, 0.250, 0.349, 0.492],\n",
       "         [0.026, 0.261, 0.358, 0.505],\n",
       "         [0.026, 0.264, 0.362, 0.507],\n",
       "         [0.032, 0.262, 0.359, 0.500],\n",
       "         [0.036, 0.263, 0.359, 0.499],\n",
       "         [0.036, 0.265, 0.361, 0.498],\n",
       "         [0.035, 0.256, 0.351, 0.490],\n",
       "         [0.034, 0.238, 0.334, 0.469],\n",
       "         [0.036, 0.251, 0.344, 0.478],\n",
       "         [0.038, 0.252, 0.343, 0.478],\n",
       "         [0.048, 0.254, 0.347, 0.484],\n",
       "         [0.050, 0.239, 0.328, 0.456],\n",
       "         [0.072, 0.252, 0.335, 0.462],\n",
       "         [0.091, 0.272, 0.351, 0.482],\n",
       "         [0.065, 0.276, 0.364, 0.504],\n",
       "         [0.067, 0.283, 0.367, 0.508],\n",
       "         [0.067, 0.278, 0.361, 0.495],\n",
       "         [0.071, 0.289, 0.369, 0.504],\n",
       "         [0.071, 0.290, 0.371, 0.504],\n",
       "         [0.070, 0.299, 0.379, 0.517],\n",
       "         [0.076, 0.298, 0.377, 0.511],\n",
       "         [0.076, 0.300, 0.379, 0.509],\n",
       "         [0.086, 0.300, 0.376, 0.502]]),\n",
       " tensor([[ 0,  1, 32]]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf4ff1-4819-4b23-b2b1-c3650257a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is text... there will be an embedding corresponding to empty/no text:\n",
    "dataset.unique_embs_pca[''].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1d6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save\n",
    "# dataset_train.save_dataset('file_name.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "0135a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = StockDataset('file_name.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fa323",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "82d2adb2-a424-4df5-9544-0fa40e698347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf3ee02-b675-412e-96ef-4c473bb9c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def autoregressive_predict(model, initial_sequence, \n",
    "                           n_future_steps, truth=None):\n",
    "                           #with_text_embed=None):\n",
    "    \"\"\"\n",
    "    Predict 'future_steps' into the future based on the 'initial_sequence' using the provided model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained time series forecasting model.\n",
    "        initial_sequence (torch.Tensor): The initial data sequence used for the first prediction, shape [1, seq_length, 1].\n",
    "        future_steps (int): Number of future steps to predict.\n",
    "\n",
    "        with_test_embed: text embedding: 2 options\n",
    "          'empty': always feed in 'empty' for future\n",
    "          'truth': feed in entire sequence of embedding beginning with first time step of input token\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Predicted values for 'future_steps', shape [1, future_steps, 1].\n",
    "    \"\"\"\n",
    "    _ = model.eval()\n",
    "\n",
    "    if initial_sequence.dim() == 1:\n",
    "        initial_sequence = initial_sequence.unsqueeze(0).unsqueeze(2)\n",
    "    elif initial_sequence.dim() == 2:\n",
    "        initial_sequence = initial_sequence.unsqueeze(0)\n",
    "    current_sequence = initial_sequence.clone().detach()\n",
    "        \n",
    "    dim_truth = 0\n",
    "    dim_in = initial_sequence.shape[-1]\n",
    "    if truth is not None:\n",
    "        dim_truth = truth.shape[-1]\n",
    "        \n",
    "    len_inp = initial_sequence.shape[1]\n",
    "    t = th.arange(len_inp).reshape(len_inp)\n",
    "    #print('seq len: {} // dim in: {}'.format(len_inp, dim_in))\n",
    "    \n",
    "    all_sequences = []\n",
    "    predictions = []\n",
    "    \n",
    "    for step in range(n_future_steps):\n",
    "        # Predict the next step\n",
    "        with torch.no_grad():\n",
    "            next_value = model(current_sequence)\n",
    "        dim_out = next_value.shape[-1]\n",
    "        \n",
    "        # Append the prediction\n",
    "        predictions.append(next_value[:, -1, :].unsqueeze(1))\n",
    "    \n",
    "        # Update the current sequence for the next prediction\n",
    "        if dim_out < dim_in:\n",
    "            assert truth is not None # make sure truth is provided when output dim is different than input dim\n",
    "            _next_value = next_value[:,-1,:].unsqueeze(1)\n",
    "            _next_value_truth = truth[:, len_inp + step: len_inp + step + 1, dim_out:]\n",
    "            #print(_next_value.shape, _next_value_truth.shape)\n",
    "            next_value = th.cat((_next_value, _next_value_truth), dim=2)\n",
    "            current_sequence = torch.cat((current_sequence[:,1:,:], next_value), dim=1)\n",
    "        else:\n",
    "            a, b = (current_sequence[:, 1:, :], next_value[:, -1, :input_dim].unsqueeze(1))\n",
    "            current_sequence = torch.cat((a, b), dim=1)\n",
    "\n",
    "        all_sequences.append((t + step + 1, current_sequence))\n",
    "    \n",
    "    return torch.cat(predictions, dim=1), all_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc403cd-760d-4e17-a95c-159e501064d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, d_model, num_layers, dropout=0.1, apply_input_mask=None):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Separate embeddings for input and output dimensions\n",
    "        self.input_linear = nn.Linear(input_dim, d_model)\n",
    "        self.output_linear = nn.Linear(d_model, output_dim)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.apply_input_mask = apply_input_mask\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=4,  # Adjust number of heads as needed\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        if model.training and self.apply_input_mask is not None:  # look ahead mask; for transformer\n",
    "            input_window = src.shape[1]\n",
    "            n_tks_to_mask = randint(*self.apply_input_mask)\n",
    "            mask = torch.ones(input_window, input_window).triu(diagonal=n_tks_to_mask)\n",
    " \n",
    "        # src shape expected: [batch_size, seq_length, input_dim]\n",
    "        src = self.input_linear(src)  # Transform input to feature space\n",
    "        src *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))  # Scale input\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)  # Pass through transformer\n",
    "        output = self.output_linear(output)  # Map output to the target dimension\n",
    "        return output\n",
    "\n",
    "    autoregress = autoregressive_predict\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000, batch_first=True):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "        self.batch_first = batch_first\n",
    "        if batch_first:\n",
    "            pe = torch.zeros(1, max_len, d_model) # batch_first\n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        else:\n",
    "            pe = torch.zeros(max_len, 1, d_model) # batch_first\n",
    "            pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "            pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:,:x.size(1),:]\n",
    "        else:\n",
    "            x = x + self.pe[x.size(0),:,:]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a66e64-2270-42ec-aa38-38f31e7d2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, d_model=50, num_layers=2):\n",
    "        super(TimeSeriesLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, d_model, batch_first=True, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "    def forward(self, x, **kwargs):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "    autoregress = autoregressive_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b9f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# class TimeSeriesTransformer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "#         super(TimeSeriesTransformer, self).__init__()\n",
    "#         self.input_linear = nn.Linear(input_dim, d_model)\n",
    "#         self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "#         encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "#         self.output_linear = nn.Linear(d_model, output_dim)\n",
    "\n",
    "#     def forward(self, src):\n",
    "#         #print(src.dtype)\n",
    "#         src = self.input_linear(src)  # [batch_size, seq_len, d_model]\n",
    "#         src = self.pos_encoder(src)\n",
    "#         output = self.transformer_encoder(src)\n",
    "#         output = self.output_linear(output)\n",
    "#         return output\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         for name, param in self.named_parameters():\n",
    "#             if 'weight' in name:\n",
    "#                 if param.dim() > 1:\n",
    "#                     nn.init.kaiming_normal_(param, mode='fan_out', nonlinearity='relu')\n",
    "#                 elif 'norm' in name:\n",
    "#                     nn.init.constant_(param, 1)\n",
    "#             elif 'bias' in name:\n",
    "#                 nn.init.constant_(param, 0)\n",
    "\n",
    "#         # Optionally set a different initialization for embeddings if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5046c",
   "metadata": {},
   "source": [
    "## Key Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9d94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc0a8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = dataset_train.input_dim # dim_1\n",
    "output_dim = dataset_train.output_dim   # dim_2\n",
    "d_model = 32  # Size of the embedding\n",
    "\n",
    "model_type = 'transformer' # or 'lstm'\n",
    "\n",
    "# for both models\n",
    "num_layers = 3\n",
    "\n",
    "# only for transformers\n",
    "apply_input_mask = (2, 5) # make sure upper limit is lower than input_window\n",
    "dim_feedforward = 256\n",
    "nhead = 4\n",
    "\n",
    "if model_type == 'lstm':\n",
    "    learning_rate = 0.01\n",
    "elif model_type == 'transformer':\n",
    "    learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d3dbbe3-ce6b-4c0d-8be2-42bfe1bec630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dim: input 4 output 4\n"
     ]
    }
   ],
   "source": [
    "print('Current dim: input {} output {}'.format(input_dim, output_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5505f",
   "metadata": {},
   "source": [
    "\n",
    "### Create fake model & data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b98d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (input_linear): Linear(in_features=4, out_features=32, bias=True)\n",
       "  (output_linear): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing \n",
      "testing autoregress...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.207, -0.384,  0.044, -0.911],\n",
       "         [ 0.157, -0.028, -0.053, -0.753],\n",
       "         [ 0.016,  0.095,  0.057, -0.460],\n",
       "         [-0.126,  0.029,  0.164, -0.384],\n",
       "         [-0.109, -0.025,  0.142, -0.491],\n",
       "         [-0.039,  0.013,  0.100, -0.587],\n",
       "         [ 0.004,  0.076,  0.069, -0.590]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 4]) torch.Size([1, 30, 4])\n"
     ]
    }
   ],
   "source": [
    "# Model Test\n",
    "if model_type == 'transformer':\n",
    "    model = TimeSeriesTransformer(input_dim, output_dim, d_model, num_layers, apply_input_mask = apply_input_mask)\n",
    "elif model_type == 'lstm':\n",
    "    model  = TimeSeriesLSTM(input_dim, output_dim, d_model, num_layers)\n",
    "\n",
    "# Forward pass with dummy data\n",
    "# input_data = torch.randn(8, seq_length, input_dim)  \n",
    "# target_data = torch.randn(8, seq_length, input_dim)  \n",
    "# Forward pass with real data\n",
    "input_data = dataset_train[0][0].unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "print ('testing ')\n",
    "output = model(input_data)\n",
    "print ('testing autoregress...')\n",
    "model.autoregress(output, 7)[0]\n",
    "print(input_data.shape, output.shape)  # Should be torch.Size([batch_size, seq_len, output_dim])\n",
    "\n",
    "# model.init_weights()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf26a0",
   "metadata": {},
   "source": [
    "# Training Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8860374e-69c1-46ed-9096-ee00422cf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loss\n",
    "# symmetrical mean absolute percentage error\n",
    "def SMAPELoss(output, target,tol=1e-4):\n",
    "    denominator = (torch.abs(target) + torch.abs(output) + tol) / 2\n",
    "    diff = torch.abs(output - target) / denominator\n",
    "    diff[denominator == 0] = 0.0  # Handle the case to avoid division by zero\n",
    "    smape = torch.mean(diff)\n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d02bb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24   # make bigger\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39151773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8169b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SMAPELoss\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd249366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.3948916176796993, Testing Loss: 0.050449474896122885\n",
      "Epoch 2, Training Loss: 0.11336063800347333, Testing Loss: 0.03724119913848964\n",
      "Epoch 3, Training Loss: 0.08759794328254082, Testing Loss: 0.03153624049351587\n",
      "Epoch 4, Training Loss: 0.07531480482547959, Testing Loss: 0.029318979614740844\n",
      "Epoch 5, Training Loss: 0.06805693382946397, Testing Loss: 0.025126178156245838\n",
      "Epoch 6, Training Loss: 0.06297628583677242, Testing Loss: 0.02346032928046468\n",
      "Epoch 7, Training Loss: 0.059298274123427495, Testing Loss: 0.021030664710061892\n",
      "Epoch 8, Training Loss: 0.05643070349200612, Testing Loss: 0.021218975219730433\n",
      "Epoch 9, Training Loss: 0.054176939317601265, Testing Loss: 0.019564155948820054\n",
      "Epoch 10, Training Loss: 0.05241748905401526, Testing Loss: 0.018236153674396603\n",
      "Epoch 11, Training Loss: 0.050883886495852744, Testing Loss: 0.017473463295632367\n",
      "Epoch 12, Training Loss: 0.0497253744383854, Testing Loss: 0.01878996563518976\n",
      "Epoch 13, Training Loss: 0.04878162368701373, Testing Loss: 0.018123905247004777\n",
      "Epoch 14, Training Loss: 0.047838164805676896, Testing Loss: 0.01689677924982139\n",
      "Epoch 15, Training Loss: 0.04699529628296291, Testing Loss: 0.018020635881981294\n",
      "Epoch 16, Training Loss: 0.046379207439634494, Testing Loss: 0.016436487690291622\n",
      "Epoch 17, Training Loss: 0.045842295458723356, Testing Loss: 0.01719962154793275\n",
      "Epoch 18, Training Loss: 0.04533819315384406, Testing Loss: 0.017404750340267436\n",
      "Epoch 19, Training Loss: 0.04501043502887377, Testing Loss: 0.01728567468945856\n",
      "Epoch 20, Training Loss: 0.044500313753079127, Testing Loss: 0.017057638917747257\n",
      "Epoch 21, Training Loss: 0.0441661583410436, Testing Loss: 0.018917014870744247\n",
      "Epoch 22, Training Loss: 0.04380683558912291, Testing Loss: 0.01564611475189011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (src, tgt, idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader_train):\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, tgt)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug_data_save:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.forward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m src \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))  \u001b[38;5;66;03m# Scale input\u001b[39;00m\n\u001b[1;32m     35\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(src)\n\u001b[0;32m---> 36\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass through transformer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_linear(output)  \u001b[38;5;66;03m# Map output to the target dimension\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/transformer.py:719\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x,\n\u001b[1;32m    716\u001b[0m                        attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    717\u001b[0m                        key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    718\u001b[0m                        need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_causal\u001b[38;5;241m=\u001b[39mis_causal)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm/lib/python3.8/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Training and Testing Loop\n",
    "losses = {}\n",
    "\n",
    "debug_data_save = False\n",
    "data = []\n",
    "data_test = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_e_train = 0.\n",
    "    _data = [] \n",
    "    _ = model.train()\n",
    "    for batch, (src, tgt, idx) in enumerate(dataloader_train):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        \n",
    "        if debug_data_save:\n",
    "            _data.append((src, output.detach(), tgt))\n",
    "        \n",
    "        loss.backward()\n",
    "        _ = clip_grad_norm_(model.parameters(), max_norm=1.) \n",
    "        optimizer.step()\n",
    "        loss_e_train += loss.detach().item()\n",
    "\n",
    "    data.append(_data)\n",
    "    loss_e_train /= batch\n",
    "    losses.setdefault('train', {})[epoch]=loss_e_train\n",
    "    \n",
    "    loss_e_test = 0\n",
    "    _ = model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (src, tgt, idx) in enumerate(dataloader_test):\n",
    "            _data = []\n",
    "            output = model(src)\n",
    "            loss = criterion(output, tgt)\n",
    "            loss_e_test += loss.item()\n",
    "            if debug_data_save:\n",
    "                _data.append((src, output.detach(), tgt))\n",
    "        data_test.append(_data)\n",
    "    loss_e_test /= batch\n",
    "    losses.setdefault('test', {})[epoch]=loss_e_test\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {loss_e_train}, Testing Loss: {loss_e_test}\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2673a73-4e53-4dc1-903b-1f33a2339f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d0cdee1-e2a6-4e33-b4d1-4435cd0c2889",
   "metadata": {},
   "source": [
    "# VISUALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2ff5c9a0-00d8-4101-8e29-8427590805d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import pow\n",
    "\n",
    "def visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth):\n",
    "    seq_to_test_truth = seq_to_test_truth[0,:,0]\n",
    "    len_seq_truth = seq_to_test_truth.shape[-1]\n",
    "    \n",
    "    seq_len_pred = len(seq_to_test_pred_per_step)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    i_truth_end = min(input_window+seq_len_pred, len_seq_truth)\n",
    "    ax.plot(th.arange(input_window).tolist(), seq_to_test_truth[:input_window], c='black')\n",
    "    ax.plot(th.arange(input_window-1,i_truth_end), seq_to_test_truth[input_window-1:i_truth_end], c='red')\n",
    "    \n",
    "    for _step, (_t, _seq) in enumerate(seq_to_test_pred_per_step):\n",
    "        _seq = _seq[0,:,:1]  # only show stock price (first dimension of output)\n",
    "        _is_future = _t >= (input_window - 1)\n",
    "        _ = ax.plot(_t[_is_future], _seq[_is_future], c='magenta', alpha=pow(0.8, _step))\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.show()\n",
    "visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34f48da-a2a2-493f-8cbd-c76678c59711",
   "metadata": {},
   "source": [
    "# INSPECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d3aa73-8a89-492a-8388-c9112bc34a2d",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ef74315b-6c49-47a2-b500-3ef70443db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data point information: company: 2 & time: 117\n",
      "goldman_sachs 2023-11-21\n"
     ]
    }
   ],
   "source": [
    "dataloader_test_shuffled = DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
    "seq_to_test = next(iter(dataloader_test_shuffled))\n",
    "#seq_to_test = dataset_test[0] # a random test dataset point\n",
    "\n",
    "n_future_steps = 7 # how many steps to forecast into the future\n",
    "use_empty_text = True   # future text is assumed to be empty if True; otherwise, use true text from future\n",
    "\n",
    "seq_to_test_idx = seq_to_test[2].squeeze() # get the index\n",
    "print(\"Test data point information: company: {} & time: {}\".format(seq_to_test_idx[0].item(), seq_to_test_idx[1].item()))\n",
    "print(dataset_test.names[seq_to_test_idx[0].item()], dataset_test.dates[seq_to_test_idx[1].item()])\n",
    "\n",
    "# get the corresponding raw data sequence from the dataset beginning from the start of this subsequence\n",
    "seq_to_test_truth = dataset_test.get_sequence_from_index(seq_to_test_idx, use_empty_text) \n",
    "seq_to_test_input = seq_to_test[0]\n",
    "\n",
    "#run model autoregressively\n",
    "seq_to_test_pred, seq_to_test_pred_per_step =  model.autoregress(seq_to_test_input, n_future_steps, truth=seq_to_test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6dfcdda1-1d70-4708-bd20-0d8089074a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_forecast(seq_to_test_pred_per_step, seq_to_test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f36a3af0-b5fb-49e1-a896-ac6472f85663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.863, 0.938, 0.934, 0.933],\n",
       "         [0.856, 0.932, 0.924, 0.924],\n",
       "         [0.850, 0.928, 0.919, 0.917],\n",
       "         [0.845, 0.924, 0.915, 0.912],\n",
       "         [0.841, 0.920, 0.911, 0.908],\n",
       "         [0.837, 0.917, 0.908, 0.904],\n",
       "         [0.833, 0.913, 0.905, 0.901]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d82ee26c-0a23-4a83-9ea7-f47cef3cf06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "          19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]),\n",
       "  tensor([[[0.859, 0.912, 0.897, 0.933],\n",
       "           [0.865, 0.913, 0.901, 0.939],\n",
       "           [0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933]]])),\n",
       " (tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "          20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       "  tensor([[[0.865, 0.913, 0.901, 0.939],\n",
       "           [0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924]]])),\n",
       " (tensor([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "          21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]),\n",
       "  tensor([[[0.871, 0.928, 0.914, 0.947],\n",
       "           [0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917]]])),\n",
       " (tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "          22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
       "  tensor([[[0.866, 0.932, 0.915, 0.949],\n",
       "           [0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912]]])),\n",
       " (tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "          23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]),\n",
       "  tensor([[[0.863, 0.953, 0.925, 0.946],\n",
       "           [0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908]]])),\n",
       " (tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "          24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]),\n",
       "  tensor([[[0.892, 0.948, 0.923, 0.952],\n",
       "           [0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908],\n",
       "           [0.837, 0.917, 0.908, 0.904]]])),\n",
       " (tensor([ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "          25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]),\n",
       "  tensor([[[0.844, 0.918, 0.900, 0.928],\n",
       "           [0.841, 0.939, 0.916, 0.935],\n",
       "           [0.867, 0.944, 0.926, 0.951],\n",
       "           [0.864, 0.930, 0.918, 0.944],\n",
       "           [0.864, 0.915, 0.908, 0.941],\n",
       "           [0.877, 0.910, 0.910, 0.944],\n",
       "           [0.884, 0.958, 0.945, 0.965],\n",
       "           [0.886, 0.954, 0.945, 0.968],\n",
       "           [0.884, 0.951, 0.939, 0.965],\n",
       "           [0.886, 0.958, 0.942, 0.961],\n",
       "           [0.894, 0.948, 0.939, 0.960],\n",
       "           [0.880, 0.963, 0.948, 0.962],\n",
       "           [0.876, 0.983, 0.961, 0.966],\n",
       "           [0.891, 0.976, 0.959, 0.961],\n",
       "           [0.886, 0.948, 0.942, 0.942],\n",
       "           [0.881, 0.957, 0.950, 0.946],\n",
       "           [0.877, 0.982, 0.968, 0.952],\n",
       "           [0.872, 0.963, 0.957, 0.949],\n",
       "           [0.870, 0.956, 0.955, 0.951],\n",
       "           [0.877, 0.982, 0.974, 0.962],\n",
       "           [0.891, 0.972, 0.970, 0.964],\n",
       "           [0.878, 0.967, 0.966, 0.957],\n",
       "           [0.873, 0.951, 0.955, 0.948],\n",
       "           [0.863, 0.938, 0.934, 0.933],\n",
       "           [0.856, 0.932, 0.924, 0.924],\n",
       "           [0.850, 0.928, 0.919, 0.917],\n",
       "           [0.845, 0.924, 0.915, 0.912],\n",
       "           [0.841, 0.920, 0.911, 0.908],\n",
       "           [0.837, 0.917, 0.908, 0.904],\n",
       "           [0.833, 0.913, 0.905, 0.901]]]))]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_to_test_pred_per_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e0dca929-dc9b-4db1-abd8-298702f50eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273f140-982f-4cc9-a041-008126c7180a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c56d05-a795-4eac-8542-009d82a4b655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87f8be-f843-4cfa-a8ba-63171f2f9647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
