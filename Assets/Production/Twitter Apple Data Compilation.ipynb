{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96248e68-d1ee-4749-b972-6d372f2c2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "th = torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953b9e8c-6aec-4a36-b623-b73975ed2a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_13633/1812772017.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_13633/1812772017.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_13633/1812772017.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_13633/1812772017.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            close_tesla  close_apple  close_dow_jones  close_nasdaq_composite  \\\n",
      "Date                                                                            \n",
      "2020-01-02    28.684000    75.087502     28868.800781             9092.190430   \n",
      "2020-01-03    29.534000    74.357498     28634.880859             9020.769531   \n",
      "2020-01-06    30.102667    74.949997     28703.380859             9071.469727   \n",
      "2020-01-07    31.270666    74.597504     28583.679688             9068.580078   \n",
      "2020-01-08    32.809334    75.797501     28745.089844             9129.240234   \n",
      "\n",
      "            close_sp_500  \n",
      "Date                      \n",
      "2020-01-02   3257.850098  \n",
      "2020-01-03   3234.850098  \n",
      "2020-01-06   3246.280029  \n",
      "2020-01-07   3237.179932  \n",
      "2020-01-08   3253.050049  \n",
      "            close_tesla  close_apple  close_dow_jones  close_nasdaq_composite  \\\n",
      "Date                                                                            \n",
      "2020-01-02     0.011927     0.133751         0.484405                0.232898   \n",
      "2020-01-03     0.014130     0.128611         0.473379                0.225444   \n",
      "2020-01-06     0.015604     0.132783         0.476608                0.230736   \n",
      "2020-01-07     0.018631     0.130301         0.470966                0.230434   \n",
      "2020-01-08     0.022618     0.138751         0.478574                0.236765   \n",
      "\n",
      "            close_sp_500  \n",
      "Date                      \n",
      "2020-01-02      0.338239  \n",
      "2020-01-03      0.330615  \n",
      "2020-01-06      0.334404  \n",
      "2020-01-07      0.331388  \n",
      "2020-01-08      0.336648  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_13633/1812772017.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2024, 4, 15)\n",
    "\n",
    "# List of ticker symbols and their corresponding company names\n",
    "companies = {\n",
    "    'TSLA': 'tesla',\n",
    "    'AAPL': 'apple',\n",
    "    '^DJI': 'dow_jones',\n",
    "    '^IXIC': 'nasdaq_composite',\n",
    "    '^GSPC': 'sp_500'\n",
    "}\n",
    "\n",
    "# Download stock data for each company\n",
    "stock_data_frames = []\n",
    "for ticker, name in companies.items():\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "    df = df[['Close']]  # Keep only the 'Close' column\n",
    "    df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
    "    stock_data_frames.append(df)\n",
    "\n",
    "# Merge all data frames on the Date index\n",
    "merged_df = stock_data_frames[0]\n",
    "for df in stock_data_frames[1:]:\n",
    "    merged_df = merged_df.join(df, how='outer')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the data\n",
    "scaled_data = scaler.fit_transform(merged_df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=merged_df.columns, index=merged_df.index)\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208a7703-8cf0-42a0-9025-651ffedb590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies=['close_tesla', 'close_apple'] \n",
    "dfs=[scaled_df[[_name] + ['close_nasdaq_composite', 'close_sp_500', 'close_dow_jones']].copy() for _name in companies]\n",
    "dfs={_name.split('close_')[1]: _df.rename(columns={_name:'close'}) for _df, _name in zip(dfs, companies)}\n",
    "\n",
    "import pickle\n",
    "pickle.dump(dfs, open('apple_vs_tesla_windex.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcc53f3-1054-4d0d-96b9-e58d2ec485a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tesla':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.011927                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.014130                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.015604                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.018631                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.022618                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.385859                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.395966                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.382698                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.390057                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.380858                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns],\n",
       " 'apple':                close  close_nasdaq_composite  close_sp_500  close_dow_jones\n",
       " Date                                                                       \n",
       " 2020-01-02  0.133751                0.232898      0.338239         0.484405\n",
       " 2020-01-03  0.128611                0.225444      0.330615         0.473379\n",
       " 2020-01-06  0.132783                0.230736      0.334404         0.476608\n",
       " 2020-01-07  0.130301                0.230434      0.331388         0.470966\n",
       " 2020-01-08  0.138751                0.236765      0.336648         0.478574\n",
       " ...              ...                     ...           ...              ...\n",
       " 2024-04-08  0.791152                0.980354      0.982777         0.956891\n",
       " 2024-04-09  0.799743                0.985852      0.985270         0.956461\n",
       " 2024-04-10  0.786435                0.971629      0.968939         0.936562\n",
       " 2024-04-11  0.837555                1.000000      0.981674         0.936448\n",
       " 2024-04-12  0.848188                0.972122      0.956599         0.914019\n",
       " \n",
       " [1077 rows x 4 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db69425f-5ea5-450c-a435-477feb46c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_2012/3281780412.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            close_tesla  close_apple\n",
      "Date                                \n",
      "2020-01-02    28.684000    75.087502\n",
      "2020-01-03    29.534000    74.357498\n",
      "2020-01-06    30.102667    74.949997\n",
      "2020-01-07    31.270666    74.597504\n",
      "2020-01-08    32.809334    75.797501\n",
      "            close_tesla  close_apple\n",
      "Date                                \n",
      "2020-01-02     0.011927     0.133751\n",
      "2020-01-03     0.014130     0.128611\n",
      "2020-01-06     0.015604     0.132783\n",
      "2020-01-07     0.018631     0.130301\n",
      "2020-01-08     0.022618     0.138751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/f0/ckkb_ykj483d49h__2mxzsk00000gn/T/ipykernel_2012/3281780412.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2024, 4, 15)\n",
    "\n",
    "# List of ticker symbols and their corresponding company names\n",
    "companies = {\n",
    "    'TSLA': 'tesla',\n",
    "    'AAPL': 'apple',\n",
    "}\n",
    "\n",
    "# Download stock data for each company\n",
    "stock_data_frames = []\n",
    "for ticker, name in companies.items():\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "    df = df[['Close']]  # Keep only the 'Close' column\n",
    "    df.rename(columns={'Close': f'close_{name}'}, inplace=True)\n",
    "    stock_data_frames.append(df)\n",
    "\n",
    "# Merge all data frames on the Date index\n",
    "merged_df = stock_data_frames[0]\n",
    "for df in stock_data_frames[1:]:\n",
    "    merged_df = merged_df.join(df, how='outer')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the data\n",
    "scaled_data = scaler.fit_transform(merged_df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=merged_df.columns, index=merged_df.index)\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41d4a5d0-5e19-490e-9a4a-931113acbc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Tweet_elon'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "FILEPATH = '/Users/Shared/tweets/elon_tweet.csv'\n",
    "df1 = pd.read_csv(FILEPATH)\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d12b4184-8573-4b13-80f6-9f0d92b8a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Tweet_elon'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "FILEPATH = '/Users/Shared/tweets/tim_tweets.csv'\n",
    "df2 = pd.read_csv(FILEPATH)\n",
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0794690-d77d-4338-a285-e3ec0d9f0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#companies=['close_tesla', 'close_apple'] \n",
    "#dfs=[scaled_df[[_name]].copy() for _name in companies]\n",
    "#dfs={_name.split('close_')[1]: _df.rename(columns={_name:'close'}) for _df, _name in zip(dfs, companies)}\n",
    "\n",
    "#import pickle\n",
    "#pickle.dump(dfs, open('apple_vs_tesla_stockonly.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0320f70d-b306-4f23-8d5a-63f5873601ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tesla':                close\n",
       " Date                \n",
       " 2020-01-02  0.011927\n",
       " 2020-01-03  0.014130\n",
       " 2020-01-06  0.015604\n",
       " 2020-01-07  0.018631\n",
       " 2020-01-08  0.022618\n",
       " ...              ...\n",
       " 2024-04-08  0.385859\n",
       " 2024-04-09  0.395966\n",
       " 2024-04-10  0.382698\n",
       " 2024-04-11  0.390057\n",
       " 2024-04-12  0.380858\n",
       " \n",
       " [1077 rows x 1 columns],\n",
       " 'apple':                close\n",
       " Date                \n",
       " 2020-01-02  0.133751\n",
       " 2020-01-03  0.128611\n",
       " 2020-01-06  0.132783\n",
       " 2020-01-07  0.130301\n",
       " 2020-01-08  0.138751\n",
       " ...              ...\n",
       " 2024-04-08  0.791152\n",
       " 2024-04-09  0.799743\n",
       " 2024-04-10  0.786435\n",
       " 2024-04-11  0.837555\n",
       " 2024-04-12  0.848188\n",
       " \n",
       " [1077 rows x 1 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4290ec0f-b4de-4603-9f9b-77888b40bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_elon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-15 20:34:02+00:00</td>\n",
       "      <td>Interesting series about a potentially good fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-15 19:34:09+00:00</td>\n",
       "      <td>United States laws prevent 𝕏 from participatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-15 18:34:59+00:00</td>\n",
       "      <td>Interesting https://t.co/hQJTsYDx5v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-15 18:34:21+00:00</td>\n",
       "      <td>If you’re experiencing severe neck/back pain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-15 17:50:59+00:00</td>\n",
       "      <td>https://t.co/wXlbpNU97H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>2020-01-04 03:33:58+00:00</td>\n",
       "      <td>@hot_rod_co @Tesla People talk about the produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9438</th>\n",
       "      <td>2020-01-04 03:25:03+00:00</td>\n",
       "      <td>@slashdot Wow, I built my first server room wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9439</th>\n",
       "      <td>2020-01-01 06:50:06+00:00</td>\n",
       "      <td>Congratulations Tesla &amp;amp; SpaceX on great 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9440</th>\n",
       "      <td>2020-01-01 06:33:47+00:00</td>\n",
       "      <td>No one suspected his disguise https://t.co/yHl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>2020-01-01 05:32:58+00:00</td>\n",
       "      <td>Carlos Gone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9442 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date  \\\n",
       "0     2024-04-15 20:34:02+00:00   \n",
       "1     2024-04-15 19:34:09+00:00   \n",
       "2     2024-04-15 18:34:59+00:00   \n",
       "3     2024-04-15 18:34:21+00:00   \n",
       "4     2024-04-15 17:50:59+00:00   \n",
       "...                         ...   \n",
       "9437  2020-01-04 03:33:58+00:00   \n",
       "9438  2020-01-04 03:25:03+00:00   \n",
       "9439  2020-01-01 06:50:06+00:00   \n",
       "9440  2020-01-01 06:33:47+00:00   \n",
       "9441  2020-01-01 05:32:58+00:00   \n",
       "\n",
       "                                             Tweet_elon  \n",
       "0     Interesting series about a potentially good fu...  \n",
       "1     United States laws prevent 𝕏 from participatin...  \n",
       "2                   Interesting https://t.co/hQJTsYDx5v  \n",
       "3     If you’re experiencing severe neck/back pain, ...  \n",
       "4                               https://t.co/wXlbpNU97H  \n",
       "...                                                 ...  \n",
       "9437  @hot_rod_co @Tesla People talk about the produ...  \n",
       "9438  @slashdot Wow, I built my first server room wi...  \n",
       "9439  Congratulations Tesla &amp; SpaceX on great 20...  \n",
       "9440  No one suspected his disguise https://t.co/yHl...  \n",
       "9441                                        Carlos Gone  \n",
       "\n",
       "[9442 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "698d4f88-9079-406e-a7f2-62efb51d2403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date                                         Tweet_elon\n",
      "0     2024-04-15  Interesting series about a potentially good fu...\n",
      "1     2024-04-15  United States laws prevent 𝕏 from participatin...\n",
      "2     2024-04-15                Interesting https://t.co/hQJTsYDx5v\n",
      "3     2024-04-15  If you’re experiencing severe neck/back pain, ...\n",
      "4     2024-04-15                            https://t.co/wXlbpNU97H\n",
      "...          ...                                                ...\n",
      "9437  2020-01-04  @hot_rod_co @Tesla People talk about the produ...\n",
      "9438  2020-01-04  @slashdot Wow, I built my first server room wi...\n",
      "9439  2020-01-01  Congratulations Tesla &amp; SpaceX on great 20...\n",
      "9440  2020-01-01  No one suspected his disguise https://t.co/yHl...\n",
      "9441  2020-01-01                                        Carlos Gone\n",
      "\n",
      "[9442 rows x 2 columns]\n",
      "           Date                                          Tweet_tim\n",
      "0    2024-04-15  Thanks to the very talented VietMax for showin...\n",
      "1    2024-04-15  Developers CollaNote &amp; ELSA Speak walked m...\n",
      "2    2024-04-15  Phuong Vu and his team are wildly creative. Th...\n",
      "3    2024-04-15  Hoan Kiem Lake in Hanoi is as beautiful as it ...\n",
      "4    2024-04-15  Xin chào, Vietnam! Thank you to the very talen...\n",
      "..          ...                                                ...\n",
      "667  2020-01-18  Glad to support the essential work of our frie...\n",
      "668  2020-01-17  There are countless ways to make a difference....\n",
      "669  2020-01-13  “The Ultra Wide camera brings a whole new expe...\n",
      "670  2020-01-06  Congratulations to all of tonight’s @GoldenGlo...\n",
      "671  2020-01-01  There is opportunity in every new beginning. I...\n",
      "\n",
      "[672 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the 'date' column to datetime\n",
    "df1['Date'] = pd.to_datetime(df1['Date']).dt.date\n",
    "df2['Date'] = pd.to_datetime(df2['Date']).dt.date\n",
    "\n",
    "# Display the modified DataFrames\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3702cd4e-1b59-4b4d-a808-3a5daca9526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date                                         Tweet_elon\n",
      "0    2020-01-01  Congratulations Tesla &amp; SpaceX on great 20...\n",
      "1    2020-01-04  @annerajb @slashdot Zip2 @hot_rod_co @Tesla Pe...\n",
      "2    2020-01-05  @7400N @Model3Owners Ok @APompliano @Tesla Fai...\n",
      "3    2020-01-06  @flcnhvy @slashdot 🤣🤣 @slashdot The Nirvana ba...\n",
      "4    2020-01-07  @BnOrdhaug @Erdayastronaut I haven’t cross-che...\n",
      "..          ...                                                ...\n",
      "682  2024-04-11  Community Notes will now show faster https://t...\n",
      "683  2024-04-12  Thank you DoubleVerify for correcting your mis...\n",
      "684  2024-04-13  Always wondered what that chair was for https:...\n",
      "685  2024-04-14  Create or join 𝕏 Communities! https://t.co/TKU...\n",
      "686  2024-04-15  Interesting series about a potentially good fu...\n",
      "\n",
      "[687 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.groupby('Date')['Tweet_elon'].agg(' '.join).reset_index()\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dd2cc36-5eda-49d0-bd06-ca9e73764424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date                                          Tweet_tim\n",
      "0    2020-01-01  There is opportunity in every new beginning. I...\n",
      "1    2020-01-06  Congratulations to all of tonight’s @GoldenGlo...\n",
      "2    2020-01-13  “The Ultra Wide camera brings a whole new expe...\n",
      "3    2020-01-17  There are countless ways to make a difference....\n",
      "4    2020-01-18  When you add up every ambitious dreamer, every...\n",
      "..          ...                                                ...\n",
      "491  2024-03-17  Congratulations!! @coachbrucepearl @AuburnMBB ...\n",
      "492  2024-03-25  Happy Holi to all who celebrate! Thank you @jo...\n",
      "493  2024-03-31  Today and every day, let's commit to creating ...\n",
      "494  2024-04-09  Leading companies in every industry are levera...\n",
      "495  2024-04-15  Thanks to the very talented VietMax for showin...\n",
      "\n",
      "[496 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.groupby('Date')['Tweet_tim'].agg(' '.join).reset_index()\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c08b2f0f-c602-42db-bbf8-d47f061b9cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            close_tesla  close_apple  close_dow_jones  close_nasdaq_composite  \\\n",
      "Date                                                                            \n",
      "2020-01-02     0.011927     0.133751         0.484405                0.232898   \n",
      "2020-01-03     0.014130     0.128611         0.473379                0.225444   \n",
      "2020-01-06     0.015604     0.132783         0.476608                0.230736   \n",
      "2020-01-07     0.018631     0.130301         0.470966                0.230434   \n",
      "2020-01-08     0.022618     0.138751         0.478574                0.236765   \n",
      "...                 ...          ...              ...                     ...   \n",
      "2024-04-08     0.385859     0.791152         0.956891                0.980354   \n",
      "2024-04-09     0.395966     0.799743         0.956461                0.985852   \n",
      "2024-04-10     0.382698     0.786435         0.936562                0.971629   \n",
      "2024-04-11     0.390057     0.837555         0.936448                1.000000   \n",
      "2024-04-12     0.380858     0.848188         0.914019                0.972122   \n",
      "\n",
      "            close_sp_500                                         Tweet_elon  \\\n",
      "Date                                                                          \n",
      "2020-01-02      0.338239                                                      \n",
      "2020-01-03      0.330615                                                      \n",
      "2020-01-06      0.334404  @flcnhvy @slashdot 🤣🤣 @slashdot The Nirvana ba...   \n",
      "2020-01-07      0.331388  @BnOrdhaug @Erdayastronaut I haven’t cross-che...   \n",
      "2020-01-08      0.336648  @nichegamer King of the Goblins,\\nMaster of th...   \n",
      "...                  ...                                                ...   \n",
      "2024-04-08      0.982777  https://t.co/gKoHxYpHPC The AI compute growth ...   \n",
      "2024-04-09      0.985270  Accurate https://t.co/Oen5ct1aNB Much apprecia...   \n",
      "2024-04-10      0.968939  𝕏 algorithm update coming soon with more bange...   \n",
      "2024-04-11      0.981674  Community Notes will now show faster https://t...   \n",
      "2024-04-12      0.956599  Thank you DoubleVerify for correcting your mis...   \n",
      "\n",
      "                                                    Tweet_tim  \n",
      "Date                                                           \n",
      "2020-01-02                                                     \n",
      "2020-01-03                                                     \n",
      "2020-01-06  Congratulations to all of tonight’s @GoldenGlo...  \n",
      "2020-01-07                                                     \n",
      "2020-01-08                                                     \n",
      "...                                                       ...  \n",
      "2024-04-08                                                     \n",
      "2024-04-09  Leading companies in every industry are levera...  \n",
      "2024-04-10                                                     \n",
      "2024-04-11                                                     \n",
      "2024-04-12                                                     \n",
      "\n",
      "[1077 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df1, df2, and scaled_df are already defined and loaded\n",
    "\n",
    "# Convert 'Date' column in df1 and df2 to datetime\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "# If scaled_df has a 'Date' column, ensure it is a datetime type\n",
    "# If it's using date as an index and the index is not already datetime, convert it:\n",
    "# scaled_df.index = pd.to_datetime(scaled_df.index)\n",
    "\n",
    "# First, merge df1 with scaled_df\n",
    "# Adjust 'on' or 'left_index=True, right_on='Date'' based on the structure of scaled_df\n",
    "if 'Date' in scaled_df.columns:\n",
    "    merged_df1_scaled = pd.merge(scaled_df, df1, on='Date', how='left')\n",
    "else:\n",
    "    # Assuming the index of scaled_df is date-based\n",
    "    merged_df1_scaled = pd.merge(scaled_df, df1, left_index=True, right_on='Date', how='left')\n",
    "\n",
    "# Now merge the result with df2\n",
    "final_merged_df = pd.merge(merged_df1_scaled, df2, on='Date', how='left')\n",
    "\n",
    "# Fill NaN values in final_merged_df with empty strings, if needed\n",
    "final_merged_df.fillna('', inplace=True)\n",
    "\n",
    "# Optionally, set 'Date' as the index of the final DataFrame\n",
    "final_merged_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Print the final merged DataFrame\n",
    "print(final_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "303eda0f-05d8-4c10-bd96-ea20bc39a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tesla':                close  close_nasdaq_composite  close_sp_500  close_dow_jones  \\\n",
      "Date                                                                          \n",
      "2020-01-02  0.011927                0.232898      0.338239         0.484405   \n",
      "2020-01-03  0.014130                0.225444      0.330615         0.473379   \n",
      "2020-01-06  0.015604                0.230736      0.334404         0.476608   \n",
      "2020-01-07  0.018631                0.230434      0.331388         0.470966   \n",
      "2020-01-08  0.022618                0.236765      0.336648         0.478574   \n",
      "...              ...                     ...           ...              ...   \n",
      "2024-04-08  0.385859                0.980354      0.982777         0.956891   \n",
      "2024-04-09  0.395966                0.985852      0.985270         0.956461   \n",
      "2024-04-10  0.382698                0.971629      0.968939         0.936562   \n",
      "2024-04-11  0.390057                1.000000      0.981674         0.936448   \n",
      "2024-04-12  0.380858                0.972122      0.956599         0.914019   \n",
      "\n",
      "                                                        tweet  \n",
      "Date                                                           \n",
      "2020-01-02                                                     \n",
      "2020-01-03                                                     \n",
      "2020-01-06  @flcnhvy @slashdot 🤣🤣 @slashdot The Nirvana ba...  \n",
      "2020-01-07  @BnOrdhaug @Erdayastronaut I haven’t cross-che...  \n",
      "2020-01-08  @nichegamer King of the Goblins,\\nMaster of th...  \n",
      "...                                                       ...  \n",
      "2024-04-08  https://t.co/gKoHxYpHPC The AI compute growth ...  \n",
      "2024-04-09  Accurate https://t.co/Oen5ct1aNB Much apprecia...  \n",
      "2024-04-10  𝕏 algorithm update coming soon with more bange...  \n",
      "2024-04-11  Community Notes will now show faster https://t...  \n",
      "2024-04-12  Thank you DoubleVerify for correcting your mis...  \n",
      "\n",
      "[1077 rows x 5 columns], 'apple':                close  close_nasdaq_composite  close_sp_500  close_dow_jones  \\\n",
      "Date                                                                          \n",
      "2020-01-02  0.133751                0.232898      0.338239         0.484405   \n",
      "2020-01-03  0.128611                0.225444      0.330615         0.473379   \n",
      "2020-01-06  0.132783                0.230736      0.334404         0.476608   \n",
      "2020-01-07  0.130301                0.230434      0.331388         0.470966   \n",
      "2020-01-08  0.138751                0.236765      0.336648         0.478574   \n",
      "...              ...                     ...           ...              ...   \n",
      "2024-04-08  0.791152                0.980354      0.982777         0.956891   \n",
      "2024-04-09  0.799743                0.985852      0.985270         0.956461   \n",
      "2024-04-10  0.786435                0.971629      0.968939         0.936562   \n",
      "2024-04-11  0.837555                1.000000      0.981674         0.936448   \n",
      "2024-04-12  0.848188                0.972122      0.956599         0.914019   \n",
      "\n",
      "                                                        tweet  \n",
      "Date                                                           \n",
      "2020-01-02                                                     \n",
      "2020-01-03                                                     \n",
      "2020-01-06  Congratulations to all of tonight’s @GoldenGlo...  \n",
      "2020-01-07                                                     \n",
      "2020-01-08                                                     \n",
      "...                                                       ...  \n",
      "2024-04-08                                                     \n",
      "2024-04-09  Leading companies in every industry are levera...  \n",
      "2024-04-10                                                     \n",
      "2024-04-11                                                     \n",
      "2024-04-12                                                     \n",
      "\n",
      "[1077 rows x 5 columns]}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'final_merged_df' is your DataFrame containing all the necessary data\n",
    "companies = ['close_tesla', 'close_apple']\n",
    "tweets = ['Tweet_elon', 'Tweet_tim']  # Corresponding tweet columns\n",
    "\n",
    "# Create a list of DataFrames, each containing the data for one company and relevant indices\n",
    "dfs = [\n",
    "    final_merged_df[[company] + ['close_nasdaq_composite', 'close_sp_500', 'close_dow_jones', tweet]].copy()\n",
    "    for company, tweet in zip(companies, tweets)\n",
    "]\n",
    "\n",
    "# Create a dictionary where the keys are company names without the 'close_' prefix\n",
    "# and the values are the corresponding DataFrames with renamed columns to generalize 'close'\n",
    "dfs = {\n",
    "    company.split('close_')[1]: df.rename(columns={company: 'close', tweet: 'tweet'})\n",
    "    for df, company, tweet in zip(dfs, companies, tweets)\n",
    "}\n",
    "print(dfs)\n",
    "# Save the dictionary of DataFrames to a pickle file\n",
    "pickle.dump(dfs, open('real_companies_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1cac0-819e-4e0f-a3e1-9ee7046dcfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
