{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa82fc7e-10d4-4cb2-bb1c-7c5d3b360882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        User              Date Created  Number of Likes Source of Tweet  \\\n",
      "0  Elon Musk 2024-04-15 20:34:02+00:00            25241            None   \n",
      "1  Elon Musk 2024-04-15 19:34:09+00:00           134973            None   \n",
      "2  Elon Musk 2024-04-15 18:34:59+00:00            61911            None   \n",
      "3  Elon Musk 2024-04-15 18:34:21+00:00           101493            None   \n",
      "4  Elon Musk 2024-04-15 17:50:59+00:00           208075            None   \n",
      "\n",
      "                                               Tweet  \n",
      "0  Interesting series about a potentially good fu...  \n",
      "1  United States laws prevent ùïè from participatin...  \n",
      "2                Interesting https://t.co/hQJTsYDx5v  \n",
      "3  If you‚Äôre experiencing severe neck/back pain, ...  \n",
      "4                            https://t.co/wXlbpNU97H  \n",
      "Data saved to 'tweets.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Enter your credentials here\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAADcz9vgczEZMZ7q6u5aGQ4UstazE%3DOSybzlXB9L8nCDM6XRgLlZSTqsJ1GaOV8UAoMqZgk9Zc5sODJQ'\n",
    "\n",
    "# Initialize Tweepy with Twitter API v2\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# Tim Cook's Twitter user ID\n",
    "user_id = \"44196397\"\n",
    "# This is Tim Cook's user ID; replace if different\n",
    "\n",
    "#user_id = \"1636590253\"\n",
    "# Define the time range\n",
    "start_time = \"2024-01-01T00:00:00Z\"\n",
    "end_time = \"2024-04-15T23:59:59Z\"\n",
    "\n",
    "# Collect tweets\n",
    "try:\n",
    "    tweets = client.get_users_tweets(id=user_id, \n",
    "                                     start_time=start_time, \n",
    "                                     end_time=end_time, \n",
    "                                     max_results=5, \n",
    "                                     tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], \n",
    "                                     exclude=[\"retweets\", \"replies\"], \n",
    "                                     expansions='author_id')\n",
    "\n",
    "    # Prepare tweet and user data\n",
    "    tweets_data = tweets.data\n",
    "    users = {u[\"id\"]: u for u in tweets.includes[\"users\"]} if tweets.includes and \"users\" in tweets.includes else {}\n",
    "\n",
    "    attributes_container = []\n",
    "    if tweets_data:\n",
    "        for tweet in tweets_data:\n",
    "            user = users[tweet.author_id]\n",
    "            attributes_container.append([user.name, tweet.created_at, tweet.public_metrics[\"like_count\"], tweet.source, tweet.text])\n",
    "\n",
    "    # Create DataFrame\n",
    "    columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"Tweet\"]\n",
    "    tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "    print(tweets_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print('Failed to fetch tweets:', str(e))\n",
    "\n",
    "print(\"Data saved to 'tweets.pkl'.\")\n",
    "\n",
    "# Save to CSV\n",
    "#tweets_df.to_csv('tweets.csv', index=False)\n",
    "#print(\"Data saved to 'tweets.csv'.\")\n",
    "\n",
    "# Save to Pickle\n",
    "tweets_df.to_pickle('elon_trial_10tweet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f9883d-b35b-48f8-9d17-fc463ce302be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "tweets_df.to_csv('tweets.csv', index=False)\n",
    "print(\"Data saved to 'tweets.csv'.\")\n",
    "\n",
    "# Save to Pickle\n",
    "tweets_df.to_pickle('tweets_tim cook 10 tweet.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e8bd35-33d3-4cad-985a-e819d23c820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'tweets_next100_timcook.csv'.\n",
      "Data saved to 'tweets_next100_timcook.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter credentials\n",
    "#bearer_token = AAAAAAAAAAAAAAAAAAAAALAPtgEAAAAADcz9vgczEZMZ7q6u5aGQ4UstazE%3DOSybzlXB9L8nCDM6XRgLlZSTqsJ1GaOV8UAoMqZgk9Zc5sODJQ'\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n",
    "\n",
    "# User ID for which to fetch tweets\n",
    "#user_id = \"1636590253\"  # Example: Tim Cook's user ID\n",
    "user_id = \"44196397\"\n",
    "\n",
    "# Define time range\n",
    "start_time = \"202-01-01T00:00:00Z\"\n",
    "end_time = \"2020-T00:00:00Z\"\n",
    "\n",
    "def fetch_tweets(user_id, start_time, end_time, max_results=100):\n",
    "    all_tweets = []\n",
    "    includes_users = {}\n",
    "    response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                       tweet_fields=[\"created_at\", \"public_metrics\", \"source\"], exclude=[\"retweets\", \"replies\"],\n",
    "                                       expansions=\"author_id\")\n",
    "    if response.data:\n",
    "        all_tweets.extend(response.data)\n",
    "        if 'users' in response.includes:\n",
    "            for user in response.includes['users']:\n",
    "                includes_users[user.id] = user\n",
    "\n",
    "    while 'next_token' in response.meta:\n",
    "        response = client.get_users_tweets(id=user_id, start_time=start_time, end_time=end_time, max_results=max_results,\n",
    "                                           pagination_token=response.meta['next_token'], tweet_fields=[\"created_at\", \"public_metrics\", \"source\"],\n",
    "                                           exclude=[\"retweets\", \"replies\"], expansions=\"author_id\")\n",
    "        if response.data:\n",
    "            all_tweets.extend(response.data)\n",
    "            if 'users' in response.includes:\n",
    "                for user in response.includes['users']:\n",
    "                    includes_users[user.id] = user\n",
    "\n",
    "    return all_tweets, includes_users\n",
    "    \n",
    "tweets, users = fetch_tweets(user_id, start_time, end_time)\n",
    "\n",
    "attributes_container = [\n",
    "    [\n",
    "        users[tweet.author_id].name,\n",
    "        tweet.created_at,\n",
    "        tweet.public_metrics['like_count'],\n",
    "        tweet.public_metrics['retweet_count'],\n",
    "        tweet.source,\n",
    "        tweet.text\n",
    "    ]\n",
    "    for tweet in tweets\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"User\", \"Date Created\", \"Number of Likes\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"]\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=columns)\n",
    "\n",
    "# Save to CSV and Pickle\n",
    "tweets_df.to_csv('tweets_next100_timcook.csv', index=False)\n",
    "print(\"Data saved to 'tweets_next100_timcook.csv'.\")\n",
    "tweets_df.to_pickle('tweets_next100_timcook.pkl')\n",
    "print(\"Data saved to 'tweets_next100_timcook.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ceeb4-b674-454d-85b5-cca06ecb51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
